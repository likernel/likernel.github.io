[{"title":"Ubuntu下安装Docker","date":"2018-01-31T08:51:27.000Z","path":"2018/01/31/Ubuntu下安装Docker/","text":"本文主要介绍在Ubuntu下Docker的安装。 Ubuntu下安装Docker检查当前内核版本：12$ uname -r4.14.0-041400-generic 内核版本要求最低为 3.10。 更新apt源Docker默认APT仓库中的版本较低，因此要设置APT使用Docker的官方源：1.更新包信息，确保APT能使用https的方式，并安装CA证书：12sudo apt-get updatesudo apt-get install apt-transport-https ca-certificates 2.添加GPG密钥：1sudo apt-key adv --keyserver hkp://p80.pool.sks-keyservers.net:80 --recv-keys 58118E89F3A912897C070ADBF76221572C52609D 3.在文件 /etc/apt/sources.list.d/docker.list中添加相应的源。对于16.04版本的系统：1echo \"deb https://apt.dockerproject.org/repo ubuntu-xenial main\" | sudo tee /etc/apt/sources.list.d/docker.list 4.更新APT包索引1sudo apt-get update 5.确保 APT 现在是从设置的仓库中下载Docker1apt-cache policy docker-engine 执行后输出： 6.对于Ubuntu 16.04，推荐安装linux-image-extra-* 内核包。这些包能允许我们使用aufs存储驱动。1sudo apt-get update &amp;&amp; sudo apt-get install linux-image-extra-$(uname -r) linux-image-extra-virtual 安装Docker1sudo apt-get install -y docker-engine 开启守护进程：1sudo service docker start 确认docker正确安装：1sudo docker run hello-world 输出如下： 查看 docker 守护进程的状态：1sudo systemctl status docker 输出如下： 如果不想每次运行Docker都使用sudo权限，可以把用户加到Docker组中，该组在Docker安装时自动创建：1sudo usermod -aG docker $(whoami)","tags":[{"name":"docker","slug":"docker","permalink":"http://likernel.github.io/tags/docker/"}]},{"title":"Docker基础","date":"2018-01-31T04:41:15.000Z","path":"2018/01/31/Docker基础/","text":"Docker是一个开源的应用程序引擎。Docker使用容器引擎解决平台依赖问题，它在每台宿主机上都启动一个Docker的守护进程，守护进程屏蔽了与具体平台相关的信息，对上层应用提供统一的接口。这样Docker化的应用，就可以在多个平台下运行，Docker会针对不同的平台，解析给不同平台下的执行驱动、存储驱动和网络驱动去执行。达到： Build once，Run anywhere，Configure once，Run anything. Docker如果把Docker当做一个独立的软件来看，它就是用Golang写的开源程序，采用C/S架构，包含Docker Server和Docker Client。docker生态包括两个部分：Docker仓库和Docker自身程序。 Docker仓库官方的Docker仓库地址为：https://hub.docker.com，上面的应用非常丰富，既有各大公司打包的应用，也有大量个人开发者提供的应用。 Docker自身程序Docker运行在Linux操作系统之上，属于用户态程序，通过一些接口和内核交互。Docker Daemon作为Server端，在宿主机上以后台守护进程的形式运行。Docker Client使用比较灵活，既可以在本机上以bin命令的形式发送指令，也可在远端通过RESTful API的形式发送指令；Docker的Server端接受指令并把指令分解为一系列任务去执行。 Docker工作流程一图胜千言： 可以理解为github版的应用部署解决方案。 Docker分层首先，用户的需求是：把软件运行起来，至于如何安装软件、软件运行在什么操作系统上，用户不太关心。就把软件和它依赖的环境（操作系统、共享库）、配置文件打包在一起，以虚拟机的形式放到官方库。但是，这样存在一个问题：我们不需要每次安装软件都带上它依赖的操作系统，因此引入了分层。比如操作系统是第一层，依赖库和第三方软件是第二层，应用的软件包和配置文件是第三层。如果两个应用有相同的底层，就可以共享这些库。例如下图中应用A和B需要的操作系统一样，就可以共享这一层。 但是这样共享层存在冲突问题，这时候就要规定他们的优先级，一般下层和上层有相同的文件和配置时，上层覆盖下层，数据以上层数据为主。我们给每个应用一个优先级最高的空白层，如果需要修改下层文件，就把这个文件拷贝到这个空白层即可。如下图： 这样从应用A的角度来说，文件已经修改成功，而从应用B的角度来看，文件没发生任何变化。这就是Docker的分层和写时拷贝策略 镜像和容器主流的虚拟机一般比较笨重（需要消耗大量的系统资源，如：CPU、内存），因此我们最好使用容器类虚拟机（例如OpenVZ、VServer、LXC），这是一种内核虚拟化技术，与宿主机运行在相同的Linux内核，不需要指令级模拟，性能消耗非常小，是非常轻量级的虚拟化容器。Docker使用的就是LXC（后来推出了libcontainer）。 接下来就讨论镜像和容器：在Docker的官方仓库里只有一些完整的文件系统和程序包，没有动态生成新文件的需求，此为镜像（image）。把镜像下载到宿主机对外提供服务时，有可能需要修改文件（比如输出新日志到日志文件中），此为容器。 仓库中的应用都是以镜像的形式存在的，把镜像从Docker仓库拉到本机，以这个镜像为模板启动应用就叫容器。这是Docker最核心的两个概念，所有的指令和文档都是围绕镜像和容器展开的。 Docker变更管理举个栗子，现有一个应用的Docker镜像，V1.0版本有三层。接下来需要做如下修改： 修改位于第一层的文件A。 删除位于第二层的文件B。 新建一个文件C。 Docker会新建一个第四层，针对上面的修改，它的处理方法如下： 把第一层的文件A拷贝到第四层，修改文件A的内容。 在第四层把文件B设置为不存在。 在第四层创建以个文件C。 这时候版本就变为了V1.1，我们发布到Docker仓库时，只需要把第四层上传到仓库即可。 参考[^1]: 《循序渐进学Docker》李金榜，尹烨等. 编著","tags":[{"name":"docker","slug":"docker","permalink":"http://likernel.github.io/tags/docker/"}]},{"title":"PyQt5之信号与槽","date":"2018-01-25T04:13:52.000Z","path":"2018/01/25/PyQt5之信号与槽/","text":"PyQt5中最核心的内容就是信号与槽。本文主要结合一个简单的实例对这部分内容进行详细的介绍。 预备知识本文是笔者在学习pyQt5中的学习笔记，需要建立在一定基础之上，如下。 Python面向对象知识 了解PyQt5基本操作：布局、常用控件等。 Qt Designer的使用 何谓信号与槽信号和槽机制是PyQt5的核心机制，主要用来在对象之间传递数据。具体的过程是：1事件发生-&gt;发射signal-&gt;slot响应 信号当对象的状态发生变化的时候，信号就由对象发射（emit）出去，与其关联的槽函数立刻被执行。 对象只负责发送信号，不关心是哪个对象接收信号。这样保证了对象与对象之间的低耦合。 槽负责接受信号，当和槽连接的信号被发射时，槽会被调用。一个槽并不知道是否有信号与自己相连。 如何连接信号与槽在Qt Designer中，有很便捷的方法。在Edit中通过Edit Signals/Slots（F4）连接信号与槽。但是这种方式，并不能完全满足我们的需求，很多时候我们需要手动（手写代码）连接信号与槽。 手动连接信号与槽手动连接主要下面三种方式：123self.connect(widgets,SIGNAL(&quot;signal&quot;),func)self.connect(widgets,SIGNAL(&quot;signal&quot;),instance.methodname)self.connect(widgets,SIGNAL(&quot;signal&quot;),instance,SLOT(&quot;slotSignature&quot;)) ##自定义槽函数Qt中的对象有很多预定义的信号和槽函数。但是预定义的槽函数毕竟有限，我们需要自定义槽函数，实现我们的需求。当然可以通过eric自动生成槽函数，但是这种方式主要的逻辑仍然需要自己实现，这里就不介绍。 举个栗子：这里用自己写的一个岩体分级的工具为例。逻辑非常简单：就是输入一堆参数，得到一个结果，通过结果对岩体进行分级，界面如下。 UI设计通过Qt Designer生成。 逻辑部分和UI部分分离，新建.py文件，创建一个类，继承QMainWindow和QtDesigner生成的UI类Ui_MainWindow。12345class MainWindow(QMainWindow, Ui_MainWindow): global QRD, Jn, Jr, Ja, Jw, SRF, res,rl def __init__(self, parent = None): QMainWindow.__init__(self,parent) self.setupUi(self) 继承父类Ui_MainWindow的setupUi方法，setupUi方法中通过控件的名字来自动连接槽：1QtCore.QMetaObject.connectSlotsByName(MainWindow) 通过自定义槽函数来实现特定的功能：12def on_pushButton_clicked(self): self.test() 其中test()主要实现具体的逻辑功能，注意这里自定义槽函数的名称要和控件名称（pushButton）对应：on_pushButton\\ _clicked。 通过实例ui的show()方法来显示程序：123456if __name__ == &apos;__main__&apos;: import sys app = QtWidgets.QApplication(sys.argv) ui = MainWindow() ui.show() sys.exit(app.exec_()) 这里对信号和槽做了粗浅的认识和学习，关于其他内容不再赘述，更多详细内容，可参照官方文档。 官方文档PyQt5 Reference Guide","tags":[{"name":"python","slug":"python","permalink":"http://likernel.github.io/tags/python/"},{"name":"PyQt5","slug":"PyQt5","permalink":"http://likernel.github.io/tags/PyQt5/"}]},{"title":"PyQt5+Pycharm环境搭建","date":"2018-01-23T00:35:50.000Z","path":"2018/01/23/PyQt5-Pycharm环境搭建/","text":"最近要写一个岩石分级的工具，选择了PyQt5作为GUI开发的框架。本文介绍一下基本的环境的配置。 安装环境 Pycharm Python 3.6(这里建议使用python3，在虚拟环境中配置) PyQt5 SIP Qt Designer安装过程安装SIP1pip3 install SIP sip是RiverBank（PyQt的开发商）开发的用于PyQt的Python/C++混合编程解决方案。由于Qt框架的复杂性，PyQt并没有使用Cython、SWIG的混合编程方案，而是自己单独做了一套框架。sip包括一个sip工具、SDK和Python Module。 安装PyQt51pip3 install PyQt5 安装QtDesignerQtDesigner在pyqt5-tools这个包里面有1pip install pyqt5-tools Pycharm配置这里我们主要在Pycharm里面配置两个扩展工具。QtDesigner和PyUIC，前者是可视化UI编辑工具，后者是将.ui文件转成.py文件的工具。 QtDesigner配置1.Ctrl+Alt+s调出设置-&gt;Tools-&gt;External Tools 2.添加扩展工具Qt Designer Program填写designer.exe所在的路径，在pyqt5-tools包下面。Working directory填写$ProjectFileDir$(项目目录，在Insert Macro…中可以选择) PyUIC配置同Qt Designer的配置，具体的配置参数如下： Program填写python.exe所在的路径（根据你的虚拟环境而定）。Working directory填写$FileDir$(文件目录，在Insert Macro…中可以选择)其中，Arguments的配置如下：1-m PyQt5.uic.pyuic $FileName$ -o $FileNameWithoutExtension$.py 这时候在External tools下可以看到这两个扩展工具。 点击QtDesigner就可以进入QtDesigner界面了，界面设计完成，可以通过PyUIC将设计的UI文件转化成python代码。","tags":[{"name":"python","slug":"python","permalink":"http://likernel.github.io/tags/python/"},{"name":"PyQt5","slug":"PyQt5","permalink":"http://likernel.github.io/tags/PyQt5/"}]},{"title":"scikit-neuralnetwork安装","date":"2017-12-27T23:32:48.000Z","path":"2017/12/28/scikit-neuralnetwork安装/","text":"scikit-neuralnetwork是一个开源的深度学习的库，scikit-neuralnetwork的接口和设计规范都是参照scikit-learn，之前用过scikit-learn，对它比较熟悉，因此，准备用它作为深度学习的工具。本文主要介绍它的安装过程以及期间可能遇到的一些问题。 环境 Ubuntu 16.04 Python 3.5（virtualenv） 注：选择Linux的原因，由于这些库的开发者在开发的时候用的都是Linux，出问题的话对应的好解决，Windows环境也可以部署，但是稍微麻烦一些。 Python的版本选择的是3.5，在沙箱环境virtualenv中，使用virtualenv的好处就是方便管理包，出现问题也可以直接删除这个环境，避免不必要的麻烦。 安装安装scikit-neuralnetwork之前需要安装一些依赖（需要依赖的库）。 1.进入Python的沙箱环境，安装以下依赖。12345678pip install scikit-learn==0.17pip install scipy==0.17.0pip install Theano==0.8.1pip install git+https://github.com/Lasagne/Lasagne.git@0440814#egg=Lasagne==0.2-devsudo pip install -U numpypip install -e git+https://github.com/lisa-lab/pylearn2.git=Packagepip install pandaspip install matplotlib 2.安装scikit-neuralnetwork123456# 将scikit-neuralnetwork源码从github上拷贝下来。git clone https://github.com/aigamedev/scikit-neuralnetwork.git# 进入scikit-neuralnetwork文件夹cd scikit-neuralnetwork# 安装python setup.py develop 3.测试12pip install nosenosetests -v sknn.tests 正常情况下，到这一步不出现问题就安装好了。实际情况会遇到很多问题，下面总结一下常见的问题，和解决方案。 常见问题####各种依赖安装出错最常见的是pylearn2。各种module不存在，cannot import等问题。 解决方案：在测试或者源码安装时，往往会出现上述情况，原因一般是版本的问题。由于网上的很多教程时间比较早，可能他们安装时不会出现这样的问题。因此，这里最好使用推荐的版本。下图是笔者安装时测试没问题的一些版本的包。 注：实在想用最新的版本，可以根据相应的问题修改源码（指的是pylearn2等第三方源码安装的），通常情况下是import出问题。 测试时出现问题1.ERROR：no modole named XXX通常是上述包未安装完，可以根据提示安装完对应的包。记住安装完成后，可以通过 pip list/freeze check一下。 2.ImportError: libmkl_rt.so:cannot open shared object file: No such file or directory. mkl是英特尔数学核心函数库，这个.so（shared object）文件就在进行上述测试时需要调用。但是找不到了。需要我们重新配置一番。①进入官网下载。 ②找到libmkl_rt.so，一般在”/opt/intel/compilers_and_libraries_2018.1.163/linux/mkl/lib“下。“2018.1.163”一般是你下载的版本。可以看到，下面可以找到其所在位置。 ③让系统能找到，这里使用ldconfig方式。在/etc/ld.so.conf.d下创建一个文件mylibs.conf（注意修改其权限为可写的）。编辑文件，将对应的路径添加进去。 注：上述路径可以不用添加那么多，这里是当时为了保险起见都加了。 ④sudo ldconfig 重新加载对应的shared libraries。 ⑤可以通过 ldconfig -vcheck一下安装成功没有。 这个时候再使用 nosetests -v sknn.tests 进行测试就没有问题了。 3.如遇到其他问题可随时留言。 Demo1.首先来个多层神经网络的demo，examples下的plot_mlp.py（官网和github上也是用的这个demo）。 注：需要安装python3-tk，不然会出现上述“ERROR：no modole named XXX”错误。 2.再来个mnist数据集上的测试，随便找一个bench_mnist.py下面是训练神经网络的过程。 注：这里由于数据量大，没有完全完全跑完，这里只是验证一下。接下来，我们就可以愉快的进行deep learning的学习了。 参考官网地址：https://scikit-neuralnetwork.readthedocs.io github地址：https://github.com/aigamedev/scikit-neuralnetwork 以上便是scikit-neuralnetwork安装的整个过程，供自己学习记录，欢迎留言和转载（注明出处）。","tags":[{"name":"深度学习","slug":"深度学习","permalink":"http://likernel.github.io/tags/深度学习/"}]},{"title":"NN-神经网络","date":"2017-12-23T07:01:47.000Z","path":"2017/12/23/NN-神经网络/","text":"神经网络（Neural Network）是以人脑中的神经网络为启发的，历史上出现过很多不同的版本，其中最著名也是最常用的算法就是在1980提出的backpropagation(反向传播)，也可以称为BP神经网络，它被应用于多层向前神经网络（Multilayer Feed-Forward Neural Network）。 定义多层向前神经网络由3部分组成，输入层(input layer)，隐藏层(hidden layers)，输出层(output layers)。 每一层由单元（units）组成，我们也可称其为神经节点。 输入层（input layer）由训练集的实例特征向量传入。 经过连接点的权重传入下一层，一层的输出是下一层的输入。 隐藏层（hidden layer）的个数可以是任意的，输入层有一层，输出层有一层。 上面这幅图称为两层神经网络（输入层不算）。 作为多层向前神经网络，理论上，如果有足够多的隐藏层，和足够大的训练集，可以模拟出任何方程。 设计神经网络结构 使用神经网络训练数据之前，必须先设计神经网络的结构，也就是确定神经网络的层数以及每层的单元个数。 特征向量在被传入输入层时，通常要先标准化到0，1之间，目的是加速学习的过程。 离散型变量的可以被编码成：每一个输入单元对应一个特征值可能被赋的值。 没有特定的规则来说明最好设计多少个隐藏层，往往需要根据实验测试和误差，以及准确度来实验并改进。 分类神经网络既可以做分类，也可以解决回归问题，本文主要讨论分类问题。 二分类：用一个输出单元表示（分别用0和1表示）。 多于两类：每一个类别用一个输出单元表示。 所以，一般情况下，输出单元数量，往往等于类别数量。 交叉验证之前介绍的机器学习的一般框架主要是把一组数据分成训练集和测试集两部分。训练集来训练模型。测试集输入进去看结果是不是对的，根据正确率得到一个准确度。 机器学习中还有一种更常用和科学的方法，交叉验证方法(cross-validation)。下面来介绍一下这种方法。 前面我们用机器学习的一般框架是把数据分成2份，一份测试集一份数据集。 交叉验证方法就是把数据分成更多份，比如像上图中分成3份，其中2份当做训练集，1份当做测试集。重复三次，就可以得到3个准确度，做一个均值就得到最终的准确度，这就是交叉验证。实际上可以分成任意的K份，所以这个方法也被称为K-fold cross validation。 backpropagation算法开篇的时候提到神经网络中最常用的算法就是backpropagation，下面是这种BP算法的主要思想: 通过迭代性处理训练集中的实例。 对比经过神经网络后输入层预测值（predict value）和真实值（target value）。 反方向（output-&gt;hidden-&gt;input）来以最小化误差（error）来更新每个连接的权重（weight）。 输入数据集、学习率（learning rate）和一个多层向前神经网络。 输出一个训练好的神经网络。 初始化权重（weights）和偏向（bias，每个单元都有这样一个偏向）需要在开始时进行初始化，一般在-1到1或-0.5到0.5之间进行随机初始化。 步骤对于一个训练实例X执行以下步骤： 由输入层，向前传送，具体传递和计算过程见下图： $$I_j=\\sum_{i}{} w_ij O_i+\\theta_j$$ 其中，\\(O_j=\\frac{1}{1+{e^{-I_j}}}\\) 如上图所示n个单元，加权求和加上一个偏向后得到一个值，再代入上面的非线性转化方程，可以得到输出结果。 通过这样的方式就能够一步一步正向的计算出最后输出，接下来就是倒推回去修正优化神经网络。 2.根据误差（error）反向传送。 输出层：\\(E_{rr_j}=O_j(1-O_j)(T_j-O_j)\\) 隐藏层：\\(E_{rr_j}=O_j(1-O_j)\\sum_{k}{} E_{rr_j} w_{jk}\\) 权重更新：\\(w_{ij}(new)=w_{ij}(old)+\\Delta w_{ij}\\)，其中，\\(\\Delta w_{ij}=(l)E_{rr_j}O_i\\)，l为学习率（learning rate）。 偏向更新：\\(\\theta_j(new)=\\theta_j(old)+\\Delta \\theta_j\\)，其中，\\(\\Delta \\theta_j=(l)E_{rr_j}O_i\\) 注：上述的更新实际上采用的是一种梯度爬行的方法。 3.终止条件。 权重的更新低于某个阈值。 预测的错误率低于某个阈值。 达到预设的循环次数。 实际上最核心的过程就是在不断的更新、优化权重和偏向。以上就是对神经网络的初步认识，为后面的深度学习打下基础，本文完。","tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://likernel.github.io/tags/机器学习/"},{"name":"深度学习","slug":"深度学习","permalink":"http://likernel.github.io/tags/深度学习/"}]},{"title":"KNN-最邻近规则分类","date":"2017-12-23T06:59:48.000Z","path":"2017/12/23/KNN-最邻近规则分类/","text":"KNN（K-Nearest Neighbor）是Cover&amp;Hart于1968年提出的一种分类算法，算法思想就是：&gt;1.为判断未知实例的类别，以所有已知类别的实例作为参考点；2.选择参数K；3.计算未知实例与所有已知实例的距离；4.选择最近的K个已知实例；5.根据投票法则，将未知实例归为K个最邻近样本中最多数的类别。 KNN就是这种“近朱者赤，近墨者黑”的思想，它由你的邻居来推断出你的类别。这里仅对以下一些细节进行补充说明。 距离距离的衡量包括：欧式距离、余弦相似度、曼哈顿距离等。 欧式距离：$$dist(X,Y)=\\sqrt{\\sum_{i=1}^{n} {(x_i-y_i)}^2}$$ 余弦相似度（Cosine Similarity）：$$sim(X,Y)=\\cos\\theta=\\frac{\\vec{x}\\cdot \\vec{y}}{||x||\\cdot||y||}$$ 曼哈顿距离：$$dist(X,Y)=\\sqrt{\\sum_{i=1}^{n} {|x_i-y_i|}}$$注：对于文本分类来说，使用余弦相似度来计算就比欧式距离更合适。 关于Kk值通常是采用交叉检验来确定（以k=1为基准），一般低于训练样本数的平方根。 优劣1.优点：简单，易于理解，易于实现，无需估计参数，无需训练。适合对稀有事件进行分类，特别适合于多分类问题。2.缺点：懒惰算法，对测试样本分类时的计算量大，内存开销大。可解释性较差，无法给出决策树那样的规则。 改进版本对距离加权，距离越近，权重越大。例如：1/d。 本文完。","tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://likernel.github.io/tags/机器学习/"}]},{"title":"决策树","date":"2017-12-23T06:55:35.000Z","path":"2017/12/23/决策树/","text":"决策树（decision tree）又称为判定树，是运用于分类的一种树结构，其中：&gt;1.每个内部节点代表对某一属性的一次测试。2.每条边代表一个测试结果。3.叶节点代表某个类或类的分布。 决策过程需要从根节点开始，测试集中的数据与决策树中的特征节点进行比较，并按照比较结果选择下一比较分支，直到叶子节点作为最终的决策结果。 实现决策树的核心就是选择属性判断节点，有很多标准，对应的就是不同的算法，最著名的有三个：ID3，C4.5和CART。在介绍之前，先了解一些预备知识。 预备知识信息熵信息是个抽象概念。人们常说信息很多，或者信息较少，但很难说清楚信息到底有多少。1948年，香农提出了“信息熵”的概念，才解决了对信息的量化度量问题。 热力学中的热熵是表示分子状态混乱程度的物理量。香农用信息熵的概念来描述信源的不确定度。 一条信息的信息量大小和不确定性有直接的关系。如果信息的不确定性越大，熵的值也就越大。设D为用类别对训练元组进行的划分，则D的熵（entropy）表示为： $$Info(D)=-\\sum_{i=1}^{m} p_i log_{2}p_i$$ 其中，D为所有事件集合，p为发生概率，m为特征总数。 一般用比特（bit）来衡量信息的多少。当然，如果log不是以2为底，则使用的是其他的单位。 信息增益即信息获取量（information gain），原有信息熵与属性划分后信息熵的差值，具体计算法如下： $$gain(A)=Info(D)-Info_A(D)$$ 其中，第二项为将训练元组D按属性A进行划分： $$Info_A(D)=\\sum_{j=1}^{v} \\frac{|D_j|}{|D|} Info(D_j)$$ 决策树归纳算法ID3算法ID3算法实际上就是在每次需要分裂时，计算每个属性的增益率，然后选择增益率最大的属性进行分裂。 C4.5算法 ID3算法存在一个问题，就是偏向于多值属性，例如，如果存在唯一标识属性ID，则ID3会选择它作为分裂属性，这样虽然使得划分充分纯净，但这种划分对分类几乎毫无用处。ID3的后继算法C4.5使用增益率（gain ratio）的信息增益扩充，试图克服这个偏倚。 C4.5算法首先定义了“分裂信息”，其定义可以表示成： $$split\\underline{} Info_A(D)=\\sum_{j=1}^{v} \\frac{|D_j|}{|D|} log_2(\\frac{|D_j|}{|D|})$$ 增益率被定义为： $$gain\\underline{} ratio(A)=\\frac{gain}{split\\underline{} Info(A)}$$ C4.5选择具有最大增益率的属性作为分裂属性。 补充说明剪枝在实际构造决策树时，通常要进行剪枝，主要是为了避免overfitting。剪枝有两种： 1.先剪枝：在构造过程中，当某个节点满足剪枝条件，则直接停止此分支的构造。2.后剪枝：先构造完成完整的决策树，再通过某些条件遍历树进行剪枝。 优缺点1.优点：直观、便于理解，小规模数据集有效。2.缺点：处理连续变量时效果不好；类别较多时，错误增加较多；可规模性一般。 一种特殊情况在决策树构造过程中可能会出现这种情况：所有属性都作为分裂属性用完了，但有的子集还不是纯净集，即集合内的元素不属于同一类别。在这种情况下，一般采取“多数表决”，即使用此子集中出现次数最多的类别作为此节点类别，然后将此节点作为叶子节点。 关于决策树的概念先介绍这么多，具体实例和应用，会有后续文章讲解。","tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://likernel.github.io/tags/机器学习/"}]},{"title":"机器学习基本概念","date":"2017-12-23T04:46:00.000Z","path":"2017/12/23/机器学习基本概念/","text":"由于论文需要，需要学习一下机器学习相关的知识，本文主要作为抛砖引玉，介绍机器学习的一些基础概念。 概念学习 概念学习是指从有关某个布尔函数的输入输出训练样例中推断出该布尔函数，可以表示为：X-&gt;Y/C(x)。 X：实例集，概念就是基于这个实例集的。x：具体的实例。C(x)：待学习的目标概念/函数。 ###训练集和测试集训练集：用来进行训练，产生模型/算法的数据集。 测试集：用来测试已经学习好的模型或算法。 特征向量和标记特征向量：属性的集合，通常用一个向量表示，附属于一个实例(x)。 标记：C(x)，实例类别的标记。 正例和反例正例：目标概念的成员。 反例：非目标概念的成员。 分类和回归分类和回归在机器学习中是很重要的两个领域，暂且先做如下简单的解释，不做深入的探讨。 分类分类（classification）的目标标记（label）为类别性数据（离散型）。 回归回归（regression）的目标标记（label）为连续性数值。 ##有监督、无监督和半监督学习机器学习主要分为三类：有监督学习、无监督学习和半监督学习。 有监督学习训练集有类别标记（即数据中包含分类的结果）。计算机进行学习之后，在丢给它新的数据，它能够算出结果。可以理解为“在类别标记的监督下进行学习”。 主要包括：分类和回归。 无监督学习训练集无类别标记。单纯凭借计算机强大的计算能力分析数据的特征，得出结果，通常是得到一些集合，集合内的数据在某些特征上相同或相似。可以理解为“没有在类别标记的监督下进行学习”。 主要包括：聚类。 半监督学习训练集一部分有类别标记，一部分没有类别标记。无类别标记的数据量往往远远大于有有标记的数据。可以通过一些有类别标记的数据局部特征，和没类别标记数据的整体分布，得到可以接受甚至是非常好的分类结果。 主要包括：分类、回归、聚类和降维。 机器学习一般步骤这里不做详细的阐述，只列举一般的机器学习的步骤： 1.问题定义通过观察类别确定究竟是分类还是回归问题。 2.样本划分将数据划分为训练集和测试集。 3.训练算法用训练集和训练集的特征向量训练算法。 4.评估算法用学习来的算法用在测试集。其中，涉及调参和优化（调参还涉及到验证集）这里不做赘述。 本文主要起到一个抛砖引玉，为后面的学习，梳理一些基本的概念，本文完。","tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://likernel.github.io/tags/机器学习/"}]},{"title":"Linux启动流程","date":"2017-08-31T21:25:09.000Z","path":"2017/09/01/Linux启动流程/","text":"之前介绍过计算机的启动流程，我们在此基础上继续介绍Linux的启动流程。 #1.加载BIOS当你打开计算机电源，计算机会首先加载BIOS信息，BIOS信息是如此的重要，以至于计算机必须在最开始就找到它。这是因为BIOS中包含了CPU的相关信息、设备启动顺序信息、硬盘信息、内存信息、时钟信息、PnP特性等等。在此之后，计算机心里就有谱了，知道应该去读取哪个硬件设备了。 #2.读取MBR众所周知，硬盘上第0磁道第一个扇区被称为MBR，也就是Master Boot Record，即主引导记录，它的大小是512字节，别看地方不大，可里面却存放了预启动信息、分区表信息。 系统找到BIOS所指定的硬盘的MBR后，就会将其复制到0x7c00地址所在的物理内存中。其实被复制到物理内存的内容就是Boot Loader，而具体到你的电脑，那就是lilo或者grub了。 #3.Boot LoaderBoot Loader 就是在操作系统内核运行之前运行的一段小程序。通过这段小程序，我们可以初始化硬件设备、建立内存空间的映射图，从而将系统的软硬件环境带到一个合适的状态，以便为最终调用操作系统内核做好一切准备。 Boot Loader有若干种，其中Grub、Lilo和spfdisk是常见的Loader。我们以Grub为例： 系统读取内存中的grub配置信息（一般为menu.lst或grub.lst），并依照此配置信息来启动不同的操作系统。 #4.加载内核操作系统接管硬件以后，首先读入 /boot 目录下的内核文件，如下： 根据grub设定的内核映像所在路径，系统读取内存映像，并进行解压缩操作。此时，屏幕一般会输出“Uncompressing Linux”的提示。当解压缩内核完成后，屏幕输出“OK, booting the kernel”。 系统将解压后的内核放置在内存之中，并调用start_kernel()函数来启动一系列的初始化函数并初始化各种设备，完成Linux核心环境的建立。至此，Linux内核已经建立起来了，基于Linux的程序应该可以正常运行了。 #5.启动初始化进程并确定运行级别内核被加载后，第一个运行的程序便是/sbin/init，它的进程编号（pid）就是1。其他所有进程都从它衍生，都是它的子进程。该文件会读取/etc/inittab文件，并依据此文件来进行初始化工作。 其实/etc/inittab文件最主要的作用就是设定Linux的运行等级，其设定形式是“：id:5:initdefault:”，这就表明Linux需要运行在等级5上。运行等级相关内容在之前有过详细介绍。 #6.init进程执行rc.sysinit在设定了运行等级后，Linux系统执行的第一个用户层文件就是/etc/rc.d/rc.sysinit脚本程序，它做的工作非常多，包括设定PATH、设定网络配置（/etc/sysconfig/network）、启动swap分区、设定/proc等等。 #7.启动内核模块具体是依据/etc/modules.conf文件或/etc/modules.d目录下的文件来装载内核模块。 #8.执行不同运行级别的脚本程序根据运行级别的不同，系统会运行rc0.d到rc6.d中的相应的脚本程序，来完成相应的初始化工作和启动相应的服务，如下： 上面目录名中的”rc”，表示run command（运行程序），最后的d表示directory（目录）。下面让我们看看 /etc/rc2.d 目录中到底指定了哪些程序。 可以看到，除了第一个文件README以外，其他文件名都是”字母S+两位数字+程序名”的形式。字母S表示Start，也就是启动的意思（启动脚本的运行参数为start），如果这个位置是字母K，就代表Kill（关闭），即如果从其他运行级别切换过来，需要关闭的程序（启动脚本的运行参数为stop）。后面的两位数字表示处理顺序，数字越小越早处理，所以第一个启动的程序是motd，然后是rpcbing、nfs……数字相同时，则按照程序名的字母顺序启动，所以rsyslog会先于sudo启动。 这个目录里的所有文件（除了README），就是启动时要加载的程序。如果想增加或删除某些程序，不建议手动修改 /etc/rcN.d 目录，最好是用一些专门命令进行管理。 #9.执行/etc/rc.d/rc.local你如果打开了此文件，里面有一句话，读过之后，你就会对此命令的作用一目了然：123# This script will be executed *after* all the other init scripts.# You can put your own initialization stuff in here if you don’t# want to do the full Sys V style init stuff. rc.local就是在一切初始化工作后，Linux留给用户进行个性化的地方。你可以把你想设置和启动的东西放到这里。 #10.执行/bin/login程序，进入登录状态输入用户名密码登录成功后，系统会为用户分配一个用户 ID（UID），和一个组 ID（GID）。这两个 ID 就好像身份证一样会一直伴随用户，用于检测用户执行程序时的身份验证。 当用户登录成功后，一个完整的操作系统就展现在用户的面前了。","tags":[{"name":"Linux","slug":"Linux","permalink":"http://likernel.github.io/tags/Linux/"},{"name":"操作系统","slug":"操作系统","permalink":"http://likernel.github.io/tags/操作系统/"}]},{"title":"计算机启动流程","date":"2017-08-31T20:58:22.000Z","path":"2017/09/01/计算机启动流程/","text":"计算机的启动是一个非常复杂的过程，在介绍Linux启动流程之前，有必要先了解一下计算机的启动流程。我们都知道计算机的启动叫做boot，这个名称来源于一句谚语： “pull oneself up by one’s bootstraps”字面意思是”拽着鞋带把自己拉起来”，这当是不可能的事情。 最早的时候，工程师们用它来比喻计算机的启动，计算机启动是一个很矛盾的过程：必须先运行程序，然后计算机才能启动，但是计算机不启动就无法运行程序。 早期真的是这样，必须想尽各种办法，把一小段程序装进内存，然后计算机才能正常运行。所以，工程师们把这个过程叫做”拉鞋带”，久而久之就简称为boot了。 计算机的整个启动过程分成四个阶段。 第一阶段：BIOS上个世纪70年代初，”只读内存”（read-only memory，缩写为ROM）发明，开机程序被刷入ROM芯片，计算机通电后，第一件事就是读取它。 这块芯片里的程序叫做”基本输出输入系统”（Basic Input/Output System），简称为BIOS。 硬件自检BIOS程序首先检查，计算机硬件能否满足运行的基本条件，这叫做”硬件自检”（Power-On Self-Test），缩写为POST。如果硬件出现问题，主板会发出不同含义的蜂鸣，启动中止。如果没有问题，屏幕就会显示出CPU、内存、硬盘等信息。 启动顺序硬件自检完成后，BIOS把控制权转交给下一阶段的启动程序。这时，BIOS需要知道，”下一阶段的启动程序”具体存放在哪一个设备。也就是说，BIOS需要有一个外部储存设备的排序，排在前面的设备就是优先转交控制权的设备。这种排序叫做”启动顺序”（Boot Sequence）。打开BIOS的操作界面，里面有一项就是”设定启动顺序”。我们在装系统的时候经常会设置这一个选项，例如，将U盘作为启动盘的时候，将U盘启动的顺序设为第一启动。 #第二阶段：主引导记录BIOS按照”启动顺序”，把控制权转交给排在第一位的储存设备。这时，计算机读取该设备的第一个扇区，也就是读取最前面的512个字节。如果这512个字节的最后两个字节是0x55和0xAA，表明这个设备可以用于启动；如果不是，表明设备不能用于启动，控制权于是被转交给”启动顺序”中的下一个设备。这最前面的512个字节，就叫做”主引导记录”（Master boot record，缩写为MBR）。 主引导记录的结构“主引导记录”只有512个字节，放不了太多东西。它的主要作用是，告诉计算机到硬盘的哪一个位置去找操作系统。主引导记录由三个部分组成：123（1） 第1-446字节：调用操作系统的机器码。（2） 第447-510字节：分区表（Partition table）。（3） 第511-512字节：主引导记录签名（0x55和0xAA）。 其中，第二部分”分区表”的作用，是将硬盘分成若干个区。 分区表硬盘分区有很多好处。考虑到每个区可以安装不同的操作系统，”主引导记录”因此必须知道将控制权转交给哪个区。 分区表的长度只有64个字节，里面又分成四项，每项16个字节。所以，一个硬盘最多只能分四个一级分区，又叫做”主分区”。每个主分区的16个字节，由6个部分组成：123456（1） 第1个字节：如果为0x80，就表示该主分区是激活分区，控制权要转交给这个分区。四个主分区里面只能有一个是激活的。（2） 第2-4个字节：主分区第一个扇区的物理位置（柱面、磁头、扇区号等等）。（3） 第5个字节：主分区类型。（4） 第6-8个字节：主分区最后一个扇区的物理位置。（5） 第9-12字节：该主分区第一个扇区的逻辑地址。（6） 第13-16字节：主分区的扇区总数。 最后的四个字节（”主分区的扇区总数”），决定了这个主分区的长度。也就是说，一个主分区的扇区总数最多不超过2的32次方。 如果每个扇区为512个字节，就意味着单个分区最大不超过2TB。再考虑到扇区的逻辑地址也是32位，所以单个硬盘可利用的空间最大也不超过2TB。如果想使用更大的硬盘，只有2个方法：一是提高每个扇区的字节数，二是增加扇区总数。 #第三阶段：硬盘启动这时，计算机的控制权就要转交给硬盘的某个分区了，这里又分成三种情况。 ##情况A：卷引导记录上一节提到，四个主分区里面，只有一个是激活的。计算机会读取激活分区的第一个扇区，叫做”卷引导记录”（Volume boot record，缩写为VBR）。 “卷引导记录”的主要作用是，告诉计算机，操作系统在这个分区里的位置。然后，计算机就会加载操作系统了。 ##情况B：扩展分区和逻辑分区随着硬盘越来越大，四个主分区已经不够了，需要更多的分区。但是，分区表只有四项，因此规定有且仅有一个区可以被定义成”扩展分区”（Extended partition）。所谓”扩展分区”，就是指这个区里面又分成多个区。这种分区里面的分区，就叫做”逻辑分区”（logical partition）。 计算机先读取扩展分区的第一个扇区，叫做”扩展引导记录”（Extended boot record，缩写为EBR）。它里面也包含一张64字节的分区表，但是最多只有两项（也就是两个逻辑分区）。 计算机接着读取第二个逻辑分区的第一个扇区，再从里面的分区表中找到第三个逻辑分区的位置，以此类推，直到某个逻辑分区的分区表只包含它自身为止（即只有一个分区项）。因此，扩展分区可以包含无数个逻辑分区。 但是，似乎很少通过这种方式启动操作系统。如果操作系统确实安装在扩展分区，一般采用下一种方式启动。 ##情况C：启动管理器在这种情况下，计算机读取”主引导记录”前面446字节的机器码之后，不再把控制权转交给某一个分区，而是运行事先安装的”启动管理器”（boot loader），由用户选择启动哪一个操作系统。 Linux环境中，目前最流行的启动管理器是Grub。 #第四阶段：操作系统控制权转交给操作系统后，操作系统的内核首先被载入内存。以Linux系统为例，先载入/boot目录下面的kernel。内核加载成功后，第一个运行的程序是/sbin/init。它根据配置文件（Debian系统是/etc/initab）产生init进程。这是Linux启动后的第一个进程，pid进程编号为1，其他进程都是它的后代。 然后，init线程加载系统的各个模块，比如窗口程序和网络程序，直至执行/bin/login程序，跳出登录界面，等待用户输入用户名和密码。至此，全部启动过程完成。","tags":[{"name":"Linux","slug":"Linux","permalink":"http://likernel.github.io/tags/Linux/"},{"name":"操作系统","slug":"操作系统","permalink":"http://likernel.github.io/tags/操作系统/"}]},{"title":"Linux系统运行级别","date":"2017-08-31T06:35:59.000Z","path":"2017/08/31/Linux系统运行级别/","text":"运行级别（Runlevel）指的是Unix或者Linux等类Unix操作系统的运行模式，不同的运行模式下系统的功能也有所有不同。Linux系统下通常分为7种运行级别，分别是从0到6。各级别介绍如下： #7种运行级别 ##运行级别0停机模式。在这种模式下，系统处于停机状态，系统默认运行级别不能设为0，否则将不能正常启动。这个运行级别主要用于关闭任务，在/etc/rc0.d目录下的各个连接命令都是此级别的命令，在关闭系统时，这些命令将被逐个执行。它们会杀掉所有进程、关闭虚拟内存和交换文件、卸载文件系统和交换分区。 ##运行级别1单用户模式。在这种运行模下，系统处于单用户工作状态，登录用户具有root权限，文件系统被加载但是网络却没有被加载，因此也无法远程登陆。这个运行级别，只允一个用户从本地计算机上登录，/etc/rc1.d目录下的所有文件与此运行级别相关连，这个运行级别一般用于系统管理与维护。 ##运行级别2多用户模式。用户可以通过网络进行登录，但没有NFS（Network File System），即网络文件系统。/etc/rc2.d目录下所有文件与此级别相连。 ##运行级别3完全多用户模式。用户可以通过网络进行登录，且有NFS，用户登陆后会进入控制台命令行模式。这也是缺省的运行模式，在这种运行级别下所有网络服务程序会一起运行。/etc/rc2.d录下的文件与此级别相连。 ##运行级别4自定义模式。这是一种系统未使用的保留模式，/etc/rc4.d目录与此级别相连。这一级别是用户自定义的运行级别，用户可以根自己的需要进行一些自定义设置。如果想要运行这一级别的话，必须在rc3.d目录下放入连接文件，就像其他rc*.d目录下的文件，并指明是启动还是终止进程。 ##运行级别5图形化模式。在 Linux 下运行X Window就是使用这一运行级别，用户登录后将进入图形化的GUI界面。在这一级别下除了DNS的named与级别3不同，其余的都相同。 ##运行级别6重启模式。系统正常关闭并重启，默认运行级别不能设为5，否则系统将不能正常启动。/etc/rc6.d目录与此级别相连。在这一运行级别下，不会关闭电源，/etc/rc6.d目录下的连接与rc0.d目录下的连接基本相同；不同之处在于，虽然它们都执行halt（关闭）命令，但是给halt传递的参数不同，所级别6会重新启动系统而0会关闭系统。 注意：以上适用于CentOS等发行版，而对于Ubuntu等debian系的Linux来说，2~5都是多用户图形模式，几个运行模式没有区别。 #不同运行级别的实现原理如上所述，Linux系统的每一个运行级别，都对应一个目录。 在/etc/init.d目录下有许多脚本程序，我们将这些程序称之为服务(Service)。 而/etc目录下，还有rc0.d~rc6.d共7个目录。在这些目录下都是一些软链接文件，这些链接文件都指向了init.d目录下的service脚本文件。而这些软连接的命名规则为：K+nn+服务名或S+nn+服务名，其中nn为两位数字。 系统启动时，会根据当前运行级别进入对应的rc*.d目录，然后按照文件名顺序检索目录下的链接文件，并会做以下处理：12对于以K开头的文件，系统将终止对应的服务对于以S开头的文件，系统将启动对应的服务 注意：/etc/init.d存在于Ubuntu等发行版中，而CentOS等发行版中位于/etc/rc.d/init.d目录下，但通过/etc/init.d软连接进行关联。同样的，rc*.d等目录，在Ubuntu等系统中位于/etc/目录下，而在CentOS等系统中位于/etc/rc.d目录下，但在/etc下都有对应的软连接。 #Linux运行级别的修改 ##运行级别相关命令查看系统当前运行级别：runlevel12$ runlevelN 3 切换系统运行级别：init N。如，切换到3多用户命令模式：1init 3 常用的init命令还有：init 0结束所有进程后关闭计算机、init 6重启系统 ##修改系统默认运行级别Linux 会根据运行级别的不同执行不同程序，虽然Ubuntu和CenosOS等不同发行版中都有运行级别的概念，但运行机制不同，因此修改默认启动级别的方式也有所有不同。 这里以CentOS为例： CentOS等Linux系统中使用一种叫System V的机制来启动运行级别，在该机制下，通过/etc/inittab配置系统启动进程。因此，也可以通过该文件来配置默认的启动级别：1$ sudo vi /etc/inittab 找到如下行：1id:5:initdefault: 并修改为：1id:3:initdefault: 注意：以上方法适用于CentOS 7之前的系统，在CentOS 7中/etc/inittab文件已不再使用：123456789101112131415161718$ cat /etc/inittab# inittab is no longer used when using systemd.## ADDING CONFIGURATION HERE WILL HAVE NO EFFECT ON YOUR SYSTEM.## Ctrl-Alt-Delete is handled by /usr/lib/systemd/system/ctrl-alt-del.target## systemd uses &apos;targets&apos; instead of runlevels. By default, there are two main targets:## multi-user.target: analogous to runlevel 3# graphical.target: analogous to runlevel 5## To view current default target, run:# systemctl get-default## To set a default target, run:# systemctl set-default TARGET.target# 根据该文件提示，查看当前启动模式：12$ systemctl get-defaultgraphical.target 修改默认启动级别：1systemctl set-default multi-user.target 输入密码完成修改。重启后，系统默认将以级别3启动。","tags":[{"name":"Linux","slug":"Linux","permalink":"http://likernel.github.io/tags/Linux/"}]},{"title":"su和su -的区别","date":"2017-08-30T21:56:21.000Z","path":"2017/08/31/su和su-的区别/","text":"本文主要介绍一下，su和su -的区别。 #su命令实例当不加任何参数执行su命令时，表示要切换到root用户，但这样执行，会遇到一些问题。因为虽然是切换到root用户了，但并没有改变为root用户登录环境，用户默认的登录环境，可以在/etc/passwd 中查得到，包括家目录，shell类型等。比较规范的操作方法是“su -“，见下面的实例。 实例：由普通用户likernel切换到root用户 使用su： 可以看到，如果使用su而不加上“-”这个参数，那么，切换前的用户的相关信息还会存在，这会引起很多麻烦，甚至会出现意想不到的结果。因此，切换用户时，最好是 “su - 用户名”。这是生产场景中标准的切换用户的操作方法。 使用su -： 这次和上次就不同了，所有的环境变量信息都切换到了root下。因此，请大家在切换用户时一定要加上“su - 用户名”。注意，不光是切到root，切换到其他用户也是一样。 #su命令总结： 1）普通用户切换到root用户，可使用su -或su - root。必须输入root密码才能完成切换。 2）root用户切换到普通用户，可使用“su - 普通用户名”的写法。不需要输入任何密码就能完成切换。切换到普通用户后，在执行一些命令如ifconfig时，可能会遭遇到环境变量PATH路径问题而找不到某些系统命令（一般是/sbin，/usr/sbin等下面的命令），这时就需要将普通用户的PATH，配置成root的PATH内容。 3）如果仅希望在某用户下执行命令，而不直接切换到该用户下操作，可以使用 su - 用户名 -c “命令”的方式。","tags":[{"name":"Linux","slug":"Linux","permalink":"http://likernel.github.io/tags/Linux/"}]},{"title":"Leetcode--Reverse Linked List","date":"2017-08-23T00:06:53.000Z","path":"2017/08/23/Leetcode-Reverse-Linked-List/","text":"翻转单链表。链表的操作，关键就在指针。当然使用栈很容易实现，但是我们有更好的方法，就是借助三个指针。 pre：当前元素的前一个元素的指针cur：当前元素的指针nextp：当前元素的下一个元素的指针 实现：1234567891011121314151617181920212223# Definition for singly-linked list.# class ListNode(object):# def __init__(self, x):# self.val = x# self.next = Noneclass Solution(object): def reverseList(self, head): \"\"\" :type head: ListNode :rtype: ListNode \"\"\" pre = None cur = head while cur != None: nextp = cur.next cur.next = pre #翻转操作 pre = cur cur = nextp return pre","tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://likernel.github.io/tags/leetcode/"},{"name":"算法","slug":"算法","permalink":"http://likernel.github.io/tags/算法/"},{"name":"链表","slug":"链表","permalink":"http://likernel.github.io/tags/链表/"}]},{"title":"Python读取文件","date":"2017-08-21T06:58:16.000Z","path":"2017/08/21/Python读取文件/","text":"python中读取文件常用的三种方法：read(),readline(),readlines()。在做笔试题的时候被这个东西卡了半天，遂总结一下。假设a.txt的内容如下所示：123This is line1.This is line2.This is line3. #read()语法如下：1read([size]) 从文件当前位置起读取size个字节，若无参数size，则表示读取至文件结束为止，它范围为字符串对象。12345f = open(\"a.txt\")lines = f.read()print linesprint(type(lines))f.close() 输出结果：1234This is line1.This is line2.This is line3.&lt;type 'str'&gt; #字符串类型 readline()该方法每次读出一行内容，所以，读取时占用内存小，比较适合大文件，该方法返回一个字符串对象。1234567f = open(\"a.txt\")line = f.readline()print(type(line))while line: print line, line = f.readline()f.close() 输出结果：1234&lt;type 'str'&gt;This is line1.This is line2.This is line3. #readlines()读取整个文件所有行，保存在一个列表(list)变量中，每行作为一个元素，但读取大文件会比较占内存。f = open(“a.txt”)lines = f.readlines()print(type(lines))for line in lines: print line，f.close()输出结果：1234&lt;type 'list'&gt;This is line1.This is line2.This is line3.","tags":[{"name":"python","slug":"python","permalink":"http://likernel.github.io/tags/python/"}]},{"title":"Python函数式编程","date":"2017-08-17T03:15:34.000Z","path":"2017/08/17/Python函数式编程/","text":"本文主要介绍一下Python函数式编程的基本概念。 命令式编程首先从大家熟悉的命令式编程开始，我们先回顾下平时在写代码时主要的情景。 其实，不管我们的业务代码有多复杂，都离不开以下几类操作：1231.函数定义：def2.条件控制：if, elif, else3.循环控制：for, break, continue, while 当然，这只是部分操作类型，除此之外还应该有类和模块、异常处理等等。但考虑到是入门，我们就先只关注上面这三种最常见的操作。 函数式编程对应地，函数式编程也有自己的关键字。在Python语言中，用于函数式编程的主要由3个基本函数和1个算子。121.基本函数：map()、reduce()、filter()2.算子(operator)：lambda 令人惊讶的是，仅仅采用这几个函数和算子就基本上可以实现任意Python程序。 当然，能实现是一回事儿，实际编码时是否这么写又是另外一回事儿。估计要真只采用这几个基本单元来写所有代码的话，不管是在表达上还是在阅读上应该都挺别扭的。不过，尝试采用这几个基本单元来替代上述的函数定义、条件控制、循环控制等操作，对理解函数式编程如何通过函数和递归表达流程控制应该会很有帮助。 替换条件控制语句在对条件控制进行替换之前，我们先来回顾下Python中对布尔表达式求值时进行的“短路”处理。 什么叫“短路”处理？简单地讲，就是如下两点： 1.在f(x) and g(y)中，当f(x)为false时，不会再执行g(y)，直接返回false2.在f(x) or g(y)中，当f(x)为true时，不会再执行g(y)，直接返回true结论是显然易现的，就不再过多解释。 那么，对应到条件控制语句，我们不难理解，如下条件控制语句和表达式是等价的。1234# flow control statementif &lt;cond1&gt;: func1()elif &lt;cond2&gt;: func2()else: func3() 12# Equivalent \"short circuit\" expression(&lt;cond1&gt; and func1()) or (&lt;cond2&gt; and func2()) or (func3()) 通过这个等价替换，我们就去除掉了if/elif/else关键词，将条件控制语句转换为一个表达式。而lambda算子返回的就是一个表达式。 基于这一点，我们就可以采用lambda创建如下函数。12345678910&gt;&gt;&gt; pr = lambda s:s&gt;&gt;&gt; print_num = lambda x: (x==1 and pr(\"one\")).... or (x==2 and pr(\"two\")).... or (pr(\"other\"))&gt;&gt;&gt; print_num(1)'one'&gt;&gt;&gt; print_num(2)'two'&gt;&gt;&gt; print_num(3)'other' 通过函数调用的结果可以看到，以上函数实现的功能与之前的条件控制语句实现的功能完全相同。 到这里，我们就实现了命令式条件控制语句向函数式语句的转换。并且这个转换的方法是通用的，所有条件控制语句都可以采用这种方式转换为函数式语句。 替换循环控制语句接下来我们再看循环控制语句的转换。在Python中，循环控制是通过for和while这两种方式实现的。 ##替换for循环 for循环语句的替换十分简单，采用map()函数就能轻松实现。这主要是因为for语句和map()原理相同，都是对可迭代对象里面的每一个元素进行操作，因此转换过程比较自然。12345# statement-based for loopfor e in lst: func(e)# Equivalent map()-based loopmap(func, lst) 12345678910&gt;&gt;&gt; square = lambda x : x * x&gt;&gt;&gt; for x in [1,2,3,4,5]: square(x)...1491625&gt;&gt;&gt; map(square, [1,2,3,4,5])[1, 4, 9, 16, 25] 替换while循环while循环语句的替换相比而言就复杂了许多。 下面分别是while循环语句及其对应的函数式风格的代码。12345678910111213141516171819# statement-based while loopwhile &lt;condition&gt;: &lt;pre-suite&gt; if &lt;break_condition&gt;: break else: &lt;suite&gt;# Equivalent FP-style recursive while loopdef while_block(): &lt;pre-suite&gt; if &lt;break_condition&gt;: return 1 else: &lt;suite&gt; return 0while_FP = lambda: &lt;condition&gt; and (while_block() or while_FP())while_FP() 这里的难点在于，函数式while_FP循环采用了递归的概念。当为true时，进入循环体，执行while_block()；若为true时，返回1，while_FP()调用结束；若为false时，返回0，会继续执行or右侧的while_FP()，从而实现递归调用；若始终为false，则会持续递归调用while_FP()，这就实现了while语句中同样的功能。 为了对函数式的while循环有更深刻的理解，可以再看下如下示例。这个例子是在网上找的，实现的是echo功能：输入任意非”quit”字符时，打印输入的字符；输入”quit”字符时，退出程序。123456789101112➜ PythonFP python pyecho.pyIMP -- 11IMP -- 22IMP -- abcabcIMP -- 1 + 11 + 1IMP -- quitquit➜ PythonFP 如下便是分别采用过程式和函数式语句实现的”echo”功能。123456789# imperative version of \"echo()\"def echo_IMP(): while 1: x = raw_input(\"IMP -- \") print x if x == 'quit': breakecho_IMP() 1234567def monadic_print(x): print x return x# FP version of \"echo()\"echo_FP = lambda: monadic_print(raw_input(\"FP -- \"))=='quit' or echo_FP()echo_FP() 参考资料[^1]: (Python的函数式编程，从入门到放弃)","tags":[{"name":"python","slug":"python","permalink":"http://likernel.github.io/tags/python/"}]},{"title":"filter()","date":"2017-08-17T03:06:00.000Z","path":"2017/08/17/filter/","text":"Python内建的filter()函数用于过滤序列。和map()类似，filter()也接收一个函数和一个序列。和map()不同的时，filter()把传入的函数依次作用于每个元素，然后根据返回值是True还是False决定保留还是丢弃该元素。 例如，在一个list中，删掉偶数，只保留奇数，可以这么写：12345def is_odd(n): return n % 2 == 1filter(is_odd, [1, 2, 4, 5, 6, 9, 10, 15])# 结果: [1, 5, 9, 15] 把一个序列中的空字符串删掉，可以这么写：12345def not_empty(s): return s and s.strip()filter(not_empty, ['A', '', 'B', None, 'C', ' '])# 结果: ['A', 'B', 'C'] 可见用filter()这个高阶函数，关键在于正确实现一个“筛选”函数。","tags":[{"name":"python","slug":"python","permalink":"http://likernel.github.io/tags/python/"}]},{"title":"map() and reduce()","date":"2017-08-17T02:48:44.000Z","path":"2017/08/17/map-and-reduce/","text":"Python内建了map()和reduce()函数。 map()map()函数的常见调用形式如下所示：1map(func, iterable) map()需要两个必填参数，第一个参数是一个函数名，第二个参数是一个可迭代的对象，如列表、元组等。 map()实现的功能很简单，就是将第二个参数（iterable）中的每一个元素分别传给第一个参数（func），依次执行函数得到结果，并将结果组成一个新的list对象后进行返回。返回结果永远都是一个list。 简单示例如下：123&gt;&gt;&gt; double_func = lambda s : s * 2&gt;&gt;&gt; map(double_func, [1,2,3,4,5])[2, 4, 6, 8, 10] 除了传入一个可迭代对象这种常见的模式外，map()还支持传入多个可迭代对象。1map(func, iterable1, iterable2) 在传入多个可迭代对象的情况下，map()会依次从所有可迭代对象中依次取一个元素，组成一个元组列表，然后将元组依次传给func；若可迭代对象的长度不一致，则会以None进行补上。 通过以下示例应该就比较容易理解。1234567&gt;&gt;&gt; plus = lambda x,y : (x or 0) + (y or 0)&gt;&gt;&gt; map(plus, [1,2,3], [4,5,6])[5, 7, 9]&gt;&gt;&gt; map(plus, [1,2,3,4], [4,5,6])[5, 7, 9, 4]&gt;&gt;&gt; map(plus, [1,2,3], [4,5,6,7])[5, 7, 9, 7] 在上面的例子中，之所以采用x or 0的形式，是为了防止None + int出现异常。 需要注意的是，可迭代对象的个数应该与func的参数个数一致，否则就会出现异常，因为传参个数与函数参数个数不一致了，这个应该比较好理解。12345&gt;&gt;&gt; plus = lambda x,y : x + y&gt;&gt;&gt; map(plus, [1,2,3])Traceback (most recent call last): File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;TypeError: &lt;lambda&gt;() takes exactly 2 arguments (1 given) 另外，map()还存在一种特殊情况，就是func为None。这个时候，map()仍然是从所有可迭代对象中依次取一个元素，组成一个元组列表，然后将这个元组列表作为结果进行返回。12345678&gt;&gt;&gt; map(None, [1,2,3,4])[1, 2, 3, 4]&gt;&gt;&gt; map(None, [1,2,3,4], [5,6,7,8])[(1, 5), (2, 6), (3, 7), (4, 8)]&gt;&gt;&gt; map(None, [1,2,3,4], [5,6,7])[(1, 5), (2, 6), (3, 7), (4, None)]&gt;&gt;&gt; map(None, [1,2,3,4], [6,7,8,9], [11,12])[(1, 6, 11), (2, 7, 12), (3, 8, None), (4, 9, None)] reduce()reduce()函数的调用形式如下所示：1reduce(func, iterable[, initializer]) reduce()函数的功能是对可迭代对象（iterable）中的元素从左到右进行累计运算，最终得到一个数值。第三个参数initializer是初始数值，可以空置，空置为None时就从可迭代对象（iterable）的第二个元素开始，并将第一个元素作为之前的结果。 看下reduce()的例子：1234567891011def reduce(function, iterable, initializer=None): it = iter(iterable) if initializer is None: try: initializer = next(it) except StopIteration: raise TypeError('reduce() of empty sequence with no initial value') accum_value = initializer for x in it: accum_value = function(accum_value, x) return accum_value 再加上如下示例，对reduce()的功能应该就能掌握了。12345&gt;&gt;&gt; plus = lambda x, y : x + y&gt;&gt;&gt; reduce(plus, [1,2,3,4,5])15&gt;&gt;&gt; reduce(plus, [1,2,3,4,5], 10)25 配合map()，我们就可以写出把str转换为int的函数：12345678&gt;&gt;&gt; def fn(x, y):... return x * 10 + y...&gt;&gt;&gt; def char2num(s):... return &#123;'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9&#125;[s]...&gt;&gt;&gt; reduce(fn, map(char2num, '13579'))13579 整理成一个str2int的函数就是：123456def str2int(s): def fn(x, y): return x * 10 + y def char2num(s): return &#123;'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9&#125;[s] return reduce(fn, map(char2num, s)) 还可以用lambda函数进一步简化成：12345def char2num(s): return &#123;'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9&#125;[s]def str2int(s): return reduce(lambda x,y: x*10+y, map(char2num, s)) 也就是说，假设Python没有提供int()函数，你完全可以自己写一个把字符串转化为整数的函数，而且只需要几行代码！","tags":[{"name":"python","slug":"python","permalink":"http://likernel.github.io/tags/python/"}]},{"title":"Python协程","date":"2017-08-17T02:22:10.000Z","path":"2017/08/17/Python协程/","text":"协程，又称微线程，纤程。英文名Coroutine。子程序，或者称为函数，在所有语言中都是层级调用，比如A调用B，B在执行过程中又调用了C，C执行完毕返回，B执行完毕返回，最后是A执行完毕。 所以子程序调用是通过栈实现的，一个线程就是执行一个子程序。 子程序调用总是一个入口，一次返回，调用顺序是明确的。而协程的调用和子程序不同。 协程看上去也是子程序，但执行过程中，在子程序内部可中断，然后转而执行别的子程序，在适当的时候再返回来接着执行。 注意，在一个子程序中中断，去执行其他子程序，不是函数调用，有点类似CPU的中断。比如子程序A、B：123456789def A(): print '1' print '2' print '3'def B(): print 'x' print 'y' print 'z' 假设由协程执行，在执行A的过程中，可以随时中断，去执行B，B也可能在执行过程中中断再去执行A，结果可能是：12345612xy3z 但是在A中是没有调用B的，所以协程的调用比函数调用理解起来要难一些。 看起来A、B的执行有点像多线程，但协程的特点在于是一个线程执行，那和多线程比，协程有何优势？ 最大的优势就是协程极高的执行效率。因为子程序切换不是线程切换，而是由程序自身控制，因此，没有线程切换的开销，和多线程比，线程数量越多，协程的性能优势就越明显。 第二大优势就是不需要多线程的锁机制，因为只有一个线程，也不存在同时写变量冲突，在协程中控制共享资源不加锁，只需要判断状态就好了，所以执行效率比多线程高很多。 因为协程是一个线程执行，那怎么利用多核CPU呢？最简单的方法是多进程+协程，既充分利用多核，又充分发挥协程的高效率，可获得极高的性能。 Python对协程的支持还非常有限，用在generator中的yield可以一定程度上实现协程。虽然支持不完全，但已经可以发挥相当大的威力了。 来看例子： 传统的生产者-消费者模型是一个线程写消息，一个线程取消息，通过锁机制控制队列和等待，但一不小心就可能死锁。 如果改用协程，生产者生产消息后，直接通过yield跳转到消费者开始执行，待消费者执行完毕后，切换回生产者继续生产，效率极高：12345678910111213141516171819202122232425import timedef consumer(): r = '' while True: n = yield r if not n: return print('[CONSUMER] Consuming %s...' % n) time.sleep(1) r = '200 OK'def produce(c): c.next() n = 0 while n &lt; 5: n = n + 1 print('[PRODUCER] Producing %s...' % n) r = c.send(n) print('[PRODUCER] Consumer return: %s' % r) c.close()if __name__=='__main__': c = consumer() produce(c) 执行结果：123456789101112131415[PRODUCER] Producing 1...[CONSUMER] Consuming 1...[PRODUCER] Consumer return: 200 OK[PRODUCER] Producing 2...[CONSUMER] Consuming 2...[PRODUCER] Consumer return: 200 OK[PRODUCER] Producing 3...[CONSUMER] Consuming 3...[PRODUCER] Consumer return: 200 OK[PRODUCER] Producing 4...[CONSUMER] Consuming 4...[PRODUCER] Consumer return: 200 OK[PRODUCER] Producing 5...[CONSUMER] Consuming 5...[PRODUCER] Consumer return: 200 OK 注意到consumer函数是一个generator（生成器），把一个consumer传入produce后：首先调用c.next()启动生成器；然后，一旦生产了东西，通过c.send(n)切换到consumer执行；consumer通过yield拿到消息，处理，又通过yield把结果传回；produce拿到consumer处理的结果，继续生产下一条消息；produce决定不生产了，通过c.close()关闭consumer，整个过程结束。 整个流程无锁，由一个线程执行，produce和consumer协作完成任务，所以称为“协程”，而非线程的抢占式多任务。 最后套用Donald Knuth的一句话总结协程的特点： “子程序就是协程的一种特例。”","tags":[{"name":"python","slug":"python","permalink":"http://likernel.github.io/tags/python/"}]},{"title":"Python切片","date":"2017-08-17T01:13:59.000Z","path":"2017/08/17/Python切片/","text":"本文主要介绍一下Python切片。取一个list或tuple的部分元素是非常常见的操作。Python提供了切片（Slice）操作符，能大大简化这种操作。例子:1&gt;&gt;&gt; L = ['Michael', 'Sarah', 'Tracy', 'Bob', 'Jack'] 取前3个元素：12&gt;&gt;&gt; L[0:3]['Michael', 'Sarah', 'Tracy'] L[0:3]表示，从索引0开始取，直到索引3为止，但不包括索引3。即索引0，1，2，正好是3个元素。 如果第一个索引是0，还可以省略：12&gt;&gt;&gt; L[:3]['Michael', 'Sarah', 'Tracy'] 也可以从索引1开始，取出2个元素出来：12&gt;&gt;&gt; L[1:3]['Sarah', 'Tracy'] 类似的，既然Python支持L[-1]取倒数第一个元素，那么它同样支持倒数切片，试试：1234&gt;&gt;&gt; L[-2:]['Bob', 'Jack']&gt;&gt;&gt; L[-2:-1]['Bob'] 记住倒数第一个元素的索引是-1。 切片操作十分有用。我们先创建一个0-99的数列：123&gt;&gt;&gt; L = range(100)&gt;&gt;&gt; L[0, 1, 2, 3, ..., 99] 可以通过切片轻松取出某一段数列。比如前10个数：12&gt;&gt;&gt; L[:10][0, 1, 2, 3, 4, 5, 6, 7, 8, 9] 后10个数：12&gt;&gt;&gt; L[-10:][90, 91, 92, 93, 94, 95, 96, 97, 98, 99] 前11-20个数：12&gt;&gt;&gt; L[10:20][10, 11, 12, 13, 14, 15, 16, 17, 18, 19] 前10个数，每两个取一个：12&gt;&gt;&gt; L[:10:2][0, 2, 4, 6, 8] 所有数，每5个取一个：12&gt;&gt;&gt; L[::5][0, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95] 甚至什么都不写，只写[:]就可以原样复制一个list：12&gt;&gt;&gt; L[:][0, 1, 2, 3, ..., 99] tuple也是一种list，唯一区别是tuple不可变。因此，tuple也可以用切片操作，只是操作的结果仍是tuple：12&gt;&gt;&gt; (0, 1, 2, 3, 4, 5)[:3](0, 1, 2) 字符串’xxx’或Unicode字符串u’xxx’也可以看成是一种list，每个元素就是一个字符。因此，字符串也可以用切片操作，只是操作结果仍是字符串：1234&gt;&gt;&gt; 'ABCDEFG'[:3]'ABC'&gt;&gt;&gt; 'ABCDEFG'[::2]'ACEG' 在很多编程语言中，针对字符串提供了很多各种截取函数，其实目的就是对字符串切片。Python没有针对字符串的截取函数，只需要切片一个操作就可以完成，非常简单。 小结有了切片操作，很多地方循环就不再需要了。Python的切片非常灵活，一行代码就可以实现很多行循环才能完成的操作。","tags":[{"name":"python","slug":"python","permalink":"http://likernel.github.io/tags/python/"}]},{"title":"ThreadLocal","date":"2017-08-17T00:56:02.000Z","path":"2017/08/17/ThreadLocal/","text":"在多线程环境下，每个线程都有自己的数据。一个线程使用自己的局部变量比使用全局变量好，因为局部变量只有线程自己能看见，不会影响其他线程，而全局变量的修改必须加锁。但是局部变量也有问题，就是在函数调用的时候，传递起来很麻烦：12345678910111213def process_student(name): std = Student(name) # std是局部变量，但是每个函数都要用它，因此必须传进去： do_task_1(std) do_task_2(std)def do_task_1(std): do_subtask_1(std) do_subtask_2(std)def do_task_2(std): do_subtask_2(std) do_subtask_2(std) 每个函数一层一层调用都这么传参数那还得了？用全局变量？也不行，因为每个线程处理不同的Student对象，不能共享。 如果用一个全局dict存放所有的Student对象，然后以thread自身作为key获得线程对应的Student对象如何？123456789101112131415161718global_dict = &#123;&#125;def std_thread(name): std = Student(name) # 把std放到全局变量global_dict中： global_dict[threading.current_thread()] = std do_task_1() do_task_2()def do_task_1(): # 不传入std，而是根据当前线程查找： std = global_dict[threading.current_thread()] ...def do_task_2(): # 任何函数都可以查找出当前线程的std变量： std = global_dict[threading.current_thread()] ... 这种方式理论上是可行的，它最大的优点是消除了std对象在每层函数中的传递问题，但是，每个函数获取std的代码有点丑。 有没有更简单的方式？ThreadLocal应运而生，不用查找dict，ThreadLocal帮你自动做这件事。 ThreadLocal12345678910111213141516171819import threading# 创建全局ThreadLocal对象:local_school = threading.local()def process_student(): print 'Hello, %s (in %s)' % (local_school.student, threading.current_thread().name)def process_thread(name): # 绑定ThreadLocal的student: local_school.student = name process_student()t1 = threading.Thread(target= process_thread, args=('Alice',), name='Thread-A')t2 = threading.Thread(target= process_thread, args=('Bob',), name='Thread-B')t1.start()t2.start()t1.join()t2.join() 执行结果：12Hello, Alice (in Thread-A)Hello, Bob (in Thread-B) 全局变量local_school就是一个ThreadLocal对象，每个Thread对它都可以读写student属性，但互不影响。你可以把local_school看成全局变量，但每个属性如local_school.student都是线程的局部变量，可以任意读写而互不干扰，也不用管理锁的问题，ThreadLocal内部会处理。 可以理解为全局变量local_school是一个dict，不但可以用local_school.student，还可以绑定其他变量，如local_school.teacher等等。 ThreadLocal最常用的地方就是为每个线程绑定一个数据库连接，HTTP请求，用户身份信息等，这样一个线程的所有调用到的处理函数都可以非常方便地访问这些资源。 参考资料","tags":[{"name":"python","slug":"python","permalink":"http://likernel.github.io/tags/python/"}]},{"title":"Python线程","date":"2017-08-16T21:32:13.000Z","path":"2017/08/17/Python线程/","text":"多任务可以由多进程完成，也可以由一个进程内的多线程完成。我们前面提到了进程是由若干线程组成的，一个进程至少有一个线程。由于线程是操作系统直接支持的执行单元，因此，高级语言通常都内置多线程的支持，Python也不例外，并且，Python的线程是真正的Posix Thread，而不是模拟出来的线程。 Python的标准库提供了两个模块：thread和threading，thread是低级模块，threading是高级模块，对thread进行了封装。绝大多数情况下，我们只需要使用threading这个高级模块。 threading启动一个线程就是把一个函数传入并创建Thread实例，然后调用start()开始执行：1234567891011121314151617import time, threading# 新线程执行的代码:def loop(): print 'thread %s is running...' % threading.current_thread().name n = 0 while n &lt; 5: n = n + 1 print 'thread %s &gt;&gt;&gt; %s' % (threading.current_thread().name, n) time.sleep(1) print 'thread %s ended.' % threading.current_thread().nameprint 'thread %s is running...' % threading.current_thread().namet = threading.Thread(target=loop, name='LoopThread')t.start()t.join()print 'thread %s ended.' % threading.current_thread().name 执行结果：123456789thread MainThread is running...thread LoopThread is running...thread LoopThread &gt;&gt;&gt; 1thread LoopThread &gt;&gt;&gt; 2thread LoopThread &gt;&gt;&gt; 3thread LoopThread &gt;&gt;&gt; 4thread LoopThread &gt;&gt;&gt; 5thread LoopThread ended.thread MainThread ended. 由于任何进程默认就会启动一个线程，我们把该线程称为主线程，主线程又可以启动新的线程，Python的threading模块有个current_thread()函数，它永远返回当前线程的实例。 主线程实例的名字叫MainThread，子线程的名字在创建时指定，我们用LoopThread命名子线程。名字仅仅在打印时用来显示，完全没有其他意义，如果不起名字Python就自动给线程命名为Thread-1，Thread-2…… Lock多线程和多进程最大的不同在于，多进程中，同一个变量，各自有一份拷贝存在于每个进程中，互不影响，而多线程中，所有变量都由所有线程共享，所以，任何一个变量都可以被任何一个线程修改，因此，线程之间共享数据最大的危险在于多个线程同时改一个变量，把内容给改乱了。 来看看多个线程同时操作一个变量怎么把内容给改乱了：12345678910111213141516171819202122import time, threading# 假定这是你的银行存款:balance = 0def change_it(n): # 先存后取，结果应该为0: global balance balance = balance + n balance = balance - ndef run_thread(n): for i in range(100000): change_it(n)t1 = threading.Thread(target=run_thread, args=(5,))t2 = threading.Thread(target=run_thread, args=(8,))t1.start()t2.start()t1.join()t2.join()print balance 我们定义了一个共享变量balance，初始值为0，并且启动两个线程，先存后取，理论上结果应该为0，但是，由于线程的调度是由操作系统决定的，当t1、t2交替执行时，只要循环次数足够多，balance的结果就不一定是0了。 原因是因为高级语言的一条语句在CPU执行时是若干条语句，即使一个简单的计算：1balance = balance + n 也分两步： 1.计算balance + n，存入临时变量中；2.将临时变量的值赋给balance。 也就是可以看成：12x = balance + nbalance = x 由于x是局部变量，两个线程各自都有自己的x，当代码正常执行时：12345678910111213初始值 balance = 0t1: x1 = balance + 5 # x1 = 0 + 5 = 5t1: balance = x1 # balance = 5t1: x1 = balance - 5 # x1 = 5 - 5 = 0t1: balance = x1 # balance = 0t2: x2 = balance + 8 # x2 = 0 + 8 = 8t2: balance = x2 # balance = 8t2: x2 = balance - 8 # x2 = 8 - 8 = 0t2: balance = x2 # balance = 0结果 balance = 0 但是t1和t2是交替运行的，如果操作系统以下面的顺序执行t1、t2：123456789101112131415初始值 balance = 0t1: x1 = balance + 5 # x1 = 0 + 5 = 5t2: x2 = balance + 8 # x2 = 0 + 8 = 8t2: balance = x2 # balance = 8t1: balance = x1 # balance = 5t1: x1 = balance - 5 # x1 = 5 - 5 = 0t1: balance = x1 # balance = 0t2: x2 = balance - 5 # x2 = 0 - 5 = -5t2: balance = x2 # balance = -5结果 balance = -5 究其原因，是因为修改balance需要多条语句，而执行这几条语句时，线程可能中断，从而导致多个线程把同一个对象的内容改乱了。 两个线程同时一存一取，就可能导致余额不对，你肯定不希望你的银行存款莫名其妙地变成了负数，所以，我们必须确保一个线程在修改balance的时候，别的线程一定不能改。 如果我们要确保balance计算正确，就要给change_it()上一把锁，当某个线程开始执行change_it()时，我们说，该线程因为获得了锁，因此其他线程不能同时执行change_it()，只能等待，直到锁被释放后，获得该锁以后才能改。由于锁只有一个，无论多少线程，同一时刻最多只有一个线程持有该锁，所以，不会造成修改的冲突。创建一个锁就是通过threading.Lock()来实现：12345678910111213balance = 0lock = threading.Lock()def run_thread(n): for i in range(100000): # 先要获取锁: lock.acquire() try: # 放心地改吧: change_it(n) finally: # 改完了一定要释放锁: lock.release() 当多个线程同时执行lock.acquire()时，只有一个线程能成功地获取锁，然后继续执行代码，其他线程就继续等待直到获得锁为止。 获得锁的线程用完后一定要释放锁，否则那些苦苦等待锁的线程将永远等待下去，成为死线程。所以我们用try…finally来确保锁一定会被释放。 锁的好处就是确保了某段关键代码只能由一个线程从头到尾完整地执行，坏处当然也很多，首先是阻止了多线程并发执行，包含锁的某段代码实际上只能以单线程模式执行，效率就大大地下降了。其次，由于可以存在多个锁，不同的线程持有不同的锁，并试图获取对方持有的锁时，可能会造成死锁，导致多个线程全部挂起，既不能执行，也无法结束，只能靠操作系统强制终止。 多核CPU如果写一个死循环的话，我们可以监控到一个死循环线程会100%占用一个CPU。如果有两个死循环线程，在多核CPU中，可以监控到会占用200%的CPU，也就是占用两个CPU核心。正常情况下要想把N核CPU的核心全部跑满，就必须启动N个死循环线程。 试试用Python写个死循环：12345678910import threading, multiprocessingdef loop(): x = 0 while True: x = x ^ 1for i in range(multiprocessing.cpu_count()): t = threading.Thread(target=loop) t.start() 启动与CPU核心数量相同的N个线程，在4核CPU上可以监控到CPU占用率仅有160%，也就是使用不到两核。 即使启动100个线程，使用率也就170%左右，仍然不到两核。 但是用C、C++或Java来改写相同的死循环，直接可以把全部核心跑满，4核就跑到400%，8核就跑到800%，为什么Python不行呢？ 因为Python的线程虽然是真正的线程，但解释器执行代码时，有一个GIL锁：Global Interpreter Lock，任何Python线程执行前，必须先获得GIL锁，然后，每执行100条字节码，解释器就自动释放GIL锁，让别的线程有机会执行。这个GIL全局锁实际上把所有线程的执行代码都给上了锁，所以，多线程在Python中只能交替执行，即使100个线程跑在100核CPU上，也只能用到1个核。 GIL是Python解释器设计的历史遗留问题，通常我们用的解释器是官方实现的CPython，要真正利用多核，除非重写一个不带GIL的解释器。 所以，在Python中，可以使用多线程，但不要指望能有效利用多核。如果一定要通过多线程利用多核，那只能通过C扩展来实现，不过这样就失去了Python简单易用的特点。 不过，也不用过于担心，Python虽然不能利用多线程实现多核任务，但可以通过多进程实现多核任务。多个Python进程有各自独立的GIL锁，互不影响。 #小结 多线程编程，模型复杂，容易发生冲突，必须用锁加以隔离，同时，又要小心死锁的发生。 Python解释器由于设计时有GIL全局锁，导致了多线程无法利用多核。多线程的并发在Python中就是一个美丽的梦。 参考","tags":[{"name":"python","slug":"python","permalink":"http://likernel.github.io/tags/python/"}]},{"title":"Python进程","date":"2017-08-16T21:31:54.000Z","path":"2017/08/17/Python进程/","text":"本文主要介绍和Python进程相关的内容。 forkUnix/Linux操作系统提供了一个fork()系统调用，用来把当前进程（父进程）复制了一份（子进程）。 在Python的os模块封装了常见的系统调用，其中就包括fork，可以在Python程序中轻松创建子进程：12345678import ospid = os.fork()if pid == 0: print(&apos;哈哈1&apos;)else: print(&apos;哈哈2&apos;) 1.程序执行到os.fork()时，操作系统会创建一个新的进程（子进程），然后复制父进程的所有信息到子进程中。2.然后父进程和子进程都会从fork()函数中得到一个返回值，在子进程中这个值一定是0，而父进程中是子进程的 id号。 这样做的理由是，一个父进程可以fork出很多子进程，所以，父进程要记下每个子进程的ID，而子进程只需要调用getppid()就可以拿到父进程的ID。 123456789101112import osrpid = os.fork()if rpid&lt;0: print(\"fork调用失败。\")elif rpid == 0: print(\"我是子进程（%s），我的父进程是（%s）\"%(os.getpid(),os.getppid())) x+=1else: print(\"我是父进程（%s），我的子进程是（%s）\"%(os.getpid(),rpid))print(\"父子进程都可以执行这里的代码\") 结果：1234我是父进程（19360），我的子进程是（19361）父子进程都可以执行这里的代码我是子进程（19361），我的父进程是（19360）父子进程都可以执行这里的代码 由于Windows没有fork调用，上面的代码在Windows上无法运行，这样显然不适合这种跨平台的开发，因此，Python提供一个multiprocessing模块来支持跨平台的多进程。 multiprocessingpython中的多线程其实并不是真正的多线程，如果想要充分地使用多核CPU的资源，在python中大部分情况需要使用多进程。Python提供了非常好用的多进程包multiprocessing，只需要定义一个函数，Python会完成其他所有事情。借助这个包，可以轻松完成从单进程到并发执行的转换。multiprocessing支持子进程、通信和共享数据、执行不同形式的同步，提供了Process、Queue、Pipe、Lock等组件。 ProcessProcess语法结构如下：1Process([group [, target [, name [, args [, kwargs]]]]]) 1.target：表示这个进程实例所调用对象；2.args：表示调用对象的位置参数元组；3.kwargs：表示调用对象的关键字参数字典；4.name：为当前进程实例的别名；5.group：大多数情况下用不到； Process类常用方法：1.is_alive()：判断进程实例是否还在执行；2.join([timeout])：是否等待进程实例执行结束，或等待多少秒；3.start()：启动进程实例（创建子进程）；4.run()：如果没有给定target参数，对这个对象调用start()方法时，就将执行对象中的run()方法；5.terminate()：不管任务是否完成，立即终止； Process类常用属性：1.name：当前进程实例别名，默认为Process-N，N为从1开始递增的整数；2.pid：当前进程实例的PID值； 创建函数并将其作为单个进程1234567891011121314151617181920from multiprocessing import Processimport osfrom time import sleep# 子进程要执行的代码def run_proc(name, age, **kwargs): for i in range(10): print('子进程运行中，name= %s,age=%d ,pid=%d...' % (name, age,os.getpid())) print(kwargs) sleep(0.5)if __name__=='__main__': print('父进程 %d.' % os.getpid()) p = Process(target=run_proc, args=('test',18), kwargs=&#123;\"m\":20&#125;) print('子进程将要执行') p.start() sleep(1) p.terminate() p.join() print('子进程已结束') 结果：1234567父进程 21378.子进程将要执行子进程运行中，name= test,age=18 ,pid=21379...&#123;'m': 20&#125;子进程运行中，name= test,age=18 ,pid=21379...&#123;'m': 20&#125;子进程已结束 创建函数并将其作为多个进程12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152#coding=utf-8from multiprocessing import Processimport timeimport os#两个子进程将会调用的两个方法def worker_1(interval): print(\"worker_1,父进程(%s),当前进程(%s)\"%(os.getppid(),os.getpid())) t_start = time.time() time.sleep(interval) #程序将会被挂起interval秒 t_end = time.time() print(\"worker_1,执行时间为'%0.2f'秒\"%(t_end - t_start))def worker_2(interval): print(\"worker_2,父进程(%s),当前进程(%s)\"%(os.getppid(),os.getpid())) t_start = time.time() time.sleep(interval) t_end = time.time() print(\"worker_2,执行时间为'%0.2f'秒\"%(t_end - t_start))#输出当前程序的IDprint(\"进程ID：%s\"%os.getpid())#创建两个进程对象，target指向这个进程对象要执行的对象名称，#args后面的元组中，是要传递给worker_1方法的参数，#因为worker_1方法就一个interval参数，这里传递一个整数2给它，#如果不指定name参数，默认的进程对象名称为Process-N，N为一个递增的整数p1=Process(target=worker_1,args=(2,))p2=Process(target=worker_2,name=\"dongGe\",args=(1,))#使用\"进程对象名称.start()\"来创建并执行一个子进程，#这两个进程对象在start后，就会分别去执行worker_1和worker_2方法中的内容p1.start()p2.start()#同时父进程仍然往下执行，如果p2进程还在执行，将会返回Trueprint(\"p2.is_alive=%s\"%p2.is_alive())#输出p1和p2进程的别名和pidprint(\"p1.name=%s\"%p1.name)print(\"p1.pid=%s\"%p1.pid)print(\"p2.name=%s\"%p2.name)print(\"p2.pid=%s\"%p2.pid)#join括号中不携带参数，表示父进程在这个位置要等待p1进程执行完成后，#再继续执行下面的语句，一般用于进程间的数据同步，如果不写这一句，#下面的is_alive判断将会是True，在shell（cmd）里面调用这个程序时#可以完整的看到这个过程，大家可以尝试着将下面的这条语句改成p1.join(1)，#因为p2需要2秒以上才可能执行完成，父进程等待1秒很可能不能让p1完全执行完成，#所以下面的print会输出True，即p1仍然在执行p1.join()print(\"p1.is_alive=%s\"%p1.is_alive()) 结果:1234567891011进程ID：19866p2.is_alive=Truep1.name=Process-1p1.pid=19867p2.name=dongGep2.pid=19868worker_1,父进程(19866),当前进程(19867)worker_2,父进程(19866),当前进程(19868)worker_2,执行时间为'1.00'秒worker_1,执行时间为'2.00'秒p1.is_alive=False 将进程定义为类创建新的进程还能够使用类的方式，可以自定义一个类，继承Process类，每次实例化这个类的时候，就等同于实例化一个进程对象，请看下面的实例：123456789101112131415161718192021222324252627282930from multiprocessing import Processimport timeimport os#继承Process类class Process_Class(Process): #因为Process类本身也有__init__方法，这个子类相当于重写了这个方法， #但这样就会带来一个问题，我们并没有完全的初始化一个Process类，所以就不能使用从这个类继承的一些方法和属性， #最好的方法就是将继承类本身传递给Process.__init__方法，完成这些初始化操作 def __init__(self,interval): Process.__init__(self) self.interval = interval #重写了Process类的run()方法 def run(self): print(\"子进程(%s) 开始执行，父进程为（%s）\"%(os.getpid(),os.getppid())) t_start = time.time() time.sleep(self.interval) t_stop = time.time() print(\"(%s)执行结束，耗时%0.2f秒\"%(os.getpid(),t_stop-t_start))if __name__==\"__main__\": t_start = time.time() print(\"当前程序进程(%s)\"%os.getpid()) p1 = Process_Class(2) #对一个不包含target属性的Process类执行start()方法，就会运行这个类中的run()方法，所以这里会执行p1.run() p1.start() p1.join() t_stop = time.time() print(\"(%s)执行结束，耗时%0.2f\"%(os.getpid(),t_stop-t_start)) 进程池Pool当需要创建的子进程数量不多时，可以直接利用multiprocessing中的Process动态成生多个进程，但如果是上百甚至上千个目标，手动的去创建进程的工作量巨大，此时就可以用到multiprocessing模块提供的Pool方法。 初始化Pool时，可以指定一个最大进程数，当有新的请求提交到Pool中时，如果池还没有满，那么就会创建一个新的进程用来执行该请求；但如果池中的进程数已经达到指定的最大值，那么该请求就会等待，直到池中有进程结束，才会创建新的进程来执行，请看下面的实例：123456789101112131415161718192021from multiprocessing import Poolimport os,time,randomdef worker(msg): t_start = time.time() print(\"%s开始执行,进程号为%d\"%(msg,os.getpid())) #random.random()随机生成0~1之间的浮点数 time.sleep(random.random()*2) t_stop = time.time() print(msg,\"执行完毕，耗时%0.2f\"%(t_stop-t_start))po=Pool(3) #定义一个进程池，最大进程数3for i in range(0,10): #Pool.apply_async(要调用的目标,(传递给目标的参数元祖,)) #每次循环将会用空闲出来的子进程去调用目标 po.apply_async(worker,(i,))print(\"----start----\")po.close() #关闭进程池，关闭后po不再接收新的请求po.join() #等待po中所有子进程执行完成，必须放在close语句之后print(\"-----end-----\") 运行结果:12345678910111213141516171819202122----start----0开始执行,进程号为214661开始执行,进程号为214682开始执行,进程号为214670 执行完毕，耗时1.013开始执行,进程号为214662 执行完毕，耗时1.244开始执行,进程号为214673 执行完毕，耗时0.565开始执行,进程号为214661 执行完毕，耗时1.686开始执行,进程号为214684 执行完毕，耗时0.677开始执行,进程号为214675 执行完毕，耗时0.838开始执行,进程号为214666 执行完毕，耗时0.759开始执行,进程号为214687 执行完毕，耗时1.038 执行完毕，耗时1.059 执行完毕，耗时1.69-----end----- Pool常用函数解析：1.apply_async(func[, args[, kwds]])：使用非阻塞方式调用func（并行执行，堵塞方式必须等待上一个进程退出才能执行下一个进程），args为传递给func的参数列表，kwds为传递给func的关键字参数列表；2.apply(func[, args[, kwds]])：使用阻塞方式调用func3.close()：关闭Pool，使其不再接受新的任务；4.terminate()：不管任务是否完成，立即终止；5.join()：主进程阻塞，等待子进程的退出， 必须在close或terminate之后使用； apply堵塞式12345678910111213141516171819from multiprocessing import Poolimport os,time,randomdef worker(msg): t_start = time.time() print(\"%s开始执行,进程号为%d\"%(msg,os.getpid())) #random.random()随机生成0~1之间的浮点数 time.sleep(random.random()*2) t_stop = time.time() print(msg,\"执行完毕，耗时%0.2f\"%(t_stop-t_start))po=Pool(3) #定义一个进程池，最大进程数3for i in range(0,10): po.apply(worker,(i,))print(\"----start----\")po.close() #关闭进程池，关闭后po不再接收新的请求po.join() #等待po中所有子进程执行完成，必须放在close语句之后print(\"-----end-----\") 运行结果:123456789101112131415161718192021220开始执行,进程号为215320 执行完毕，耗时1.911开始执行,进程号为215341 执行完毕，耗时1.722开始执行,进程号为215332 执行完毕，耗时0.503开始执行,进程号为215323 执行完毕，耗时1.274开始执行,进程号为215344 执行完毕，耗时1.055开始执行,进程号为215335 执行完毕，耗时1.606开始执行,进程号为215326 执行完毕，耗时0.257开始执行,进程号为215347 执行完毕，耗时0.638开始执行,进程号为215338 执行完毕，耗时1.219开始执行,进程号为215329 执行完毕，耗时0.60----start---------end----- 进程间通信–QueueProcess之间有时需要通信，操作系统提供了很多机制来实现进程间的通信。 可以使用multiprocessing模块的Queue实现多进程之间的数据传递，Queue本身是一个消息列队程序，首先用一个小实例来演示一下Queue的工作原理：12345678910111213141516171819202122232425262728#coding=utf-8from multiprocessing import Queueq=Queue(3) #初始化一个Queue对象，最多可接收三条put消息q.put(\"消息1\")q.put(\"消息2\")print(q.full()) #Falseq.put(\"消息3\")print(q.full()) #True#因为消息列队已满下面的try都会抛出异常，第一个try会等待2秒后再抛出异常，第二个Try会立刻抛出异常try: q.put(\"消息4\",True,2)except: print(\"消息列队已满，现有消息数量:%s\"%q.qsize())try: q.put_nowait(\"消息4\")except: print(\"消息列队已满，现有消息数量:%s\"%q.qsize())#推荐的方式，先判断消息列队是否已满，再写入if not q.full(): q.put_nowait(\"消息4\")#读取消息时，先判断消息列队是否为空，再读取if not q.empty(): for i in range(q.qsize()): print(q.get_nowait()) 运行结果:1234567FalseTrue消息列队已满，现有消息数量:3消息列队已满，现有消息数量:3消息1消息2消息3 初始化Queue()对象时（例如：q=Queue()），若括号中没有指定最大可接收的消息数量，或数量为负值，那么就代表可接受的消息数量没有上限（直到内存的尽头）；1.Queue.qsize()：返回当前队列包含的消息数量；2.Queue.empty()：如果队列为空，返回True，反之False ；3.Queue.full()：如果队列满了，返回True,反之False；4.Queue.get([block[, timeout]])：获取队列中的一条消息，然后将其从列队中移除，block默认值为True；5.Queue.get_nowait()：相当Queue.get(False)；6.Queue.put(item,[block[, timeout]])：将item消息写入队列，block默认值为True；7.Queue.put_nowait(item)：相当Queue.put(item, False)； ###Queue实例我们以Queue为例，在父进程中创建两个子进程，一个往Queue里写数据，一个从Queue里读数据：1234567891011121314151617181920212223242526272829303132333435from multiprocessing import Process, Queueimport os, time, random# 写数据进程执行的代码:def write(q): for value in ['A', 'B', 'C']: print 'Put %s to queue...' % value q.put(value) time.sleep(random.random())# 读数据进程执行的代码:def read(q): while True: if not q.empty(): value = q.get(True) print 'Get %s from queue.' % value time.sleep(random.random()) else: breakif __name__=='__main__': # 父进程创建Queue，并传给各个子进程： q = Queue() pw = Process(target=write, args=(q,)) pr = Process(target=read, args=(q,)) # 启动子进程pw，写入: pw.start() # 等待pw结束: pw.join() # 启动子进程pr，读取: pr.start() pr.join() # pr进程里是死循环，无法等待其结束，只能强行终止: print '' print '所有数据都写入并且读完' 进程池中的Queue如果要使用Pool创建进程，就需要使用multiprocessing.Manager()中的Queue()，而不是multiprocessing.Queue()，否则会得到一条如下的错误信息： RuntimeError: Queue objects should only be shared between processes through inheritance. 下面的实例演示了进程池中的进程如何通信：1234567891011121314151617181920212223242526#coding=utf-8#修改import中的Queue为Managerfrom multiprocessing import Manager,Poolimport os,time,randomdef reader(q): print(\"reader启动(%s),父进程为(%s)\"%(os.getpid(),os.getppid())) for i in range(q.qsize()): print(\"reader从Queue获取到消息：%s\"%q.get(True))def writer(q): print(\"writer启动(%s),父进程为(%s)\"%(os.getpid(),os.getppid())) for i in \"dongGe\": q.put(i)if __name__==\"__main__\": print(\"(%s) start\"%os.getpid()) q=Manager().Queue() #使用Manager中的Queue来初始化 po=Pool() #使用阻塞模式创建进程，这样就不需要在reader中使用死循环了，可以让writer完全执行完成后，再用reader去读取 po.apply(writer,(q,)) po.apply(reader,(q,)) po.close() po.join() print(\"(%s) End\"%os.getpid()) 运行结果:12345678910(21156) startwriter启动(21162),父进程为(21156)reader启动(21162),父进程为(21156)reader从Queue获取到消息：dreader从Queue获取到消息：oreader从Queue获取到消息：nreader从Queue获取到消息：greader从Queue获取到消息：Greader从Queue获取到消息：e(21156) End","tags":[{"name":"python","slug":"python","permalink":"http://likernel.github.io/tags/python/"}]},{"title":"python实现链表","date":"2017-08-15T03:08:28.000Z","path":"2017/08/15/python实现链表/","text":"之前只是介绍过链表这种数据结构，但是，没有进行详细的讲解，虽然这种数据结构在很多时候，特别是在读取元素的时候，并不是显得很高效，但是仍然值得我们学习，链表问题也是面试中常见的问题，比如：链表的逆置，因此深入的学习这种数据结构很有必要。 链表链表是实现了数据之间保持逻辑顺序，但存储空间不必按顺序的方法。 基本概念1.节点：每一个节点有两个域，左边部份叫值域，用于存放用户数据；右边叫指针域，一般是存储着到下一个元素的指针。2.head节点：head是一个特殊的节点，head节点永远指向第一个节点。3.tail节点：tail节点也是一个特殊的节点，tail节点永远指向最后一个节点。4.None：链表中最后一个节点指针域的指针指向None值。 常用方法：1.LinkedList() 创建空链表，不需要参数，返回值是空链表2.is_empty() 测试链表是否为空，不需要参数，返回值是布尔值3.append(data) 在尾部增加一个元素作为列表最后一个。参数是要追加的元素，无返回值4.iter() 遍历链表，无参数，无返回值，此方法一般是一个生成器5.insert(idx,value) 插入一个元素，参数为插入元素的索引和值6.remove(idx)移除1个元素，参数为要移除的元素或索引，并修改链表7.size() 返回链表的元素数，不需要参数，返回值是个整数8.find(item) 查找链表某元素，参数为要查找的元素或索引，返回是布尔值 #节点类python用类来实现链表的数据结构，节点类中包含两个属性，数据和指针：1234class Node: def __init__(self, data): self.data = data self.next = None 此节点类只有一个构建函数，接收一个数据参数，其中next表示指针域的指针，实例化后得到一个节点对象，如下：1node = Node(4) 备注：此节点对象数据为4，指针指向None。 链表类创建空链表，不需要参数，返回值是空链表：1234class LinkedList: def __init__(self): self.head = None self.tail = None 此类实例后会生成一个链表对象，初始化了head和tail节点，且两节点都指向None，实例化代码如下：1link_list = LinkedList() is_empty方法is_empty方法检查链表是否是一个空链表，这个方法只需要检查head节点是否指向None即可：12def is_empty(self): return self.head is None #append方法append方法表示增加元素到链表，这和insert方法不同，前者使新增加的元素成为链表中第一个节点，而后者是根据索引值来判断插入到链表的哪个位置。代码如下：12345678def append(self, data): node = Node(data) if self.head is None: self.head = node self.tail = node else: self.tail.next = node self.tail = node iter方法实现iter方法用来遍历链表，分两种情况：1.空链表2.遍历链表时从head开始，直到一个节点的next指向None结束，代码如下：12345678def iter(self): if not self.head: return cur = self.head yield cur.data while cur.next: cur = cur.next yield cur.data 备注：使用局部变量cur指向head,把对应的data yield出来，再对cur的next指针指向的对象做while循环，直到next指向None，这样就遍历了链表。 insert方法采用遍历的方式找到需要插入，改变对应的指针域所指的位置：123456789101112131415def insert(self, idx, value): cur = self.head cur_idx = 0 if cur is None: raise Exception('The list is an empty list') while cur_idx &lt; idx-1: cur = cur.next if cur is None: raise Exception('list length less than index') cur_idx += 1 node = Node(value) node.next = cur.next cur.next = node if node.next is None: self.tail = node #remove方法remove方法接收一个idx参数，表示要删除节点的索引，此方法要考虑以下几种情况：1.空链表，直接抛出异常2.删除第一个节点时，移动head到删除节点的next指针指向的对象3.链表只有一个节点时，把head与tail都指向None即可4.删除最后一个节点时，需要移动tail到上一个节点5.遍历链表时要判断给定的索引是否大于链表的长度，如果大于则抛出异常信息123456789101112131415161718192021def remove(self, idx): cur = self.head cur_idx = 0 if self.head is None: # 空链表时 raise Exception('The list is an empty list') while cur_idx &lt; idx-1: cur = cur.next if cur is None: raise Exception('list length less than index') cur_idx += 1 if idx == 0: # 当删除第一个节点时 self.head = cur.next cur = cur.next return if self.head is self.tail: # 当只有一个节点的链表时 self.head = None self.tail = None return cur.next = cur.next.next if cur.next is None: # 当删除的节点是链表最后一个节点时 self.tail = cur size方法size函数不接收参数，返回链表中节点的个数，遍历链表，用一个累加器count来计算节点的个数：123456789def size(self): current = self.head count = 0 if current is None: return 'The list is an empty list' while current is not None: count += 1 current = current.next return count find方法find函数接收一个item参数，表示查找节点中数据域的值。find方法遍历链表，每到一个节点把当前节点的data值与item作比较：123456789def find(self, item): current = self.head found = False while current is not None and not found: if current.data == item: found = True else: current = current.next return found","tags":[{"name":"python","slug":"python","permalink":"http://likernel.github.io/tags/python/"}]},{"title":"并查集","date":"2017-08-14T08:43:10.000Z","path":"2017/08/14/并查集/","text":"并查集（Union-Find）是用于解决动态连通性类问题的一种数据结构。 动态连通性问题动态连通性问题是一个非常基础的计算性问题，而且它在现实世界中的应用很广泛，庞大的电脑网络、数以亿计的社交网络中的人类、数学集合中的元素、计算机程序中的变量、照片中的像素，都会涉及到动态连通性。 1.这类问题的输入是一列整数对，每个整数都表示一个某种类型的对象，一对整数“p q”表示的含义是“p和q相连”。 2.“相连”是一种等价关系1） 自反性（p与p相连接）；2） 对称性（若p连接到q，那么q也连接到p）；3） 传递性（若p连接到q，q连接到r，则p连接到r）。 3.等价关系将对象分成多个等价类，它们构成多个集合，称为“连通组件”（Connected Components）。 并查集对于一组数据，并查集主要支持两个动作，回答一个问题。 动作1.union(p,q)：将p,q连接。2.find(p)：查找p。 问题isConnected(p,q)：检测p,q是否连接并返回布尔值。 举个例子： 我们可以通过union操作，实现上图的连接，形成了两个连通分量，或称为一个组。 实现Quick-Find实现123456789101112131415161718192021id = []count = 0def unionFind(n): count = n for i in xrange(count): id[i] = idef isConnected(p,q): return find(p) == find(q)def find(p): return id[p]def union(p, q): pid = find(p) qid = find(q) for i in xrange(count): if id[i] == pid: id[i] = qid 备注：上面的实现，只给出了每个函数的实现，其中，有一点需要说明，就是id这个数组。初始化时，每个元素都是指向自己，union操作时，循环遍历id数组，将qid指向pid这条链上的最后一个元素。 具体过程如下所示： Quick-Union实现上面的Quick-find实现在规模增大时，会面临性能问题，其主要来源是union操作需要遍历数组，为了改善性能，需要避免执行union操作时遍历数组，Quick-Union实现达到了这一目的。 12345678910111213141516171819202122parent = []count = 0def unionFind(n): count = n for i in xrange(count): parent[i] = idef isConnected(p,q): return find(p) == find(q)def find(p): while p!=parent[p]: p = parent[p] return pdef union(p, q): proot = find(p) qroot = find(q) if proot != qroot: parent[proot] = qroot 具体过程如下所示： Quick-Union优化基于元素个数优化引入一个num[i]，用来记录以i为根的集合中元素个数。1234567num = []def unionFind(n): count = n for i in xrange(count): parent[i] = i num[i] = 1 始终保持元素少的根节点指向元素多的根节点，这样有很大的概率可以维护树的高度增长的不是那么快。1234567891011def union(p, q): proot = find(p) qroot = find(q) if num[proot] &lt; num[qroot]: parent[proot] = qroot num[qroot] += num[proot] else: parent[qroot] = proot num[proot] += num[qroot] 基于rank的优化在上述的优化过程中，只是有很大的概率可以维护树的高度增长的不是那么快。实际上并不准确，更多的时候我们采用的是基于rank的优化。1234567rank = []def unionFind(n): count = n for i in xrange(count): parent[i] = i rank[i] = 1 和上面一种优化相比，区别在于，这里维护的是真正的树的深度，树深小的指向树深大的，只有当相等的时候树深才会加1。1234567891011def union(p, q): proot = find(p) qroot = find(q) if rank[proot] &lt; rank[qroot]: parent[proot] = qroot elif rank[qroot] &lt; rank[proot]: parent[qroot] = proot else: parent[proot] = qroot rank[qroot] += 1 路径压缩（Path Compression）先实现第一种路径压缩优化，实际上只需要对find(p)进行一个修改：12345def find(p): while p!=parent[p]: parent[p] = parent[parent[p]] p = parent[p] return p 具体过程如下： 可以看到，路径的确被压缩了，但是这仍然不是最优的压缩路径，最优的情况下是如下图这种压缩方式： 使用递归实现：1234def find(p): if p!=parent[p]: parent[p] = find(parent[p]) return p 以上内容，便是并查集的内容，后续会更新一些笔面试题目，加深应用和理解。","tags":[{"name":"算法","slug":"算法","permalink":"http://likernel.github.io/tags/算法/"},{"name":"并查集","slug":"并查集","permalink":"http://likernel.github.io/tags/并查集/"}]},{"title":"堆排序","date":"2017-08-14T00:39:38.000Z","path":"2017/08/14/堆排序/","text":"之前介绍了二叉堆的相关内容，这里继续前面的知识，介绍一下Heapify的内容，进而具体介绍另一种O(nlogn)的排序算法–堆排序。 HeapifyMAX-HEAPIFY通过让A[i]的值在最大堆中shift down，从而使得下标i为根结点的子树重新遵循最大堆的性质。 参照《算法导论》给出相应伪码:12345678910111213MAX-HEAPIFY(A, i) l = LEFT(i) r = RIGHT(i) # 找到i，i的左子树的根结点，i的右子树的根结点中值最大的结点 if l &lt;= A.heap-size and A[l] &gt; A[i] largest = l else largest = i if r &lt;= A.heap-size and A[r] &gt; A[largest] largest = r if largest != i exchange A[i] with A[largest] MAX-HEAPIFY(A, largest) 若值最大的结点不是i，则把最大的值跟i指定的值交换。然后继续对原值最大的结点递归进行MAX-HEAPIFY操作，若值最大的结点就是i，说明以i为根结点的子树已是最大堆，函数结束。 ##BUILD-MAX-HEAP构建最大堆，伪码：1234BUILD-MAX-HEAP(A) A.heap-size = A.length for i = A.length/2 downto 1 #自底向上 MAX-HEAPIFY(A, i) HEAPSORT堆排序的实现，伪码：123456HEAPSORT(A) BUILD-MAX-HEAP(A) # 最大元素总是在根结点A[1]中 for i = A.length downto 2 exchange A[1] with A[i] # 将最大元素往后放在正确的位置i上 A.heap-size = A.heap-size - 1 # 去掉结点n MAX-HEAPIFY(A, 1) # 维护，以保证去掉结点n后的堆还是最大堆 堆排序实现思路堆排序的实现思路关键就是上面HEAPIFY操作。 1.首先，构建最大堆2.最大堆的一个性质：最大的元素就是堆顶的元素。我们每次就选择这个元素，这就像选择排序中选择的操作。我们这里不借助中间数组，直接和当前堆尾元素交换。3.使最大元素在尾部不动，前面构成一个堆，维护这个堆，对其进行MAX-HEAPIFY，是前面变成最大堆4.重复上述操作，在堆的规模缩小的同时，完成排序。 具体过程如下图： 实现1234567891011121314151617181920212223242526heap_size = 0left = lambda i: 2*i+1right = lambda i: 2*i+2def Heapify(arr, i): l, r = left(i), right(i) largest = l if l &lt; heap_size and arr[l] &gt; arr[i] else i largest = r if r &lt; heap_size and arr[r] &gt; arr[largest] else largest if i != largest: arr[i], arr[largest] = arr[largest], arr[i] Heapify(arr,largest)def BuildMaxHeap(arr): global heap_size heap_size = len(arr) for i in range(len(arr)//2-1,-1,-1): Heapify(arr,i)def HeapSort(arr): global heap_size BuildMaxHeap(arr) for i in range(len(arr)-1,-1,-1): arr[i], arr[0] = arr[0], arr[i] heap_size -= 1 Heapify(arr,0) return arr 备注：很多情况下都使用arr[0]来维护堆的大小（算法导论中是采用的这种方式），这里为了直接返回排序的数组，并未这样处理，响应的规律也有所改变，但大同小异。","tags":[{"name":"算法","slug":"算法","permalink":"http://likernel.github.io/tags/算法/"},{"name":"排序","slug":"排序","permalink":"http://likernel.github.io/tags/排序/"}]},{"title":"栈和队列","date":"2017-08-14T00:06:37.000Z","path":"2017/08/14/栈和队列/","text":"栈和队列的数据结构和操作，比较简单，这里做一个简单的总结和实现。 #栈满足后进先出(last in first out，LIFO)，在Python中可以用数组在模拟栈的操作。 ##实现1234567891011121314151617181920class Stack(object): def __init__(self): #建栈 self.stack=[] def isEmpty(self): #判空 return self.stack==[] def push(self,item): #压栈 self.stack.append(item) def pop(self): #弹出 if self.isEmpty(): raise IndexError,&apos;pop from empty stack&apos; return self.stack.pop() def peek(self): #返回最顶层的元素，不删除 return self.stack[-1] def size(self): #返回栈中元素的个数 return len(self.stack) #队列满足先进先出(first in first out，FIFO)队列的基本操作是Enqueue(入队)，在表的末端(rear)插入一个元素，还有出列(Dequeue)，删除表开头的元素。其实现也比较容易，同样可以用数组模拟。 ##实现1234567891011121314151617181920class Queue(object): def __init__(self): self.queue=[] def isEmpty(self): return self.queue==[] def enqueue(self,x): #入队 self.queue.append(x) def dequeue(self): #出队 if self.queue: a=self.queue[0] self.queue.remove(a) return a else: raise IndexError,&apos;queue is empty&apos; def size(self): return len(self.queue)","tags":[{"name":"算法","slug":"算法","permalink":"http://likernel.github.io/tags/算法/"},{"name":"数据结构","slug":"数据结构","permalink":"http://likernel.github.io/tags/数据结构/"}]},{"title":"二叉堆","date":"2017-08-13T21:09:20.000Z","path":"2017/08/14/二叉堆/","text":"为了介绍堆排序这种算法，我们先总结一下堆这种数据结构。 优先队列我们都知道队列（Queue）这种先进先出（FIFO）的数据结构。队列还有一种变体叫做“优先队列”（Priority Queue）。 优先队列的出队（Dequeue）操作和队列一样，都是从队首出队。但在优先队列的内部，元素的次序却是由“优先级”来决定：高优先级的元素排在队首，而低优先级的元素则排在后面。这样，优先队列的入队（Enqueue）操作就比较复杂，需要将元素根据优先级尽量排到队列前面。 我们很自然地会想到用之前学的排序算法和队列的方法来实现优先队列。但是，在列表里插入一个元素的时间复杂度是O(n)，对列表进行排序的时间复杂度是O(nlogn)。其实可以用别的方法来降低时间复杂度。一个实现优先队列的经典方法便是采用二叉堆（Binary Heap）。二叉堆能将优先队列的入队和出队复杂度都保持在O(logn)。 二叉堆堆的性质:父节点的键值总是大于或等于（小于或等于）任何一个子节点的键值。 二叉树的性质：除了最底层，该树是完全充满的。而且是从左向右填充。 二叉堆的性质：二叉堆是完全二叉树或者是近似完全二叉树。当父节点的键值大于或等于它的每一个子节点的键值时我们称它为最大堆，反之称之为最小堆。可以看出它兼具堆和二叉树二者的性质。 下图就是一个最大堆： 二叉堆是用数组实现的，我们注意一点，通常为了方便二叉堆的操作，我们在数组的第一个元素a[0]中是不存放堆的元素的，我们习惯从1开始对这个堆进行编号，如下图所示： 我们可以发现这样的规律： 1.PARENT(i)=i/2 2.LEFT(i) = 2*i 3.RIGHT(i) = 2*i+1。 基本操作二叉堆的基本操作中最重要的一点就是，不管如何操作，要随时维护这个堆。最基本的两个操作为：shift up和shift down。 插入在插入操作的时候，会破坏上述堆的性质，所以需要进行shift up的操作，来维护这个堆，实际上就是不停的交换，例如，在上面的最大堆的基础上插入20这个数，具体过程如下： 删除在删除操作的时候，也会破坏上述堆的性质，所以需要进行shift down的操作。删除操作先是待删元素和末尾元素交换，末尾元素依次进行shift down操作，还是上面的例子，具体过程如下： 实现二叉堆123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384# 二叉堆class BinaryHeap(object): # 建堆 def __init__(self): self.item_list = [0] #第0项元素代表堆中存放的实际元素的个数 # 插入 def insert(self, new_item): self.item_list.append(new_item) self.item_list[0] += 1 #记录元素个数的增加 self.shiftup(self.item_list[0]) # shiftup # 向上调整 def shiftup(self, index): while index/2 &gt; 0: #父节点存在 if self.item_list[index] &lt; self.item_list[index/2]: #如果当前节点比父亲节点更小，则交换 temp = self.item_list[index] self.item_list[index] = self.item_list[index/2] self.item_list[index/2] = temp index = index/2 #继续调整 else: #如果当前节点不比父节点小 break #停止调整 # 返回具有最小键值的项，并将项留在堆中。 def get_min(self): if self.item_list[0]&gt;0: #不为空，返回堆顶 return self.item_list[1] else: return None # 返回具有最小键值的项，从堆中删除该项。 def pop_min(self): if self.item_list[0] == 0: #如果为空，返回None return None else: top_min = self.item_list[1] #将堆顶元素 self.item_list[1] = self.item_list[self.item_list[0]] #将最后一个元素移动到堆顶 self.item_list[0] -= 1 self.shiftdown(1) #向下调整 return top_min # 向下调整 def shiftdown(self, index): while 2*index &lt;= self.item_list[0]: #子节点存在 if 2*index+1 &lt;= self.item_list[0]: #左右子节点都存在 if self.item_list[2*index]&lt;self.item_list[2*index+1]: #左子节点更小 if self.item_list[index]&gt;self.item_list[2*index]: #比左子节点更大，交换 temp = self.item_list[index] self.item_list[index] = self.item_list[2*index] self.item_list[2*index] = temp index = 2*index #继续调整 else: #没有比子节点更大，停止调整 break else: #右子节点更小 if self.item_list[index]&gt;self.item_list[2*index+1]: #比右子节点更大，交换 temp = self.item_list[index] self.item_list[index] = self.item_list[2*index+1] self.item_list[2*index+1] = temp index = 2*index+1 #继续调整 else: #没有比子节点更大，停止调整 break else: #只存在左节点 if self.item_list[index]&gt;self.item_list[2*index]: #比左子节点更大，交换 temp = self.item_list[index] self.item_list[index] = self.item_list[2*index] self.item_list[2*index] = temp else: #没有比子节点更大，停止调整 break # 判断是否为空 def isEmpty(self): return 0 == self.item_list[0] # 返回堆中的项数 def size(self): return self.item_list[0] #从列表构建一个新的堆。覆盖掉当前的堆 def build_heap(self, input_list): self.item_list = [0]+input_list self.item_list[0] = len(input_list) for index in range(self.item_list[0]/2, 0, -1): #从最后一个有叶节点的元素起逐个向下调整 self.shiftdown(index)","tags":[{"name":"算法","slug":"算法","permalink":"http://likernel.github.io/tags/算法/"},{"name":"数据结构","slug":"数据结构","permalink":"http://likernel.github.io/tags/数据结构/"}]},{"title":"归并排序","date":"2017-08-13T08:34:31.000Z","path":"2017/08/13/归并排序/","text":"同快速排序一样，也采用的是D&amp;C的策略。时间复杂度也为O(nlogn)。 算法原理归并算法，指的是将两个已经排序的序列合并成一个序列的操作。归并排序算法依赖归并操作。 归并操作的过程1.申请空间，使其大小为两个已经排序序列之和，该空间用来存放合并后的序列。2.设定两个指针，最初位置分别为两个已经排序序列的起始位置。3.比较两个指针所指向的元素，选择相对小的元素放入到合并空间，并移动指针到下一位置。4.重复步骤3直到某一指针达到序列尾5.将另一序列剩下的所有元素直接复制到合并序列尾。 归并排序原理1.将序列每相邻两个数字进行归并操作，形成个序列，排序后每个序列包含两个元素。2.将上述序列再次归并，形成个序列，每个序列包含四个元素。3.重复步骤2，直到所有元素排序完毕。 实现123456789101112131415161718def MergeSort(arr): if len(arr) &lt; 2: return arr return Merge(MergeSort(arr[:len(arr)/2]),MergeSort(arr[len(arr)/2:]))def Merge(left,right): res = [] left = sorted(left) right = sorted(right) while left and right: if left[0] &lt; right[0]: res.append(left.pop(0)) else: res.append(right.pop(0)) return res + left +rightprint MergeSort([6,5,2,3,4,1]) 备注：思考一个问题，返回值为res + left +right，为什么不是res呢？注意，我们之前while循环的条件是left and right，实际上有很多情形下分布不均匀，导致left和right其中有一个为空的情况，因此我们需要把这种情况下，不为空的数组拼接起来。","tags":[{"name":"算法","slug":"算法","permalink":"http://likernel.github.io/tags/算法/"},{"name":"排序","slug":"排序","permalink":"http://likernel.github.io/tags/排序/"}]},{"title":"希尔排序","date":"2017-08-13T06:49:35.000Z","path":"2017/08/13/希尔排序/","text":"通过之前的介绍，我们知道了插入排序的原理。但是，如果一个元素距离它的正确位置非常远，那么我们就要做很多次大小比较，才能找出其正确位置。因此，其设计者希尔（Donald Shell），在插入排序的基础上，提出了一种更高效的改进版本–希尔排序。 算法思想文字描述起来比较复杂，下面直接看实例：假设有数组 array = [80, 93, 60, 12, 42, 30, 68, 85, 10]，先对其进行希尔排序。 1.选择步长step=4(len(arr)/2)，根据步长进行分组（相同颜色代表一组）。 2.每组分别进行插入排序，得到下面的结果。 3.再次选择步长step=2(step/2)，再次分组。 4.分别进行插入排序。 5.step=1(step/2),此时，在最后进行插入排序即可。 备注：同样还是使用插入排序，但是由于在前面的几步分组、排序的过程中，已经把一个可能原来“很无序”的数组，逐步地变成了一个“比较有序”的数组，最后进行微调即可。我们知道一个数组越有序，对其进行插入排序的效率就越高，希尔排序实际上解决的就是如何把可能非常无序的数组通过一系列操作，变得比较有序，这时，再使用插入排序就比较高效了。 注意步长的选择shell算法的性能与所选取的分区长度序列有很大关系。我们通常把步长取半直到步长达到1。 已知的最好步长序列是由Sedgewick提出的(1, 5, 19, 41, 109,…)，该序列的项来自94^i - 9 2^i + 1和2^{i+2} * (2^{i+2} - 3) + 1这两个算式。这项研究也表明“比较在希尔排序中是最主要的操作，而不是交换。”用这样步长序列的希尔排序比插入排序和堆排序都要快，甚至在小数组中比快速排序还快，但是在涉及大量数据时希尔排序还是比快速排序慢。 时间复杂度希尔排序的时间复杂度分析很复杂。总之可以证明，其最坏情况下的时间复杂度是 O(n^2) ，但是对希尔排序稍加一点改进，就可以使其时间复杂度提高到 O(n^1.5) 。 实现1234567891011def ShellSort(arr): step = len(arr)/2 while step &gt;= 1: for i in xrange(step, len(arr)): while i &gt;= step and arr[i-step] &gt;arr[i]: arr[i-step],arr[i] = arr[i], arr[i-step] i -= step step = step/2 return arrprint ShellSort([80, 93, 60, 12, 42, 30, 68, 85, 10])","tags":[{"name":"算法","slug":"算法","permalink":"http://likernel.github.io/tags/算法/"},{"name":"排序","slug":"排序","permalink":"http://likernel.github.io/tags/排序/"}]},{"title":"冒泡排序","date":"2017-08-13T06:03:34.000Z","path":"2017/08/13/冒泡排序/","text":"算法思想冒泡排序是一种简单的排序算法。它重复地走访过要排序的数列，一次比较两个元素，如果他们的顺序错误就把他们交换过来。走访数列的工作是重复地进行直到没有再需要交换，也就是说该数列已经排序完成。这个算法的名字由来是因为越小的元素会经由交换慢慢“浮”到数列的顶端，有点类似于冒泡的过程。 实现123456def BubbleSort(arr): for i in xrange(len(arr)): for j in xrange(i+1,len(arr)): if arr[i] &gt; arr[j]: arr[i],arr[j] = arr[j],arr[i] return arr 备注：算法比较容易实现，唯一值得注意的是在Python中交换两个数是不需要中间变量的。因此有arr[i],arr[j] = arr[j],arr[i]这种写法。至于python底层的具体实现不清楚，个人感觉是之前提到的位异或运算实现的。 补充：关于变量交换问题，知乎上有大神帮忙做了解答，想了解的可以点击这里。","tags":[{"name":"算法","slug":"算法","permalink":"http://likernel.github.io/tags/算法/"},{"name":"排序","slug":"排序","permalink":"http://likernel.github.io/tags/排序/"}]},{"title":"插入排序","date":"2017-08-13T05:32:08.000Z","path":"2017/08/13/插入排序/","text":"算法思想直接插入排序是一种简单的插入排序法，其基本思想是：把待排序的纪录（这里我们记为key）的大小逐个插入到一个已经排好序的有序序列中，直到所有的纪录插入完为止，得到一个新的有序序列。 实现1234567891011def InsertionSort(arr): for i in xrange(1,len(arr)): key = arr[i] j = i-1 while j &gt;= 0 and arr[j] &gt; key: arr[j+1] = arr[j] j -= 1 arr[j+1] = key return arr 备注：算法实现参照《算法导论》中的内容，注意书中伪码的边界值处理和具体实现的区别。 arr：待排序数组。key：待比较元素，arr[i]。arr[0…i-1]：已经排好序的数组。j：已经排好序的数组的索引。时间复杂度：O(n^2)","tags":[{"name":"算法","slug":"算法","permalink":"http://likernel.github.io/tags/算法/"},{"name":"排序","slug":"排序","permalink":"http://likernel.github.io/tags/排序/"}]},{"title":"Python多态","date":"2017-08-10T01:05:07.000Z","path":"2017/08/10/Python多态/","text":"主要针对之前的鸭子类型，我们对Python的多态的知识点进行一个总结。 多态先看一个例子：1234&gt;&gt;&gt; \"This is a book\".count(\"s\")2&gt;&gt;&gt; [1,2,4,3,5,3].count(3)2 上面的count()的作用是数一数某个元素在对象中出现的次数。从例子中可以看出，我们并没有限定count的参数。类似的例子还有：1234567&gt;&gt;&gt; f = lambda x,y:x+y&gt;&gt;&gt; f(2,3)5&gt;&gt;&gt; f(\"qiw\",\"sir\")'qiwsir'&gt;&gt;&gt; f([\"python\",\"java\"],[\"c++\",\"lisp\"])['python', 'java', 'c++', 'lisp'] 在那个lambda函数中，我们没有限制参数的类型，也一定不能限制，因为如果限制了，就不是pythonic了。在使用的时候，可以给参数任意类型，都能到的不报错的结果。当然，这样做之所以合法，更多的是来自于+的功能强悍。 其实上面的例子就体现了什么叫做多态。其实就是“有多种形式”，就算不知道变量（参数）所引用的对象类型，也一样能进行操作，来者不拒。 下面给一个关于猫和狗的例子：123456789101112131415161718192021222324252627282930#!/usr/bin/env python# coding=utf-8\"the code is from: http://zetcode.com/lang/python/oop/\"__metaclass__ = typeclass Animal: def __init__(self, name=\"\"): self.name = name def talk(self): passclass Cat(Animal): def talk(self): print \"Meow!\"class Dog(Animal): def talk(self): print \"Woof!\"a = Animal()a.talk() # 无结果c = Cat(\"Missy\")c.talk() # Meow!d = Dog(\"Rocky\")d.talk() # Woof! 代码中有Cat和Dog两个类，都继承了类Animal，它们都有talk()方法，输入不同的动物名称，会得出相应的结果。 备注： 可以回忆一下鸭子类型里面的内容，可以加深你的理解。","tags":[{"name":"python","slug":"python","permalink":"http://likernel.github.io/tags/python/"}]},{"title":"Python2和Python3的区别","date":"2017-08-09T06:23:14.000Z","path":"2017/08/09/Python2和Python3的区别/","text":"你计划移植你的项目的时候，是非常值得看看这两个主要流行的 Python 版本之间的差别的，这里做一个记录。 future 模块Python 3.x 介绍的一些Python2.6+不兼容的关键字和特性可以通过在Python2.6+的内置__future__模块导入。如果你计划让你的代码支持 Python 3.x，建议你使用__future__模块导入。 以下__future__模块可被导入，从而让Python2.6+兼容Python 3.x的关键字和特性。 nested_scopes、generators、division、Operator、absolute_import、with_statement、print_function、unicode_literals 具体内容参照官方文档 print 函数Python 3.x print不再是语句，而是函数，比如：Python 2中是 print &#39;abc&#39;Python 3.x是 print(&#39;abc&#39;) Python2.6+可以使用from__future__import print_function来实现相同功能。 UnicodePython 2的默认编码是ASCII码，这导致了Python2中经常用遇到编码问题。 Python 3采用UTF-8作为默认编码，因此你不再需要在文件顶部写# coding=utf-8了。 除法运算Python中的除法较其它语言显得非常高端，有套很复杂的规则。python中的除法有两个运算符，/和// 首先来说/除法:在Python 2.x中/除法就跟我们熟悉的大多数语言，整数相除的结果是一个整数，把小数部分完全忽略掉，浮点数除法会保留小数点的部分得到一个浮点数的结果。 在Python 3.x中/除法不再这么做了，对于整数之间的相除，结果也会是浮点数。 Python 2.x:1234&gt;&gt;&gt; 1 / 20&gt;&gt;&gt; 1.0 / 2.00.5 Python 3.x:12&gt;&gt;&gt; 1/20.5 而对于//除法，这种除法叫做floor除法，会对除法的结果自动进行一个floor操作，在Python 2.x和Python 3.x中是一致的。Python 2.x:12&gt;&gt;&gt; -1 // 2-1 python 3.x:12&gt;&gt;&gt; -1 // 2-1 注意的是并不是舍弃小数部分，而是执行floor操作，如果要截取小数部分，那么需要使用math模块的trunc函数Python 3.x:12345&gt;&gt;&gt; import math&gt;&gt;&gt; math.trunc(1 / 2)0&gt;&gt;&gt; math.trunc(-1 / 2)0 #异常在Python 3中处理异常也轻微的改变了，在Python 3中我们现在使用as作为关键词。捕获异常的语法由except exc, var改为except exc as var。使用语法except (exc1, exc2) as var可以同时捕获多种类别的异常。python 2.6+已经支持这两种语法。 在2.x时代，所有类型的对象都是可以被直接抛出的，在3.x时代，只有继承自BaseException的对象才可以被抛出。 2.x raise语句使用逗号将抛出对象类型和参数分开，3.x取消了这种奇葩的写法，直接调用构造函数抛出对象即可。 在2.x时代，异常在代码中除了表示程序错误，还经常做一些普通控制结构应该做的事情，在3.x中可以看出，设计者让异常变的更加专一，只有在错误发生的情况才能去用异常捕获语句来处理。 xrange之前有讲过，这里不再赘述。 八进制字面量表示在Python 3.x中，表示八进制字面量的方式只有一种，就是0o1000。Python 2.x1234&gt;&gt;&gt; 0o1000512&gt;&gt;&gt; 01000512 python 3.x1234567&gt;&gt;&gt; 01000 File \"&lt;stdin&gt;\", line 1 01000 ^SyntaxError: invalid token&gt;&gt;&gt; 0o1000512 不等运算符Python 2.x中不等于有两种写法 != 和 &lt;&gt;Python 3.x中去掉了&lt;&gt;, 只有!=一种写法 去掉了repr表达式``Python 2.x 中反引号相当于repr函数的作用 Python 3.x 中去掉了这种写法，只允许使用repr函数 数据类型1）Python 3.x去除了long类型，现在只有一种整型int，但它的行为就像2.X版本的long2）新增了bytes类型，对应于2.X版本的八位串，定义一个bytes字面量的方法如下：123&gt;&gt;&gt; b = b'china'&gt;&gt;&gt; type(b)&lt;type 'bytes'&gt; str对象和bytes对象可以使用.encode() (str -&gt; bytes) or .decode() (bytes -&gt; str)方法相互转化。123456&gt;&gt;&gt; s = b.decode()&gt;&gt;&gt; s'china'&gt;&gt;&gt; b1 = s.encode()&gt;&gt;&gt; b1b'china' 3）dict的.keys()、.items 和.values()方法返回迭代器，而之前的iterkeys()等函数都被废弃。同时去掉的还有 dict.has_key()，可以用in替。 参考资料","tags":[{"name":"python","slug":"python","permalink":"http://likernel.github.io/tags/python/"}]},{"title":"lambda函数","date":"2017-08-09T04:15:33.000Z","path":"2017/08/09/lambda函数/","text":"在Python中，我们使用lambda关键字创造匿名函数。使用匿名函数时，我们不再使用def语句这样标准的形式定义一个函数，而是使用一种函数表达式的方式，一般只是实现一些简单的功能。 lambdalambda函数在调用时，绕过函数的栈分配。其语法是：1lambda [arg1[, arg2, ... argN]]: expression 例子:1234add = lambda x, y: x + yprint(add(3, 5))# Output: 8 lambda表达式还可以可以在一些特殊情况下使用，看下面的几个例子： 列表排序12345a = [(1, 2), (4, 1), (9, 10), (13, -3)]a.sort(key=lambda x: x[1])print(a)# Output: [(13, -3), (4, 1), (1, 2), (9, 10)] 列表并行排序123data = zip(list1, list2)data = sorted(data)list1, list2 = map(lambda t: list(t), zip(*data))","tags":[{"name":"python","slug":"python","permalink":"http://likernel.github.io/tags/python/"}]},{"title":"__new__和__init__","date":"2017-08-08T22:58:35.000Z","path":"2017/08/09/new-和-init/","text":"我们都知道一个最基本的魔术方法， __init__ 。通过此方法我们可以定义一个对象的初始操作。然而，当我调用 x = SomeClass() 的时候， __init__ 并不是第一个被调用的方法。 实际上，还有一个叫做 __new__ 的方法，来构造这个实例。然后给在开始创建时候的初始化函数来传递参数。 #__new____new__ 是在一个对象实例化的时候所调用的第一个方法。它的第一个参数是这个类，其他的参数是用来直接传递给__init__ 方法。 __new__ 方法相当不常用，但是它有自己的特性，特别是当继承一个不可变的类型比如一个tuple或者string。这里不再介绍__new__的更多细节，因为并不是很实用，python文档中有详细的阐述。 #__init__此方法为类的初始化方法。当构造函数被调用的时候的任何参数都将会传给它。(比如如果我们调用 x = SomeClass(10, ‘foo’))，那么__init__ 将会得到两个参数10和foo。 __init__ 在Python的类定义中被广泛用到。 #区别 __new__:创建对象时调用，会返回当前对象的一个实例。 __init__:创建完对象后调用，对当前对象的一些实例初始化，无返回值。 1.在类中，如果__new__和__init__同时存在，会优先调用__new__12345678&gt;&gt;&gt; class Data(object):... def __new__(self):... print \"new\"... def __init__(self):... print \"init\"...&gt;&gt;&gt; data = Data()new 2.__new__方法会返回所构造的对象，__init__则不会。__init__无返回值。 __new__:12345678910111213&gt;&gt;&gt; class Data(object):... def __new__(cls):... print \"new\"... cls.x = 1... return cls... def __init__(self):... print \"init\"...&gt;&gt;&gt; data = Data()new&gt;&gt;&gt; data.x =1&gt;&gt;&gt; data.x1 __init__:123456789101112131415161718192021222324252627class Data(object):... def __init__(cls):... cls.x = 2... print \"init\"... return cls...&gt;&gt;&gt; data = Data()initTraceback (most recent call last): File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;TypeError: __init__() should return None, not 'Data'&gt;&gt;&gt; class Data(object):... def __new__(cls):... print \"new\"... cls.x = 1... return cls... def __init__(self):... print \"init\"...&gt;&gt;&gt; data = Data()new&gt;&gt;&gt; data.x =1&gt;&gt;&gt; data.x1 3.如果__new__返回一个对象的实例，会隐式调用__init__，如果__new__不返回一个对象的实例，__init__不会被调用。 __new__返回一个对象的实例:12345678910111213&lt;class '__main__.B'&gt;&gt;&gt;&gt; class A(object):... def __new__(Class):... object = super(A,Class).__new__(Class)... print \"in New\"... return object... def __init__(self):... print \"in init\"...&gt;&gt;&gt; A()in Newin init&lt;__main__.A object at 0x7fa8bc622d90&gt; __new__不返回一个对象的实例：123456789&gt;&gt;&gt; class A(object):... def __new__(cls):... print \"in New\"... return cls... def __init__(self):... print \"in init\"...&gt;&gt;&gt; a = A() in New 参考资料","tags":[{"name":"python","slug":"python","permalink":"http://likernel.github.io/tags/python/"}]},{"title":"Python中的range和xrange","date":"2017-08-08T22:57:34.000Z","path":"2017/08/09/Python中的range和xrange/","text":"介绍Python中的range和xrange以及它们之间的区别。 range函数说明：range([start,] stop[, step])，根据start与stop指定的范围以及step设定的步长，生成一个序列。 xrange函数说明：用法与range完全相同，所不同的是生成的不是一个数组，而是一个生成器。 xrange和range区别这两个基本上都是在循环的时候用。12for i in range(0, 100):print i 12for i in xrange(0, 100):print i 这两个输出的结果都是一样的，实际上有很多不同，range会直接生成一个list对象：1234a = range(0,100)print type(a)print aprint a[0], a[1] 输出：123&lt;type 'list'&gt;[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]0 1 而xrange则不会直接生成一个list，而是每次调用返回其中的一个值1234a = xrange(0,100)print type(a)print aprint a[0], a[1] 输出：123&lt;type 'xrange'&gt;xrange(100)0 1 要生成很大的数字序列的时候，用xrange会比range性能优很多，因为不需要一上来就开辟一块很大的内存空间。尽量用xrange，除非你是要返回一个列表。 备注：在Python 3中，range()是像xrange()那样实现以至于一个专门的 xrange()函数都不再存在（在python 3中xrange()会抛出命名异常）。","tags":[{"name":"python","slug":"python","permalink":"http://likernel.github.io/tags/python/"}]},{"title":"Python中的==与is","date":"2017-08-08T22:56:49.000Z","path":"2017/08/09/Python中的-与is/","text":"这属于比较小的一个知识点了，这里记录一下。 is is the identity comparison. # 比较引用（地址）是否相同 == is the equality comparison. # 比较内容是否相同 例子：12345&gt;&gt;&gt; [] is []False&gt;&gt;&gt; [] == []True&gt;&gt;&gt;","tags":[{"name":"python","slug":"python","permalink":"http://likernel.github.io/tags/python/"}]},{"title":"Pyhton垃圾回收机制","date":"2017-08-08T22:56:14.000Z","path":"2017/08/09/Pyhton垃圾回收机制/","text":"GC(Garbage collection)作为现代编程语言的自动内存管理机制，专注于两件事：1. 找到内存中无用的垃圾资源 2. 清除这些垃圾并把内存让出来给其他对象使用。GC彻底把程序员从资源管理的重担中解放出来，让他们有更多的时间放在业务逻辑上。 Python采用的是引用计数机制为主，标记-清除和分代回收两种机制为辅的策略。 引用计数Python语言默认采用的垃圾收集机制是：引用计数法 Reference Counting。 其原理是： 每个对象维护一个ob_ref字段，用来记录该对象当前被引用的次数，每当新的引用指向该对象时，它的引用计数ob_ref加1，每当该对象的引用失效时计数ob_ref减1，一旦对象的引用计数为0，该对象立即被回收，对象占用的内存空间将被释放。 它的缺点是需要额外的空间维护引用计数，这个问题是其次的，不过最主要的问题是它不能解决对象的“循环引用”。 循环引用A和B相互引用而再没有外部引用A与B中的任何一个，它们的引用计数虽然都为1，但显然应该被回收，例子：123456a = &#123; &#125; #对象A的引用计数为 1b = &#123; &#125; #对象B的引用计数为 1a['b'] = b #B的引用计数增1b['a'] = a #A的引用计数增1del a #A的引用减 1，最后A对象的引用为 1del b #B的引用减 1, 最后B对象的引用为 1 在这个例子中程序执行完del语句后，A、B对象已经没有任何引用指向这两个对象，但是这两个对象各包含一个对方对象的引用，虽然最后两个对象都无法通过其它变量来引用这两个对象了，这对GC来说就是两个非活动对象或者说是垃圾对象，但是他们的引用计数并没有减少到零。因此如果是使用引用计数法来管理这两对象的话，他们并不会被回收，它会一直驻留在内存中，就会造成了内存泄漏（内存空间在使用完毕后未释放）。 为了解决对象的循环引用问题，Python引入了标记-清除和分代回收两种GC机制。 标记清除标记清除（Mark—Sweep）算法是一种基于追踪回收（tracing GC）技术实现的垃圾回收算法。它分为两个阶段： 1.标记阶段，GC会把所有的活动对象打上标记。2.把那些没有标记的非活动对象进行回收。 那么GC又是如何判断哪些是活动对象哪些是非活动对象的呢？ 对象之间通过引用（指针）连在一起，构成一个有向图，对象构成这个有向图的节点，而引用关系构成这个有向图的边。从根对象（root object）出发，沿着有向边遍历对象，可达的（reachable）对象标记为活动对象，不可达的对象就是要被清除的非活动对象。根对象就是全局变量、调用栈、寄存器。 在上图中，我们把小黑圈视为全局变量，也就是把它作为root object，从小黑圈出发，对象1可直达，那么它将被标记，对象2、3可间接到达也会被标记，而4和5不可达，那么1、2、3就是活动对象，4和5是非活动对象会被GC回收。 标记清除算法作为Python的辅助垃圾收集技术主要处理的是一些容器对象，比如list、dict、tuple，instance等，因为对于字符串、数值对象是不可能造成循环引用问题。Python使用一个双向链表将这些容器对象组织起来。 不过，这种简单粗暴的标记清除算法也有明显的缺点：清除非活动的对象前它必须顺序扫描整个堆内存，哪怕只剩下小部分活动对象也要扫描所有对象。 分代回收分代回收是一种以空间换时间的操作方式，Python将内存根据对象的存活时间划分为不同的集合，每个集合称为一个代。 Python将内存分为了3“代”，分别为年轻代（第0代）、中年代（第1代）、老年代（第2代），他们对应的是3个链表，它们的垃圾收集频率与对象的存活时间的增大而减小。 新创建的对象都会分配在年轻代，年轻代链表的总数达到上限时，Python垃圾收集机制就会被触发，把那些可以被回收的对象回收掉，而那些不会回收的对象就会被移到中年代去，依此类推，老年代中的对象是存活时间最久的对象，甚至是存活于整个系统的生命周期内。 同时，分代回收是建立在标记清除技术基础之上。分代回收同样作为Python的辅助垃圾收集技术处理那些容器对象。 #参考资料","tags":[{"name":"python","slug":"python","permalink":"http://likernel.github.io/tags/python/"}]},{"title":"python鸭子类型","date":"2017-08-08T22:52:57.000Z","path":"2017/08/09/python鸭子类型/","text":"当看到一只鸟走起来像鸭子、游泳起来像鸭子、叫起来也像鸭子，那么这只鸟就可以被称为鸭子。 在Python当中我们会尽量避免使用诸如type, isinstance等函数，因为当使用这个函数时，会毁掉你代码的多态性，在Python当中真正重要的事情是关心如何让对象按照你所希望的方式工作，不管它是否是正确的类型。这就是上面提到的鸭子类型。 鸭子类型在鸭子类型的编程形式当中，类型不是我们关心的第一要素，真正重要的在于这个对象的行为。 我们以静态类型语言当中的加法为例子，在静态语言当中我们通常只能对于相同类型的对象进行加法运算。假如使用了不同类型的对象进行加法运算编辑器将会直接提示错误。 而在Python当中只要对象实现了add方法，那么就意味着这个对象是可以进行加法运算的:12345678910class A: def __init__(self, val): self.val = val def __add__(self, other): return self.__class__(self.val+other.val) def __str__(self): return str(self.val)a = A(2)b = A(3)print a + b 类似于add,还包括诸如getitem setitem 等方法都是同样的道理:1234a = [1,2,3]print a[0]# 等价于print list.__getitem__(a, 0) 这里鸭子类型的产生是由于在Python当中我们对a使用“索引”操作时，我们并不用关心a的类型，我们只需要关心a所引用的对象是否包含getitem这样的方法。 继承与鸭子类型在Java当中我们使用接口来定义行为，通过继承超类实现代码共享。而在Python当中由于鸭子类型的存在，除了代码共享以外(如mixin)我们很少有对继承的需要：1234567891011121314151617181920212223class Duck: def quck(self): print \"duck qucking\" def walk(self): print \"duck is walking\"class GreenDuck(Duck): def quck(self): print \"green duck is qucking.\"class PersonWithDuckSkil: def quck(self): print \"em~ i'm not a real duck\" def walk(self): print \"All peope can waking.\"def duck_game(duck): duck.quck() duck.walk()if __name__ == \"__main__\": duck = Duck() greenDuck = GreenDuck() people = PersonWithDuckSkil() duck_game(duck) duck_game(greenDuck) duck_game(people) 基于鸭子类型实现完全由程序员自身进行控制，在增加了灵活性的同时还需要程序员自身的更高要求，虽然没有语言层面的约束，但是还是要保持心中有“接口”的状态。","tags":[{"name":"python","slug":"python","permalink":"http://likernel.github.io/tags/python/"}]},{"title":"*args和**kwargs","date":"2017-08-08T22:52:17.000Z","path":"2017/08/09/args和-kwargs/","text":"主要介绍一下*args和**kwargs的区别，其实更准确的说是，*和**。实际上真正的Python参数传递语法是*和**。*args和**kwargs只是一种约定俗成的编程实践。我们也可以写成*vars和**kvars。 *args和**kwargs一般是用在函数定义的时候。作用是允许定义的函数接受任意数目的参数。下面来分别介绍一下： *args*args用来表示函数接收可变长度的非关键字参数列表作为函数的输入。看下面的例子：12345678910111213def hello(name, age, *args): print \"do something...\" print name, age print args&gt;&gt;&gt; hello(\"Tom\", \"12\")do something...Tom 12()&gt;&gt;&gt; hello(\"Tom\", \"12\", \"Black\")do something...Tom 12('Black',) 备注：arg的输出是一个元组，如果只输入两个参数，那么可变参数args就是一个空元组。只要超过2个参数，多余的就会存储在args元组中。 **kwargs**kwargs表示函数接收可变长度的关键字参数字典作为函数的输入。当我们需要函数接收带关键字的参数作为输入的时候，应当使用**kwargs。看下面的例子：1234567def hello(**kwargs): print kwargs&gt;&gt;&gt;hello(name=\"Black\")&#123;'name': 'black'&#125;&gt;&gt;&gt; hello(name=\"Tom\", age=\"22\")&#123;'age': '22', 'name': 'Tom'&#125; 备注：kwargs输出为字典，关键词作为字典的key，参数作为值保存在kwargs中。 当输入为字典时：123456def hello(**kwargs): print kwargs&gt;&gt;&gt; d = dict(name=\"Tom\", age=22)&gt;&gt;&gt;hello(**d)&#123;'age': '22', 'name': 'Tom'&#125; 输入完全一样，相当于直接输出字典d，由此对于数据库连接，日志配置一种简单的情况就是配置成字典，然后直接传入字典，代码变得更加简洁。 混合参数1234567891011121314151617def hello(name, age, *args, **kwargs): print name, age print args print kwargs&gt;&gt;&gt;hello(\"Black\", \"22\", \"177\", hobby=\"math\")Black 22('177',)&#123;'hobby': 'math'&#125;&gt;&gt;&gt;hello(\"Black\", \"22\", length=\"177\", hobby=\"math\")Black 22()&#123;'hobby': 'math', 'length': '177'&#125;&gt;&gt;&gt;hello(name=\"Black\", age=\"22\", length=\"177\", hobby=\"math\")Black 22()&#123;'hobby': 'math', 'length': '177'&#125; 注意：标准参数与*args、**kwargs在使用时的顺序：1some_func(fargs, *args, **kwargs) 使用*args和**kwargs 来调用函数假设，你有这样一个小函数：1234def test_args_kwargs(arg1, arg2, arg3): print(\"arg1:\", arg1) print(\"arg2:\", arg2) print(\"arg3:\", arg3) 你可以使用args或*kwargs来给这个小函数传递参数：12345678910111213# 首先使用 *args&gt;&gt;&gt; args = (\"two\", 3, 5)&gt;&gt;&gt; test_args_kwargs(*args)arg1: twoarg2: 3arg3: 5# 现在使用 \\*\\*kwargs:&gt;&gt;&gt; kwargs = &#123;\"arg3\": 3, \"arg2\": \"two\", \"arg1\": 5&#125;&gt;&gt;&gt; test_args_kwargs(**kwargs)arg1: 5arg2: twoarg3: 3 参考资料","tags":[{"name":"python","slug":"python","permalink":"http://likernel.github.io/tags/python/"}]},{"title":"Python生成器","date":"2017-08-08T22:51:40.000Z","path":"2017/08/09/Python生成器/","text":"生成器和迭代器有着一定的渊源关系。生成器必须是可迭代的，但它不仅仅是迭代器，我们可以把它理解为非常方便的自定义迭代器。 简单的生成器1&gt;&gt;&gt; my_generator = (x*x for x in range(4)) 这是不是跟列表推导式很类似呢？仔细观察，它不是列表，如果这样的得到的才是列表：1&gt;&gt;&gt; my_list = [x*x for x in range(4)] 以上两的区别在于是[]还是()，虽然是细小的差别，但是结果完全不一样。123456&gt;&gt;&gt; dir(my_generator)['__class__', '__delattr__', '__doc__', '__format__', '__getattribute__', '__hash__', '__init__','__iter__','__name__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', 'close', 'gi_code', 'gi_frame', 'gi_running','next','send', 'throw'] 我们发现了在迭代器中必有的方法__inter__()和next()，这说明它是迭代器。如果是迭代器，就可以用for循环来依次读出其值。12345678910&gt;&gt;&gt; for i in my_generator:... print i...0149&gt;&gt;&gt; for i in my_generator:... print i... 当第一遍循环的时候，将my_generator里面的值依次读出并打印，但是，当再读一次的时候，就发现没有任何结果。这种特性也正是迭代器所具有的。 如果对那个列表，就不一样了：1234567891011121314&gt;&gt;&gt; for i in my_list:... print i...0149&gt;&gt;&gt; for i in my_list:... print i...0149 难道生成器就是把列表推导式中的[]换成()就行了吗？这仅仅是生成器的一种表现形式和使用方法罢了，我们称之为“生成器推导式” 生成器解析式是有很多用途的，在不少地方替代列表，是一个不错的选择。特别是针对大量值的时候，如上节所说的，列表占内存较多，迭代器（生成器是迭代器）的优势就在于少占内存，因此无需将生成器（或者说是迭代器）实例化为一个列表，直接对其进行操作，方显示出其迭代的优势。比如：12&gt;&gt;&gt; sum(i*i for i in range(10))285 备注：上面的sum()运算，并未少写括号，可以直接这么写。 如果列表，你不得不：12&gt;&gt;&gt; sum([i*i for i in range(10)])285 通过生成器推导式得到的生成器，掩盖了生成器的一些细节，并且适用领域也有限，下面就要剖析生成器的内部。 定义和执行过程yield这个词在汉语中有“生产、出产”之意，在python中，它作为一个关键词（你在变量、函数、类的名称中就不能用这个了），是生成器的标志。1234567&gt;&gt;&gt; def g():... yield 0... yield 1... yield 2...&gt;&gt;&gt; g&lt;function g at 0xb71f3b8c&gt; 建立了一个非常简单的函数，跟以往看到的函数唯一不同的地方是用了三个yield语句。然后进行下面的操作：12345&gt;&gt;&gt; ge = g()&gt;&gt;&gt; ge&lt;generator object g at 0xb7200edc&gt;&gt;&gt;&gt; type(ge)&lt;type 'generator'&gt; 上面建立的函数返回值是一个生成器(generator)类型的对象。12&gt;&gt;&gt; dir(ge)['__class__', '__delattr__', '__doc__', '__format__', '__getattribute__', '__hash__', '__init__', '__iter__', '__name__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', 'close', 'gi_code', 'gi_frame', 'gi_running', 'next', 'send', 'throw'] 在这里看到了__iter__()和next()，说明它是迭代器。既然如此，当然可以：12345678910&gt;&gt;&gt; ge.next()0&gt;&gt;&gt; ge.next()1&gt;&gt;&gt; ge.next()2&gt;&gt;&gt; ge.next()Traceback (most recent call last): File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;StopIteration 从这个简单例子中可以看出，那个含有yield关键词的函数返回值是一个生成器类型的对象，这个生成器对象就是迭代器。 我们把含有yield语句的函数称作生成器。生成器是一种用普通函数语法定义的迭代器。通过上面的例子可以看出，这个生成器（也是迭代器），在定义过程中并没有像上节迭代器那样写__inter__()和next()，而是只要用了yield语句，那个普通函数就神奇般地成为了生成器，也就具备了迭代器的功能特性。 yield语句的作用，就是在调用的时候返回相应的值。详细剖析一下上面的运行过程： 1.ge = g()：除了返回生成器之外，什么也没有操作，任何值也没有被返回。2.ge.next()：直到这时候，生成器才开始执行，遇到了第一个yield语句，将值返回，并暂停执行（有的称之为挂起）。3.ge.next()：从上次暂停的位置开始，继续向下执行，遇到yield语句，将值返回，又暂停。4.gen.next()：重复上面的操作。5.gene.next()：从上面的挂起位置开始，但是后面没有可执行的了，于是next()发出异常。 从上面的执行过程中，发现yield除了作为生成器的标志之外，还有一个功能就是返回值。那么它跟return这个返回值有什么区别呢？ yield为了弄清楚yield和return的区别，我们写两个没有什么用途的函数：12345678910111213&gt;&gt;&gt; def r_return(n):... print \"You taked me.\"... while n &gt; 0:... print \"before return\"... return n... n -= 1... print \"after return\"...&gt;&gt;&gt; rr = r_return(3)You taked me.before return&gt;&gt;&gt; rr3 从函数被调用的过程可以清晰看出，rr = r_return(3)，函数体内的语句就开始执行了，遇到return，将值返回，然后就结束函数体内的执行。所以return后面的语句根本没有执行。 下面将return改为yield：1234567891011121314151617181920212223242526&gt;&gt;&gt; def y_yield(n):... print \"You taked me.\"... while n &gt; 0:... print \"before yield\"... yield n... n -= 1... print \"after yield\"...&gt;&gt;&gt; yy = y_yield(3) #没有执行函数体内语句&gt;&gt;&gt; yy.next() #开始执行You taked me.before yield3 #遇到yield，返回值，并暂停&gt;&gt;&gt; yy.next() #从上次暂停位置开始继续执行after yieldbefore yield2 #又遇到yield，返回值，并暂停&gt;&gt;&gt; yy.next() #重复上述过程after yieldbefore yield1&gt;&gt;&gt; yy.next()after yield #没有满足条件的值，抛出异常Traceback (most recent call last): File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;StopIteration 一般的函数，都是止于return。作为生成器的函数，由于有了yield，则会遇到它挂起，如果还有return，遇到它就直接抛出SoptIteration异常而中止迭代。 生成器方法在python2.5以后，生成器有了一个新特征，就是在开始运行后能够为生成器提供新的值。这就好似生成器和“外界”之间进行数据交流。123456789&gt;&gt;&gt; def repeater(n):... while True:... n = (yield n)...&gt;&gt;&gt; r = repeater(4)&gt;&gt;&gt; r.next()4&gt;&gt;&gt; r.send(\"hello\")'hello' 当执行到r.next()的时候，生成器开始执行，在内部遇到了yield n挂起。注意在生成器函数中，n = (yield n)中的yield n是一个表达式，并将结果赋值给n，虽然不严格要求它必须用圆括号包裹，但是一般情况都这么做。 当执行r.send(“hello”)的时候，原来已经被挂起的生成器（函数）又被唤醒，开始执行n = (yield n)，也就是讲send()方法发送的值返回。这就是在运行后能够为生成器提供值的含义。 如果接下来再执行r.next()会怎样？1&gt;&gt;&gt; r.next() 什么也没有，其实就是返回了None。按照前面的叙述，读者可以看到，这次执行r.next()，由于没有传入任何值，yield返回的就只能是None。 还要注意，send()方法必须在生成器运行后并挂起才能使用，也就是yield至少被执行一次。如果不是这样：12345&gt;&gt;&gt; s = repeater(5)&gt;&gt;&gt; s.send(\"how\")Traceback (most recent call last): File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;TypeError: can't send non-None value to a just-started generator 就报错了。但是，可将参数设为None：12&gt;&gt;&gt; s.send(None)5 这是返回的是调用函数的时传入的值。 此外，还有两个方法：close()和throw()121. throw(type, value=None, traceback=None):用于在生成器内部（生成器的当前挂起处，或未启动时在定义处）抛出一个异常（在yield表达式中）。2. close()：调用时不用参数，用于关闭生成器。 最后一句，你在编程中，不用生成器也可以。","tags":[{"name":"python","slug":"python","permalink":"http://likernel.github.io/tags/python/"}]},{"title":"Python中的%和format","date":"2017-08-08T22:51:25.000Z","path":"2017/08/09/Python中的-和format/","text":"用%格式化在一个字符串中，有几个%占位符，后面的%()就跟几个变量或者值，顺序必须一致对应。当只有一个%时，括号可以省略。例子：1234&gt;&gt;&gt; 'Hello, %s' % 'world''Hello, world'&gt;&gt;&gt; 'Hi, %s, you have $%d.' % ('Michael', 1000000)'Hi, Michael, you have $1000000.' 格式化整数和浮点数还可以指定是否补0和整数与小数的位数：1234&gt;&gt;&gt; '%2d-%02d' % (3, 1)' 3-01'&gt;&gt;&gt; '%.2f' % 3.1415926'3.14' 字符串里面有‘%’时，需要转义，用‘%%’来表示一个‘%’12&gt;&gt;&gt; 'growth rate: %d %%' % 7'growth rate: 7 % 用format函数格式化‘替换’方法通过位置字符串的format函数可以接受不限个参数，位置可以不按顺序，可以不用或者用多次，可以接受‘’1234567891011&gt;&gt;&gt; '&#123;0&#125;,&#123;1&#125;'.format('abc',123) 'abc,123' &gt;&gt;&gt; '&#123;1&#125;,&#123;2&#125;'.format('abc',123,'efg') '123,efg' &gt;&gt;&gt; '&#123;&#125;,&#123;&#125;'.format('abc',123) 'abc,123' &gt;&gt;&gt; '&#123;1&#125;,&#123;0&#125;,&#123;1&#125;'.format('abc',123) '123,abc,123' 通过关键字参数12&gt;&gt;&gt; '&#123;name&#125;,&#123;age&#125;'.format(age=123,name='abc') 'abc,123' 通过对象属性1234567class Person: def __init__(self,name,age): self.name,self.age = name,age def __str__(self): return 'This guy is &#123;self.name&#125;,is &#123;self.age&#125; old'.format(self=self) &gt;&gt;&gt; str(Person('abc',123)) 'This guy is abc,is 123 old' 通过下标123&gt;&gt;&gt; p=['abc',123]&gt;&gt;&gt; '&#123;p[0]&#125;,&#123;p[1]&#125;'.format(p=p)'abc,123' 也可以：123&gt;&gt;&gt; p=['abc',123]&gt;&gt;&gt; '&#123;0[0]&#125;,&#123;0[1]&#125;'.format(p)'abc,123' 格式限定符语法是{}中带:号 填充与对齐填充常跟对齐一起使用 ^、&lt;、&gt;分别是:居中、左对齐、右对齐，后面带宽度。:号后面带填充的字符，只能是一个字符，不指定的话默认是用空格填充。 比如:123456&gt;&gt;&gt; '&#123;:&gt;8&#125;'.format('189')' 189'&gt;&gt;&gt; '&#123;:0&gt;8&#125;'.format('189')'00000189'&gt;&gt;&gt; '&#123;:a&gt;8&#125;'.format('189')'aaaaa189' 精度与类型f精度常跟类型f一起使用，来格式化浮点数12&gt;&gt;&gt; '&#123;:.2f&#125;'.format(321.33345)'321.33' 其中.2表示长度为2的精度，f表示float类型。 进制主要就是进制了，b、d、o、x分别是二进制、十进制、八进制、十六进制。12345678&gt;&gt;&gt; '&#123;:b&#125;'.format(17)'10001'&gt;&gt;&gt; '&#123;:d&#125;'.format(17) '17'&gt;&gt;&gt; '&#123;:o&#125;'.format(17)'21'&gt;&gt;&gt; '&#123;:x&#125;'.format(17)'11 用,号还能用来做金额的千位分隔符。12&gt;&gt;&gt; '&#123;:,&#125;'.format(1234567890)'1,234,567,890' 参考资料","tags":[{"name":"python","slug":"python","permalink":"http://likernel.github.io/tags/python/"}]},{"title":"Python推导式","date":"2017-08-08T20:01:59.000Z","path":"2017/08/09/Python推导式/","text":"推导式（又称解析式）是Python的一种独有特性，推导式是可以从一个数据序列构建另一个新的数据序列的结构体。共有三种推导，在Python2和3中都有支持：列表(list)推导式、字典(dict)推导式、集合(set)推导式。 列表推导式列表推导式提供了一种简明扼要的方法来创建列表。其语法如下：1variable = [out_exp for out_exp in input_list if out_exp == 2] 实际上，在之前写快速排序时，已经见过列表推导式。列表推导式在有些情况下超赞，特别是当你需要使用for循环来生成一个新列表。举个例子，你通常会这样做：123squared = []for x in range(10): squared.append(x**2) 你可以使用列表推导式来简化它，就像这样：1squared = [x**2 for x in range(10)] #字典推导式字典推导和列表推导的使用方法是类似的，它的语法如下：1d = &#123;key: value for (key, value) in iterable&#125; 看下面的例子：12345&gt;&gt;&gt; dict=&#123;\"a\":1, \"b\":2, \"c\":3, \"d\":4&#125;&gt;&gt;&gt; d=&#123;v:k for k,v in dict.items()&#125;&gt;&gt;&gt; print d&#123;1: 'a', 2: 'b', 3: 'c', 4: 'd'&#125;&gt;&gt;&gt; 在上面的例子中，我们可以快速交换字典键—值。 集合推导式集合推导式跟列表推导式差不多，主要区别在于：1.不使用[]，使用{}；2.结果中无重复；3.结果是一个set()集合，集合里面是一个序列:1234&gt;&gt;&gt; squared=&#123;i*2 for i in [1,1,2]&#125;&gt;&gt;&gt; print squaredset([2, 4])&gt;&gt;&gt;","tags":[{"name":"python","slug":"python","permalink":"http://likernel.github.io/tags/python/"}]},{"title":"python自省","date":"2017-08-08T20:01:43.000Z","path":"2017/08/09/python自省/","text":"当您有一个任意的对象（也许是一个作为参数传递给函数的对象）时，可能希望知道一些关于该对象的情况。如希望python告诉我们： 1 对象的名称是什么？2 这是哪种类型的对象？3 对象知道些什么？4 对象能做些什么？5 对象的父对象是谁？ Python的自省机制，就是告诉我们这些问题的答案是什么。内置了很多模块：type(),dir(),getattr(),hasattr(),setattr(),isinstance()等。 dir()Python 提供了一种方法，可以使用内置的 dir() 函数来检查模块（以及其它对象）的内容。 dir() 函数可能是 Python 自省机制中最著名的部分了。它返回传递给它的任何对象的属性名称经过排序的列表。如果不指定对象，则 dir() 返回当前作用域中的名称。让我们将 dir() 函数应用于 keyword 模块，并观察它揭示了什么：123&gt;&gt;&gt; import keyword&gt;&gt;&gt; dir(keyword)['__all__', '__builtins__', '__doc__', '__file__', '__name__', '__package__', 'iskeyword', 'kwlist', 'main'] type()type() 函数有助于我们确定对象是字符串还是整数，或是其它类型的对象。它通过返回类型对象来做到这一点，可以将这个类型对象与 types 模块中定义的类型相比较：12345678&gt;&gt;&gt; type(42)&lt;type &apos;int&apos;&gt;&gt;&gt;&gt; type([])&lt;type &apos;list&apos;&gt;&gt;&gt;&gt; type(&#123;&#125;)&lt;type &apos;dict&apos;&gt;&gt;&gt;&gt; type(dir)&lt;type &apos;builtin_function_or_method&apos;&gt; getattr()获取对象object的属性或者方法，如果存在打印出来，如果不存在，打印出默认值，默认值可选。需要注意的是，如果是返回的对象的方法，返回的是方法的内存地址，如果需要运行这个方法，可以在后面添加一对括号。12345678910111213141516171819&gt;&gt;&gt; class test():... name=\"xiaohua\"... def run(self):... return \"HelloWord\"...&gt;&gt;&gt; t=test()&gt;&gt;&gt; getattr(t, \"name\") #获取name属性，存在就打印出来。'xiaohua'&gt;&gt;&gt; getattr(t, \"run\") #获取run方法，存在就打印出方法的内存地址。&lt;bound method test.run of &lt;__main__.test instance at 0x0269C878&gt;&gt;&gt;&gt;&gt; getattr(t, \"run\")() #获取run方法，后面加括号可以将这个方法运行。'HelloWord'&gt;&gt;&gt; getattr(t, \"age\") #获取一个不存在的属性。Traceback (most recent call last): File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;AttributeError: test instance has no attribute 'age'&gt;&gt;&gt; getattr(t, \"age\",\"18\") #若属性不存在，返回一个默认值。'18'&gt;&gt;&gt; hasattr()hasattr(object, name)判断一个对象里面是否有name属性或者name方法，返回BOOL值，有name特性返回True，否则返回False。需要注意的是name要用括号括起来:1234567891011&gt;&gt;&gt; class test():... name=\"xiaohua\"... def run(self):... return \"HelloWord\"...&gt;&gt;&gt; t=test()&gt;&gt;&gt; hasattr(t, \"name\") #判断对象有name属性True&gt;&gt;&gt; hasattr(t, \"run\") #判断对象有run方法True&gt;&gt;&gt; setattr()给对象的属性赋值，若属性不存在，先创建再赋值。123456789101112&gt;&gt;&gt; class test():... name=\"xiaohua\"... def run(self):... return \"HelloWord\"...&gt;&gt;&gt; t=test()&gt;&gt;&gt; hasattr(t, \"age\") #判断属性是否存在False&gt;&gt;&gt; setattr(t, \"age\", \"18\") #为属相赋值，并没有返回值&gt;&gt;&gt; hasattr(t, \"age\") #属性存在了True&gt;&gt;&gt; isinstance()isinstance(object,type)来判断一个对象是否是一个已知的类型。123456789&gt;&gt;&gt; a = \"b\"&gt;&gt;&gt; isinstance(a,str)True&gt;&gt;&gt; isinstance(a,int)False&gt;&gt;&gt; isinstance(a,(int,list,float))False&gt;&gt;&gt; isinstance(a,(int,list,float,str))True","tags":[{"name":"python","slug":"python","permalink":"http://likernel.github.io/tags/python/"}]},{"title":"@staticmethod和@classmethod","date":"2017-08-08T20:01:02.000Z","path":"2017/08/09/staticmethod和-classmethod/","text":"staticmethod和classmethod均被作为装饰器，用作定义一个函数为”staticmethod”还是”classmethod”。 classmethod类方法，即类对象所拥有的方法，需要用修饰器@classmethod来标识其为类方法，对于类方法，第一个参数必须是类对象，一般以cls作为第一个参数（当然可以用其他名称的变量作为其第一个参数，但是大部分人都习惯以’cls’作为第一个参数的名字，就最好用’cls’了），能够通过实例对象和类对象去访问。1234567891011class People(object): country = 'china' #类方法，用classmethod来进行修饰 @classmethod def getCountry(cls): return cls.countryp = People()print p.getCountry() #可以用过实例对象引用print People.getCountry() #可以通过类对象引用 类方法还有一个用途就是可以对类属性进行修改：123456789101112131415161718192021class People(object): country = 'china' #类方法，用classmethod来进行修饰 @classmethod def getCountry(cls): return cls.country @classmethod def setCountry(cls,country): cls.country = countryp = People()print p.getCountry() #可以用过实例对象引用print People.getCountry() #可以通过类对象引用p.setCountry('japan') print p.getCountry() print People.getCountry() 结果显示在用类方法对类属性修改之后，通过类对象和实例对象访问都发生了改变。 @staticmethod静态方法，需要通过修饰器@staticmethod来进行修饰，静态方法不需要多定义参数12345678910class People(object): country = 'china' @staticmethod #静态方法 def getCountry(): return People.countryprint People.getCountry() 总结类方法的第一个参数是类对象cls，那么通过cls引用的必定是类对象的属性和方法。 实例方法的第一个参数是实例对象self，那么通过self引用的可能是类属性、也有可能是实例属性（这个需要具体分析），不过在存在相同名称的类属性和实例属性的情况下，实例属性优先级更高。 静态方法中不需要额外定义参数，因此在静态方法中引用类属性的话，必须通过类对象来引用。","tags":[{"name":"python","slug":"python","permalink":"http://likernel.github.io/tags/python/"}]},{"title":"Python中的元类","date":"2017-08-08T20:00:21.000Z","path":"2017/08/09/Python中的元类/","text":"这是很难理解的一个概念。这里参考了Stack overflow里What is a metaclass in Python? 这篇帖子中的一个回答，来深刻的理解一下元类这个概念。 类也是对象Python中类的概念借鉴于Smalltalk，这显得有些奇特。在大多数编程语言中，类就是一组用来描述如何生成一个对象的代码段。在Python中这一点仍然成立：12345&gt;&gt;&gt; class ObjectCreator(object): pass&gt;&gt;&gt; my_object = ObjectCreator()&gt;&gt;&gt; print my_object&lt;__main__.ObjectCreator object at 0x8974f2c&gt; 但是，Python中的类还远不止如此。类同样也是一种对象。只要你使用关键字class，就会在内存中创建一个对象。 上面的例子中会创建一个名叫ObjectCreator的对象。这个对象（类）自身拥有创建对象（类实例）的能力，而这就是为什么它是一个类的原因。但是，它的本质仍然是一个对象，于是乎你可以对它做如下的操作： 1 你可以将它赋值给一个变量2 你可以拷贝它3 你可以为它增加属性4 你可以将它作为函数参数进行传递 动态地创建类因为类也是对象，你可以在运行时动态的创建它们，就像其他任何对象一样。首先，你可以在函数中创建类：123456789101112131415&gt;&gt;&gt; def choose_class(name):… if name == 'foo':… class Foo(object):… pass… return Foo # 返回的是类，不是类的实例… else:… class Bar(object):… pass… return Bar…&gt;&gt;&gt; MyClass = choose_class('foo')&gt;&gt;&gt; print MyClass # 函数返回的是类，不是类的实例&lt;class '__main__'.Foo&gt;&gt;&gt;&gt; print MyClass() # 你可以通过这个类创建类实例，也就是对象&lt;__main__.Foo object at 0x89c6d4c&gt; 这还不够动态，因为你仍然需要自己编写整个类的代码。由于类也是对象，所以它们必须是通过什么东西来生成的才对。 还记得内建函数type吗？这个古老但强大的函数能够让你知道一个对象的类型是什么，就像这样：12345678&gt;&gt;&gt; print type(1) #数值的类型&lt;type 'int'&gt;&gt;&gt;&gt; print type(\"1\") #字符串的类型&lt;type 'str'&gt;&gt;&gt;&gt; print type(ObjectCreator()) #实例对象的类型&lt;class '__main__.ObjectCreator'&gt;&gt;&gt;&gt; print type(ObjectCreator) #类的类型&lt;type 'type'&gt; 仔细观察上面的运行结果，发现使用type对ObjectCreator查看类型是，答案为type，接下来解释一下原因。 使用type创建类type还有一种完全不同的功能，动态的创建类。 type可以接受一个类的描述作为参数，然后返回一个类。（根据传入参数的不同，同一个函数拥有两种完全不同的用法是一件很傻的事情，但这在Python中是为了保持向后兼容性） type可以像这样工作：1type(类名, 由父类名称组成的元组（针对继承的情况，可以为空），包含属性的字典（名称和值）) 比如下面的代码：12&gt;&gt;&gt; class MyShinyClass(object):… pass 可以手动像这样创建：12345&gt;&gt;&gt; MyShinyClass = type('MyShinyClass', (), &#123;&#125;) # 返回一个类对象&gt;&gt;&gt; print MyShinyClass&lt;class '__main__.MyShinyClass'&gt;&gt;&gt;&gt; print MyShinyClass() # 创建一个该类的实例&lt;__main__.MyShinyClass object at 0x8997cec&gt; 你会发现我们使用“MyShinyClass”作为类名，并且也可以把它当做一个变量来作为类的引用。即type函数中第1个实参，也可以叫做其他的名字，这个名字表示类的名字。 使用type创建带有属性的类type 接受一个字典来为类定义属性，因此:12&gt;&gt;&gt; class Foo(object):… bar = True 可以翻译为1&gt;&gt;&gt; Foo = type('Foo', (), &#123;'bar':True&#125;) 并且可以将Foo当成一个普通的类一样使用：123456789&gt;&gt;&gt; print Foo&lt;class '__main__.Foo'&gt;&gt;&gt;&gt; print Foo.barTrue&gt;&gt;&gt; f = Foo()&gt;&gt;&gt; print f&lt;__main__.Foo object at 0x8a9b84c&gt;&gt;&gt;&gt; print f.barTrue 当然，你可以向这个类继承，所以，如下的代码：12&gt;&gt;&gt; class FooChild(Foo):… pass 就可以写成：12345&gt;&gt;&gt; FooChild = type('FooChild', (Foo,),&#123;&#125;)&gt;&gt;&gt; print FooChild&lt;class '__main__.FooChild'&gt;&gt;&gt;&gt; print FooChild.bar # bar属性是由Foo继承而来True 注意： type的第2个参数，元组中是父类的名字，而不是字符串。 添加的属性是类属性，并不是实例属性。使用type创建带有方法的类最终你会希望为你的类增加方法。只需要定义一个有着恰当签名的函数并将其作为属性赋值就可以了。1234567891011&gt;&gt;&gt; def echo_bar(self):… print self.bar…&gt;&gt;&gt; FooChild = type('FooChild', (Foo,), &#123;'echo_bar': echo_bar&#125;)&gt;&gt;&gt; hasattr(Foo, 'echo_bar')False&gt;&gt;&gt; hasattr(FooChild, 'echo_bar')True&gt;&gt;&gt; my_foo = FooChild()&gt;&gt;&gt; my_foo.echo_bar()True 你可以看到，在Python中，类也是对象，你可以动态的创建类。这就是当你使用关键字class时Python在幕后做的事情，而这就是通过元类来实现的。 元类元类就是用来创建类的“东西”。换句话说，元类就是类的类：12MyClass = MetaClass()MyObject = MyClass() 你已经看到了type可以让你像这样做：1MyClass = type('MyClass', (), &#123;&#125;) 这是因为函数type实际上是一个元类。type就是Python在背后用来创建所有类的元类。现在你想知道那为什么type会全部采用小写形式而不是Type呢？好吧，我猜这是为了和str保持一致性，str是用来创建字符串对象的类，而int是用来创建整数对象的类。type就是创建类对象的类。你可以通过检查__class__属性来看到这一点。Python中所有的东西，注意，我是指所有的东西——都是对象。这包括整数、字符串、函数以及类。它们全部都是对象，而且它们都是从一个类创建而来，这个类就是type。12345678910111213&gt;&gt;&gt; age = 35&gt;&gt;&gt; age.__class__&lt;type 'int'&gt;&gt;&gt;&gt; name = 'bob'&gt;&gt;&gt; name.__class__&lt;type 'str'&gt;&gt;&gt;&gt; def foo(): pass&gt;&gt;&gt;foo.__class__&lt;type 'function'&gt;&gt;&gt;&gt; class Bar(object): pass&gt;&gt;&gt; b = Bar()&gt;&gt;&gt; b.__class__&lt;class '__main__.Bar'&gt; 现在，对于任何一个__class__的__class__属性又是什么呢？12345678&gt;&gt;&gt; a.__class__.__class__&lt;type 'type'&gt;&gt;&gt;&gt; age.__class__.__class__&lt;type 'type'&gt;&gt;&gt;&gt; foo.__class__.__class__&lt;type 'type'&gt;&gt;&gt;&gt; b.__class__.__class__&lt;type 'type'&gt; 因此，元类就是创建类这种对象的东西。type就是Python的内建元类，当然了，你也可以创建自己的元类。 __metaclass__属性你可以在定义一个类的时候为其添加__metaclass__属性。123class Foo(object): __metaclass__ = something… ...省略... 如果你这么做了，Python就会用元类来创建类Foo。小心点，这里面有些技巧。你首先写下class Foo(object)，但是类Foo还没有在内存中创建。Python会在类的定义中寻找__metaclass__属性，如果找到了，Python就会用它来创建类Foo，如果没有找到，就会用内建的type来创建这个类。把下面这段话反复读几次。当你写如下代码时 :12class Foo(Bar): pass Python做了如下的操作： Foo中有__metaclass__这个属性吗？如果是，Python会通过__metaclass__创建一个名字为Foo的类(对象) 如果Python没有找到__metaclass__，它会继续在Bar（父类）中寻找__metaclass__属性，并尝试做和前面同样的操作。 如果Python在任何父类中都找不到__metaclass__，它就会在模块层次中去寻找__metaclass__，并尝试做同样的操作。 如果还是找不到__metaclass__,Python就会用内置的type来创建这个类对象。 现在的问题就是，你可以在__metaclass__中放置些什么代码呢？答案就是：可以创建一个类的东西。那么什么可以用来创建一个类呢？type，或者任何使用到type或者子类化type的东东都可以。 自定义元类元类的主要目的就是为了当创建类时能够自动地改变类。通常，你会为API做这样的事情，你希望可以创建符合当前上下文的类。 假想一个很傻的例子，你决定在你的模块里所有的类的属性都应该是大写形式。有好几种方法可以办到，但其中一种就是通过在模块级别设定__metaclass__。采用这种方法，这个模块中的所有类都会通过这个元类来创建，我们只需要告诉元类把所有的属性都改成大写形式就万事大吉了。 幸运的是，metaclass实际上可以被任意调用，它并不需要是一个正式的类。所以，我们这里就先以一个简单的函数作为例子开始。Python2中123456789101112131415161718192021#-*- coding:utf-8 -*-def upper_attr(future_class_name, future_class_parents, future_class_attr): #遍历属性字典，把不是__开头的属性名字变为大写 newAttr = &#123;&#125; for name,value in future_class_attr.items(): if not name.startswith(\"__\"): newAttr[name.upper()] = value #调用type来创建一个类 return type(future_class_name, future_class_parents, newAttr)class Foo(object): __metaclass__ = upper_attr #设置Foo类的元类为upper_attr bar = 'bip'print(hasattr(Foo, 'bar'))print(hasattr(Foo, 'BAR'))f = Foo()print(f.BAR) Python3中1234567891011121314151617181920#-*- coding:utf-8 -*-def upper_attr(future_class_name, future_class_parents, future_class_attr): #遍历属性字典，把不是__开头的属性名字变为大写 newAttr = &#123;&#125; for name,value in future_class_attr.items(): if not name.startswith(\"__\"): newAttr[name.upper()] = value #调用type来创建一个类 return type(future_class_name, future_class_parents, newAttr)class Foo(object, metaclass=upper_attr): bar = 'bip'print(hasattr(Foo, 'bar'))print(hasattr(Foo, 'BAR'))f = Foo()print(f.BAR) 现在让我们再做一次，这一次用一个真正的class来当做元类。1234567891011121314151617181920212223242526272829303132333435363738394041424344#coding=utf-8class UpperAttrMetaClass(type): # __new__ 是在__init__之前被调用的特殊方法 # __new__是用来创建对象并返回之的方法 # 而__init__只是用来将传入的参数初始化给对象 # 你很少用到__new__，除非你希望能够控制对象的创建 # 这里，创建的对象是类，我们希望能够自定义它，所以我们这里改写__new__ # 如果你希望的话，你也可以在__init__中做些事情 # 还有一些高级的用法会涉及到改写__call__特殊方法，但是我们这里不用 def __new__(cls, future_class_name, future_class_parents, future_class_attr): #遍历属性字典，把不是__开头的属性名字变为大写 newAttr = &#123;&#125; for name,value in future_class_attr.items(): if not name.startswith(\"__\"): newAttr[name.upper()] = value # 方法1：通过'type'来做类对象的创建 # return type(future_class_name, future_class_parents, newAttr) # 方法2：复用type.__new__方法 # 这就是基本的OOP编程，没什么魔法 # return type.__new__(cls, future_class_name, future_class_parents, newAttr) # 方法3：使用super方法 return super(UpperAttrMetaClass, cls).__new__(cls, future_class_name, future_class_parents, newAttr)#Python2的用法class Foo(object): __metaclass__ = UpperAttrMetaClass bar = 'bip'# python3的用法# class Foo(object, metaclass = UpperAttrMetaClass):# bar = 'bip'print(hasattr(Foo, 'bar'))# 输出: Falseprint(hasattr(Foo, 'BAR'))# 输出:Truef = Foo()print(f.BAR)# 输出:'bip' 参考资料[^1]: What is a metaclass in Python?","tags":[{"name":"python","slug":"python","permalink":"http://likernel.github.io/tags/python/"}]},{"title":"Python的函数参数传递","date":"2017-08-08T19:59:57.000Z","path":"2017/08/09/Python的函数参数传递/","text":"本文主要探究一下Python的函数参数传递方式。这是初学者必须知道的一个知识点，也是面试之中经常出现的问题，这个做一个总结。 对象和变量Python和一些类C的语言很不一样，在Python中，类型是属于对象的，变量是没有类型的。所有的变量都可以理解是内存中的一个对象的“引用”，或者，也可以看似C中void*。 mutable &amp; immutable对应于上一个概念，这里引出另一个概念，可更改（mutable）对象与不可更改（immutable）对象。 我们都知道，在Python中，strings, tuples, 和numbers是不可更改的对象，而list,dict等则是可以修改的对象。 可改变和不可改变的含义，看下面的例子：123456&gt;&gt;&gt; a = 1&gt;&gt;&gt; id(a)26722648&gt;&gt;&gt; a = 2&gt;&gt;&gt; id(a)26722624 内存中原始的1对象因为不能改变，于是被“抛弃”，a指向一个新的int对象，其值为2。很明显发生了变化。 12345678910111213&gt;&gt;&gt; b = [1]&gt;&gt;&gt; id(b)140444991150560&gt;&gt;&gt; id(b[0])26722648&gt;&gt;&gt; b[0] = 2&gt;&gt;&gt; id(b)140444991150560&gt;&gt;&gt; id(b[0])26722624 因为list是可改变的，所以，第一个元素变更为2。其实应该说，b指向一个包含一个对象的数组。赋值所发生的事情，是有一个新int对象被指定给b所指向的数组对象的第一个元素，但是对于b本身来说，所指向的数组对象并没有变化，只是数组对象的内容发生变化了。这个看似void*的变量所指向的对象仍旧是刚刚的那个有一个int对象的list。 函数参数传递根据上面的概念，我们再来研究一下Python函数参数的传递。 不可变对象参数调用：1234567def foo(a): a = 10b = 2foo(b)print b 结果为：2。 可变对象参数调用123456def foo(a): a[0] = 10b = [2]foo(b)print b 结果为：[10] Python函数参数传递和变量传值操作是一样的，如果这个变量的值不变，我们看似就是引用，如果这个变量的值改变，我们看着像是在赋值。","tags":[{"name":"python","slug":"python","permalink":"http://likernel.github.io/tags/python/"}]},{"title":"Python练习册--头像右上角添加数字","date":"2017-08-07T03:02:19.000Z","path":"2017/08/07/Python练习册-头像右上角添加数字/","text":"在知乎上看到的推荐，感觉还有点意思，遂记录之，这是开篇。 题目地址：点这里。 题目描述第 0000 题：将你的QQ头像（或者微博头像）右上角加上红色的数字，类似于微信未读信息数量那种提示效果。类似于图中效果： PILPIL：Python Imaging Library，Python平台上的图像处理库。PIL功能强大，而且API简单易用。但是PIL仅支持到Python 2.7，有人在PIL的基础上创建了兼容的版本，名字叫Pillow，支持最新Python3.x，又加入了许多新特性，因此，我们可以直接安装使用Pillow。 下面给出pillow的官方文档。 ImageDraw首先，研究一下官方文档：The ImageDraw module provides simple 2D graphics for Image objects. You can use this module to create new images, annotate or retouch existing images, and to generate graphics on the fly for web use. Example:Draw a gray cross over an image1234567891011from PIL import Image, ImageDrawim = Image.open(\"hopper.jpg\")draw = ImageDraw.Draw(im)draw.line((0, 0) + im.size, fill=128)draw.line((0, im.size[1], im.size[0], 0), fill=128)del draw# write to stdoutim.save(sys.stdout, \"PNG\") 大致分为以下几个步骤： 1.打开图片2.创建对象3.绘制4.输出 绘制这是最核心的部分，我们进行详细的讨论，题目给的要求是：右上角加上红色的数字。 这里有两个关键点： 1.右上角2.红色 实现：1234567891011121314151617181920212223# _*_ coding:utf-8 _*___author__ = 'daqing'__date__ = '2017/8/7 19:30'from PIL import Image,ImageDraw,ImageFontdef addNum(nub,filepath): img = Image.open(filepath) # 新建draw对象 draw = ImageDraw.Draw(img) width,height = img.size fontSize = height/4 #字体 myFont = ImageFont.truetype('arial.ttf',fontSize) #位置，数字，颜色，字体 draw.text((width-fontSize,0),nub,(256,0,0),font=myFont) del draw img.save('res.png')if __name__ == '__main__': addNum('10','test.png') 效果头像： 添加数字后：","tags":[{"name":"python","slug":"python","permalink":"http://likernel.github.io/tags/python/"}]},{"title":"Python作用域","date":"2017-08-07T00:47:05.000Z","path":"2017/08/07/Python作用域/","text":"命名空间（namespace）A namespace is a mapping from names to objects. Most namespaces are currently implemented as Python dictionaries。实际上在Python中，命名空间是一个字典（dictionary），它的键就是变量名，它的值就是那些变量的值。在一个Python 程序中的任何一个地方，都存在几个可用的命名空间： 每个函数都有着自已的命名空间，叫做局部命名空间，它记录了函数的变量，包括函数的参数和局部定义的变量。 每个模块拥有它自已的命名空间，叫做全局命名空间，它记录了模块的变量，包括函数、类、其它导入的模块、模块级的变量和常量。 还有就是内置命名空间，任何模块均可访问它，它存放着内置的函数和异常。 作用域（scope）Scope是Python程序的一块文本区域。在该文本区域中，对namespace是可以直接访问，而不需要通过属性来访问。 直接访问：对一个变量名的引用会在所有namespace中查找该变量，而不是通过属性访问。 属性访问：所有名字后加.的都认为是属性访问。区别在Python中，scope是由namespace按特定的层级结构组合起来的。scope一定是namespace，但namespace不一定是scope.LEGB-rulepython的作用域一共有4中，分别是： L （Local） 局部作用域，比如一个函数/方法内部。 E （Enclosing） 闭包函数外的函数中 G （Global） 全局作用域 B （Built-in） 内建作用域，包含了内建的变量/关键字等。 scope的搜索顺序：1Local -&gt; Enclosing -&gt; Global -&gt; Built-in","tags":[{"name":"python","slug":"python","permalink":"http://likernel.github.io/tags/python/"}]},{"title":"Python装饰器","date":"2017-08-06T22:54:17.000Z","path":"2017/08/07/Python装饰器/","text":"装饰器是程序开发中经常会用到的一个功能，用好了装饰器，开发效率如虎添翼，同时，这也是Python面试中必问的问题。 例子先看下下面的例子： 需求假设某公司已经实现了一系列基础功能，如：数据库操作、redis调用、监控API等功能。业务部门使用基础功能时，只需调用基础平台提供的功能即可。如下：12345def f1(): print(&apos;f1&apos;)def f2(): print(&apos;f2&apos;) 业务部门需要使用基础平台提供的功能，直接调用就好了:12f1()f2() 现在问题来了：以前基础平台的开发人员在写代码时候没有关注验证相关的问题，现在需要对基础平台的所有功能进行重构，为平台提供的所有功能添加验证机制，即：执行功能前，先进行验证。 重构方案一将需要进行的验证操作，写入到每个函数中。1234567891011def f1(): # 验证1 # 验证2 # 验证3 print(&apos;f1&apos;)def f2(): # 验证1 # 验证2 # 验证3 print(&apos;f2&apos;) 如果我们需要的验证操作很多，这种方式显然不合理。 重构方案二我们把验证操作封装到一个函数中。12345def check_login(): # 验证1 # 验证2 # 验证3 pass 在函数中，对check_login()进行调用即可:1234567891011def f1(): check_login() print(&apos;f1&apos;)def f2(): check_login() print(&apos;f2&apos;) 上面的做法可行，但不遵循开放封闭原则，虽然在这个原则是用的面向对象开发，但是也适用于函数式编程，简单来说，它规定已经实现的功能代码不允许被修改，但可以被扩展，即： 1.封闭：已实现的功能代码块2.开放：对扩展开发 如果将开放封闭原则应用在上述需求中，那么就不允许在函数 f1 、f2的内部进行修改代码。 重构方案三使用装饰器：1234567891011121314def w1(func): def inner(): # 验证1 # 验证2 # 验证3 func() return inner@w1def f1(): print(&apos;f1&apos;)@w1def f2(): print(&apos;f2&apos;) 对于上述代码，仅仅对基础平台的代码进行修改，就可以实现在其他人调用函数f1 f2之前都进行验证操作，并且业务部门无需做任何操作。 原理单独以f1为例：1234567891011def w1(func): def inner(): # 验证1 # 验证2 # 验证3 func() return inner@w1def f1(): print(&apos;f1&apos;) python解释器就会从上到下解释代码，步骤如下：121.def w1(func): ==&gt;将w1函数加载到内存2.@w1 从表面上看解释器仅仅会解释这两句代码，因为函数在没有被调用之前其内部代码不会被执行。 但是@w1这一句代码里却有大文章，@函数名是python的一种语法糖。@w1内部会执行以下操作： 执行w1函数执行w1函数，并将@w1下面的函数作为w1函数的参数，即：@w1等价于 w1(f1)所以，内部就会去执行：1234567def w1(func): def inner(): #验证 1 #验证 2 #验证 3 f1() # func是参数，此时 func 等于 f1 return inner 返回的inner，inner代表的是函数，非执行函数，其实就是将原来的f1函数塞进另外一个函数中。 w1的返回值将执行完的w1函数返回值赋值给@w1下面的函数的函数名f1即将w1的返回值再重新赋值给f1，即：123456新f1 = def inner(): #验证 1 #验证 2 #验证 3 原来f1() return inner 所以，以后业务部门想要执行f1 函数时，就会执行新f1函数，在新f1函数内部先执行验证，再执行原来的f1函数，然后将原来f1函数的返回值返回给了业务调用者。 再议装饰器12345678910111213141516171819202122232425262728#定义函数：完成包裹数据def makeBold(fn): def wrapped(): return &quot;&lt;b&gt;&quot; + fn() + &quot;&lt;/b&gt;&quot; return wrapped#定义函数：完成包裹数据def makeItalic(fn): def wrapped(): return &quot;&lt;i&gt;&quot; + fn() + &quot;&lt;/i&gt;&quot; return wrapped@makeBolddef test1(): return &quot;hello world-1&quot;@makeItalicdef test2(): return &quot;hello world-2&quot;@makeBold@makeItalicdef test3(): return &quot;hello world-3&quot;print(test1()))print(test2()))print(test3())) 运行结果:123&lt;b&gt;hello world-1&lt;/b&gt;&lt;i&gt;hello world-2&lt;/i&gt;&lt;b&gt;&lt;i&gt;hello world-3&lt;/i&gt;&lt;/b&gt; 备注：多个装饰器的调用顺序是自下往上，但是运行时的执行顺序是自上往下。 装饰器的应用1.引入日志2.函数执行时间统计3.执行函数前预备处理4.执行函数后清理功能5.权限校验等场景6.缓存 被装饰的函数无参数123456789101112131415from time import ctime, sleepdef timefun(func): def wrappedfunc(): print(&quot;%s called at %s&quot;%(func.__name__, ctime())) func() return wrappedfunc@timefundef foo(): print(&quot;I am foo&quot;)foo()sleep(2)foo() 上面代码理解装饰器执行行为可理解成123456foo = timefun(foo)#foo先作为参数赋值给func后,foo接收指向timefun返回的wrappedfuncfoo()#调用foo(),即等价调用wrappedfunc()#内部函数wrappedfunc被引用，所以外部函数的func变量(自由变量)并没有释放#func里保存的是原foo函数对象 被装饰的函数有参数12345678910111213141516from time import ctime, sleepdef timefun(func): def wrappedfunc(a, b): print(&quot;%s called at %s&quot;%(func.__name__, ctime())) print(a, b) func(a, b) return wrappedfunc@timefundef foo(a, b): print(a+b)foo(3,5)sleep(2)foo(2,4) 被装饰的函数有不定长参数123456789101112131415from time import ctime, sleepdef timefun(func): def wrappedfunc(*args, **kwargs): print(&quot;%s called at %s&quot;%(func.__name__, ctime())) func(*args, **kwargs) return wrappedfunc@timefundef foo(a, b, c): print(a+b+c)foo(3,5,7)sleep(2)foo(2,4,9) 装饰器中的return12345678910111213141516171819202122from time import ctime, sleepdef timefun(func): def wrappedfunc(): print(&quot;%s called at %s&quot;%(func.__name__, ctime())) func() return wrappedfunc@timefundef foo(): print(&quot;I am foo&quot;)@timefundef getInfo(): return &apos;----hahah---&apos;foo()sleep(2)foo()print(getInfo()) 一般情况下为了让装饰器更通用，可以有return 装饰器带参数,在原有装饰器的基础上，设置外部变量123456789101112131415161718192021222324252627#decorator2.pyfrom time import ctime, sleepdef timefun_arg(pre=&quot;hello&quot;): def timefun(func): def wrappedfunc(): print(&quot;%s called at %s %s&quot;%(func.__name__, ctime(), pre)) return func() return wrappedfunc return timefun@timefun_arg(&quot;test&quot;)def foo(): print(&quot;I am foo&quot;)@timefun_arg(&quot;python&quot;)def too(): print(&quot;I am too&quot;)foo()sleep(2)foo()too()sleep(2)too() 可以理解为1foo()==timefun_arg(&quot;test&quot;)(foo)() 类装饰器装饰器函数其实是这样一个接口约束，它必须接受一个callable对象作为参数，然后返回一个callable对象。在Python中一般callable对象都是函数，但也有例外。只要某个对象重写了 __call__() 方法，那么这个对象就是callable的。123456class Test(): def __call__(self): print(&apos;call me!&apos;)t = Test()t() # call me 类装饰器demo123456789101112131415161718192021222324class Test(object): def __init__(self, func): print(&quot;---初始化---&quot;) print(&quot;func name is %s&quot;%func.__name__) self.__func = func def __call__(self): print(&quot;---装饰器中的功能---&quot;) self.__func()#说明：#1. 当用Test来装作装饰器对test函数进行装饰的时候，首先会创建Test的实例对象# 并且会把test这个函数名当做参数传递到__init__方法中# 即在__init__方法中的func变量指向了test函数体##2. test函数相当于指向了用Test创建出来的实例对象##3. 当在使用test()进行调用时，就相当于让这个对象()，因此会调用这个对象的__call__方法##4. 为了能够在__call__方法中调用原来test指向的函数体，所以在__init__方法中就需要一个实例属性来保存这个函数体的引用# 所以才有了self.__func = func这句代码，从而在调用__call__方法中能够调用到test之前的函数体@Testdef test(): print(&quot;----test---&quot;)test()showpy()#如果把这句话注释，重新运行程序，依然会看到&quot;--初始化--&quot; 运行结果如下：1234---初始化---func name is test---装饰器中的功能-------test---","tags":[{"name":"python","slug":"python","permalink":"http://likernel.github.io/tags/python/"}]},{"title":"Python闭包","date":"2017-08-06T21:52:16.000Z","path":"2017/08/07/Python闭包/","text":"介绍Python闭包。 函数的引用首先，看一下下面的例子：1234567891011121314def test1(): print(\"--- in test1 func----\")#调用函数test1()#引用函数ret = test1print(id(ret))print(id(test1))#通过引用调用函数ret() 运行结果：1234--- in test1 func----140212571149040140212571149040--- in test1 func---- 一图胜千言： 闭包在函数内部再定义一个函数，并且这个函数用到了外边函数的变量，那么将这个函数以及用到的一些变量称之为闭包。123456789101112131415#定义一个函数def test(number): def test_in(number_in): print(\"in test_in 函数, number_in is %d\"%number_in) return number+number_in #这里返回的就是闭包的结果 return test_in#给test函数赋值，这个20就是给参数numberret = test(20)#注意这里的100其实给参数number_inprint(ret(100))#注意这里的200其实给参数number_inprint(ret(200)) 运行结果：12345in test_in 函数, number_in is 100120in test_in 函数, number_in is 200220 闭包再理解内部函数对外部函数作用域里变量的引用（非全局变量），则称内部函数为闭包。12345678# closure.pydef counter(start=0): count=[start] def incr(): count[0] += 1 return count[0] return incr 启动python解释器1234567891011&gt;&gt;&gt;import closeure&gt;&gt;&gt;c1=closeure.counter(5)&gt;&gt;&gt;print(c1())6&gt;&gt;&gt;print(c1())7&gt;&gt;&gt;c2=closeure.counter(100)&gt;&gt;&gt;print(c2())101&gt;&gt;&gt;print(c2())102 nonlocal访问外部函数的局部变量(python3)1234567891011121314151617181920def counter(start=0): def incr(): nonlocal start start += 1 return start return incrc1 = counter(5)print(c1())print(c1())c2 = counter(50)print(c2())print(c2())print(c1())print(c1())print(c2())print(c2()) 看一个闭包的实际例子：123456789def line_conf(a, b): def line(x): return a*x + b return lineline1 = line_conf(1, 1)line2 = line_conf(4, 5)print(line1(5))print(line2(5)) 这个例子中，函数line与变量a,b构成闭包。在创建闭包的时候，我们通过line_conf的参数a,b说明了这两个变量的取值，这样，我们就确定了函数的最终形式(y = x + 1和y = 4x + 5)。我们只需要变换参数a,b，就可以获得不同的直线表达函数。由此，我们可以看到，闭包也具有提高代码可复用性的作用。 如果没有闭包，我们需要每次创建直线函数的时候同时说明a,b,x。这样，我们就需要更多的参数传递，也减少了代码的可移植性。 闭包思考：1.闭包似优化了变量，原来需要类对象完成的工作，闭包也可以完成。2.由于闭包引用了外部函数的局部变量，则外部函数的局部变量没有及时释放，消耗内存。","tags":[{"name":"python","slug":"python","permalink":"http://likernel.github.io/tags/python/"}]},{"title":"Python迭代器","date":"2017-08-04T22:12:34.000Z","path":"2017/08/05/Python迭代器/","text":"本文主要介绍Python迭代器的相关知识。在此之前，先用一幅图，了解下容器(container)、可迭代对象(iterable)、迭代器(iterator)、生成器(generator)、列表/集合/字典推导式(list,set,dict comprehension)等概念的一些关系（本图片来源于互联网，由于画的很好，这里借鉴过来）。 容器(container)容器是一种把多个元素组织在一起的数据结构，容器中的元素可以逐个地迭代获取，可以用in,not in关键字判断元素是否包含在容器中。通常这类数据结构把所有的元素存储在内存中（也有一些特例，并不是所有的元素都放在内存，比如迭代器和生成器对象）在Python中，常见的容器对象有：12345list, deque, ....set, frozensets, ....dict, defaultdict, OrderedDict, Counter, ....tuple, namedtuple, ....str 容器比较容易理解，因为你就可以把它看作是一个盒子、一栋房子、一个柜子，里面可以塞任何东西。从技术角度来说，当它可以用来询问某个元素是否包含在其中时，那么这个对象就可以认为是一个容器。 可迭代对象(iterable)可直接作用域for循环的类型，主要包括以下几类： 1.集合数据类型，如 list 、 tuple 、 dict 、 set 、 str 等；2.generator ，包括生成器和带 yield 的generator function。 这些可以直接作用于 for 循环的对象统称为可迭代对象： Iterable 。 判断是否可以迭代可以使用 isinstance() 判断一个对象是否是 Iterable 对象:123456from collections import Iterableisinstance([], Iterable) # Trueisinstance(&#123;&#125;, Iterable) # Trueisinstance('abc', Iterable) # Trueisinstance((x for x in range(10)), Iterable) # Trueisinstance(100, Iterable) # False 而生成器不但可以作用于 for 循环，还可以被 next() 函数不断调用并返回下一个值，直到最后抛出 StopIteration 错误表示无法继续返回下一个值了。 迭代器(Iterator)它是一个带状态的对象，他能在你调用next()方法的时候返回容器中的下一个值。如果容器中没有更多元素了，则抛出StopIteration异常。 所以，迭代器就是实现了工厂模式的对象，它在你每次你询问要下一个值的时候给你返回。 比如itertools函数返回的都是迭代器对象。 生成无限序列：123456&gt;&gt;&gt; from itertools import count&gt;&gt;&gt; counter = count(start=13)&gt;&gt;&gt; next(counter)13&gt;&gt;&gt; next(counter)14 从一个有限序列中生成无限序列：12345678910&gt;&gt;&gt; from itertools import cycle&gt;&gt;&gt; colors = cycle(['red', 'white', 'blue'])&gt;&gt;&gt; next(colors)'red'&gt;&gt;&gt; next(colors)'white'&gt;&gt;&gt; next(colors)'blue'&gt;&gt;&gt; next(colors)'red' 从无限的序列中生成有限序列：123456789&gt;&gt;&gt; from itertools import islice&gt;&gt;&gt; colors = cycle(['red', 'white', 'blue']) # infinite&gt;&gt;&gt; limited = islice(colors, 0, 4) # finite&gt;&gt;&gt; for x in limited: ... print(x)redwhitebluered 为了更直观地感受迭代器内部的执行过程，我们自定义一个迭代器，以斐波那契数列为例：1234567891011121314151617class Fib: def __init__(self): self.prev = 0 self.curr = 1 def __iter__(self): return self def __next__(self): value = self.curr self.curr += self.prev self.prev = value return value&gt;&gt;&gt; f = Fib()&gt;&gt;&gt; list(islice(f, 0, 10))[1, 1, 2, 3, 5, 8, 13, 21, 34, 55] 实例变量prev和curr用户维护迭代器内部的状态。每次调用next()方法的时候做两件事： 1.为下一次调用next()方法修改状态2.为当前这次调用生成返回结果 迭代器就像一个懒加载的工厂，等到有人需要的时候才给它生成值返回，没调用的时候就处于休眠状态等待下一次调用。 判断Iterator对象可以使用 isinstance()判断一个对象是否是Iterator对象：123456from collections import Iteratorisinstance((x for x in range(10)), Iterator) # Trueisinstance([], Iterator) # Falseisinstance(&#123;&#125;, Iterator) # Falseisinstance('abc', Iterator) # Falseisinstance(100, Iterator) # False iter()函数生成器都是Iterator对象，但 list、dict、str 虽然是 Iterable，却不是Iterator。 把 list、dict 、str等Iterable变成Iterator可以使用iter() 函数：12isinstance(iter([]), Iterator) # Trueisinstance(iter('abc'), Iterator) # True 参考资料：","tags":[{"name":"python","slug":"python","permalink":"http://likernel.github.io/tags/python/"}]},{"title":"leetcode--Divide Two Integers","date":"2017-08-04T08:32:06.000Z","path":"2017/08/04/leetcode-Divide-Two-Integers/","text":"Divide two integers without using multiplication, division and mod operator. If it is overflow, return MAX_INT.不用乘法，除法，求模运算来实现两个整数相除。正是之前提到的位运算。 思路： 首先，我们知道任何一个整数都可以表示成以2的幂为底的一组基的线性组合，即num = flag0 2^0 + flag1 2^1 + flag2 2^2 + … + flagn 2^n 其中，flag0, flag1, flag2, …, flagn 取值为0或1。 因此，如果令：dividend / divisor = num dividend = divisor num = divisor (flag0 2^0 + flag1 2^1 + flag2 2^2 + … + flagn 2^n) 对于除数，使用移位操作&lt;&lt;使其每次翻倍，从而减少减法求商的次数。以下是步骤： 1.当被除数大于除数时，对除数乘2（代码中使用变量temp用于记录每次除数乘2），直到temp大于被除数为止。记录移位操作的次数i。2.如果被除数大于除数，那么被除数减去temp。直到被除数小于除数。保存结果。3.判断正负，输出结果res。 实现：1234567891011121314151617def divide(dividend, divisor): sign = (dividend &lt; 0 and divisor &gt; 0) or (dividend &gt; 0 and divisor &lt; 0) a, b = abs(dividend), abs(divisor) res, temp = 0, 0 # 被除数大于除数 while a &gt;= b: temp = b i = 0 while a &gt;= temp: a -= temp res += (1&lt;&lt;i) i += 1 temp &lt;&lt;= 1 if sign: res = -res return min(max(-2147483648, res), 2147483647) 备注：int：-2147483648~2147483647 (4Bytes)","tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://likernel.github.io/tags/leetcode/"},{"name":"算法","slug":"算法","permalink":"http://likernel.github.io/tags/算法/"}]},{"title":"Python私有化","date":"2017-08-04T07:31:10.000Z","path":"2017/08/04/Python私有化/","text":"主要介绍Python的私有化。 命名规则xx公有变量。 _x单前置下划线,私有化属性或方法。当使用from module import * 导入时，_x变量并不会导入,类对象和子类可以访问。 __xx双前置下划线,避免与子类中的属性命名冲突，无法在外部直接访问。实际上通过namemangling方式可以调用，访问不了是因为名字重整，如\\_x会被重整为_className__x, className为类名。 __xx__双前后下划线,用户名字空间的魔法对象或属性。例如:_init_ , __ 。一般是系统提供的。 xx_单后置下划线,用于避免与Python关键词的冲突。 私有属性添加getter和setter方法123456789101112class Money(object): def __init__(self): self.__money = 0 def getMoney(self): return self.__money def setMoney(self, value): if isinstance(value, int): self.__money = value else: print(\"error:不是整型数字\") 使用property升级getter和setter方法12345678910111213class Money(object): def __init__(self): self.__money = 0 def getMoney(self): return self.__money def setMoney(self, value): if isinstance(value, int): self.__money = value else: print(\"error:不是整型数字\") money = property(getMoney, setMoney) 使用property取代getter和setter方法@property成为属性函数，可以对属性赋值时做必要的检查，并保证代码的清晰短小，主要有2个作用： 1.将方法转换为只读2.重新实现一个属性的设置和读取方法,可做边界判定1234567891011121314class Money(object): def __init__(self): self.__money = 0 @property def money(self): return self.__money @money.setter def money(self, value): if isinstance(value, int): self.__money = value else: print(\"error:不是整型数字\")","tags":[{"name":"python","slug":"python","permalink":"http://likernel.github.io/tags/python/"}]},{"title":"Python位运算","date":"2017-08-04T03:08:57.000Z","path":"2017/08/04/Python位运算/","text":"之前刷leetcode的时候发现，有些题目用位运算实施起来非常高效，而且位运算也是面试中经常会问到的知识点，这里做一个总结。实际上各种编程语言都提供了位运算，原理和使用基本一致，这里不做区分。 原码、反码、补码计算机中对数字的表示有三种方式：原码，反码，补码： 原码原码表示法在数值前面增加了一位符号位（即最高位为符号位）：正数该位为0，负数该位为1。 反码反码表示法，正数的反码是其本身；负数的反码是在其原码的基础上，符号位不变，其余各个位取反。 补码补码表示法，正数的补码是其本身；负数的补码是在其原码的基础上，符号位不变，其余各位取反，最后+1。 (即在反码的基础上+1) 转换1.正数，原码=反码=补码2.负数，原码=补码符号位不变，数据位取反，尾+1 备注：原码容易被人脑直接识别并用于计算，但是对于计算机来说并不友好。所以在计算机系统中，数值一律用补码来表示、运算和存储。同时，还有一个重要原因，使用补码可以将符号位和数值域统一处理，将加法和减法统一处理。 进制转换1.十进制到二进制：bin()2.十进制到八进制：oct()3.十进制到十六进制：hex()4.转成十进制直接使用int(),float()等即可。 位运算位与运算（&amp;）两数各对应的二进位相与,全1为1，否则为0。参与运算的数以补码方式出现。 应用1.按位与运算通常用来对某些位清0或保留某些位。例如，把a的高八位清0,保留低八位。1a = a&amp;255 # 255的二进制数为0000000011111111 2.之前提到过，判断power of 2。12def isPowerOfTwo(n): return (n &gt; 0 and not(n &amp; n-1)) 3.求一个整数有多少位是0(原理同上):1234count=0while x: count += 1 x &amp;= (x-1) 4.判断奇偶数(原理:奇数最后一位为1,偶数为0)1234def odd(x): return x&amp;1def even(x): return !(x&amp;1) 位或运算（|）位或运算,两数各对应的二进位相或,有1就1，全0才0。,参与运算的两个数均以补码出现。 位异或运算（^）位异或运算,两数各对应的二进位相异或,不相同为1,否则为0。参与运算数仍以补码出现。 应用1.数值交换无须引入第三个变量。123a=a^bb=b^aa=a^b # 原理:两次异或能还原,即a=(a^b)^b 2.求x绝对值(原理:x为正数时不做改变,为负数时取反加1)123456# x为正数时y=0=0000 0000 0000 0000# x为负数时y=-1=1111 1111 1111 1111# 跟0异或是本身,跟1异或是取反:def abs(x): y = x&gt;&gt;31 return (x^y-y) 求反运算(~)具有右结合性,其功能是对参与运算的数的各二进位按位求反。 应用求x的相反数1x = ~x+1 左移(&lt;&lt;)全部向左移（左移n位就是乘以2的n次方） 应用乘法运算（若为奇数可以配合加减运算实现）116&lt;&lt;2 # 64 右移(&gt;&gt;)全部向右移（左移n位就是除以2的n次方） 应用除法运算（若为奇数可以配合加减运算实现）116&gt;&gt;2 # 4 备注：在左移，右移注意int的范围，超出范围会产生溢出，这里不做讨论。","tags":[{"name":"python","slug":"python","permalink":"http://likernel.github.io/tags/python/"}]},{"title":"Python深拷贝和浅拷贝","date":"2017-08-04T01:38:49.000Z","path":"2017/08/04/Python深拷贝和浅拷贝/","text":"主要记录一下，Python中的深拷贝和浅拷贝以及它们之间的区别。 赋值在此之前，我们首先归纳下赋值操作，这对后面的理解很有帮助。 1.赋值是将一个对象的地址赋值给一个变量，让变量指向该地址。2.修改不可变对象（str、tuple）需要开辟新的空间3.修改可变对象（list等）不需要开辟新的空间 区别这里主要介绍，直接赋值、浅拷贝(copy)以及深拷贝(deepcopy)的区别。 ####直接赋值其实就是对象的引用。 直接赋值 b=a的操作实际上是b引用a对象的地址，将来a的值变化了，b也会跟着变化。 浅拷贝(copy)还是上面的例子，当b对a进行浅拷贝时，这时候b并未引用a的地址，而是重新在内存中开辟了一块空间。如下图所示： 浅拷贝 可以看出，a和b是一个独立的对象，指向内存中不同的地址。实际上，深拷贝也是如此，区别在于子对象上，浅拷贝的子对象还是指向统一对象，再看下面的例子： 这个例子的a和b就相当于c的子对象，虽然d在浅拷贝c的过程中，重新申请了一块空间，但是子对象a和b还是指向原来的地址。没有往更深层次进行拷贝。 深拷贝(deepcopy)其实，通过上面的例子，已经可以知道，深拷贝，在浅拷贝的基础上对里面所有的子孙对象都进行了更深层次的拷贝。（我们也称之为递归拷贝）。因此，不再赘述。 备注：copy.copy（浅拷贝）和copy.deepcopy（深拷贝）都位于copy模块下。","tags":[{"name":"python","slug":"python","permalink":"http://likernel.github.io/tags/python/"}]},{"title":"leetcode--Power of Two","date":"2017-08-02T02:08:19.000Z","path":"2017/08/02/leetcode-Power-of-Two/","text":"Given an integer, write a function to determine if it is a power of two. 思路： 这道题有一个技巧，还是和位运算有关，首先看下面规律： 2的0次方00012的1次方00102的2次方01002的3次方1000 实际上，因为是二进制数（二进制数不是白叫的），因此所有的Power of Two的二进制数形式均为最高位（不考虑1左边的位）为1，其它都为0。如果此时我们减1的话，则最高位会降一位，其余为0的位现在都为变为1，那么我们把两数相与，就会得到0。如果这个数不是Power of Two就没有这个性质。 实现：12def isPowerOfTwo(n): return (n &gt; 0 and not(n &amp; n-1))","tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://likernel.github.io/tags/leetcode/"},{"name":"算法","slug":"算法","permalink":"http://likernel.github.io/tags/算法/"}]},{"title":"leetcode--Single Number II","date":"2017-08-02T01:04:30.000Z","path":"2017/08/02/leetcode-Single-Number-II/","text":"Given an array of integers, every element appears three times except for one, which appears exactly once. Find that single one. Note:Your algorithm should have a linear runtime complexity. Could you implement it without using extra memory? 思路1： 使用hash实现，这种方法不做赘述，实现如下： 12345678910def singleNumber(self, nums): dict = &#123;&#125; for i in range(len(nums)): if nums[i] not in dict: dict[nums[i]] = 1 else: dict[nums[i]] += 1 for single in dict: if dict[single] == 1: return single 思路2： 和Single Number类似的解法： 1.当数字num第一出现时：ones,twos = num, 0;2.当其第二次出现时：ones,twos = 0, num;3.第三次出现时：ones,twos = 0, 0，就相当于这个数字没有出现过，这样最后的结果就是ones了。 实现：1234567def singleNumber(self, nums): ones, twos = 0, 0 for i in nums: ones = ones^i &amp; ~twos twos = twos^i &amp; ~ones return(ones)","tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://likernel.github.io/tags/leetcode/"},{"name":"算法","slug":"算法","permalink":"http://likernel.github.io/tags/算法/"}]},{"title":"leetcode--Single Number","date":"2017-08-02T00:25:43.000Z","path":"2017/08/02/leetcode-Single-Number/","text":"Given an array of integers, every element appears twice except for one. Find that single one. Note:Your algorithm should have a linear runtime complexity. Could you implement it without using extra memory? 思路：这里使用异或运算，异或运算有如下性质： 1.相同元素异或为0,0与任何数异或等于任何数，有a^b^a=b。 2.此外，异或还可以用于两个元素交换a=a^b^(b=a)。 实现：12345def singleNumber(nums): res = 0 for i in nums: res = res^i return res","tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://likernel.github.io/tags/leetcode/"},{"name":"算法","slug":"算法","permalink":"http://likernel.github.io/tags/算法/"}]},{"title":"leetcode--Reverse Words in a String","date":"2017-08-02T00:08:20.000Z","path":"2017/08/02/leetcode-Reverse-Words-in-a-String/","text":"Given an input string, reverse the string word by word.For example,Given s = &quot;the sky is blue&quot;,return &quot;blue is sky the&quot;. 思路： 拆分字符串，使用split函数，用&#39; &#39;拆分。 去掉空字符，字符串最后一位为空字符。 reverse整个数组并连接。 实现：12345678def reverseWords(s): arr = s.split(' ') while '' in arr: arr.remove('') arr.reverse() str = ' '.join(arr) return str","tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://likernel.github.io/tags/leetcode/"},{"name":"算法","slug":"算法","permalink":"http://likernel.github.io/tags/算法/"}]},{"title":"leetcode--Longest Substring Without Repeating Characters","date":"2017-08-01T21:44:48.000Z","path":"2017/08/02/leetcode-Longest-Substring-Without-Repeating-Characters/","text":"Given a string, find the length of the longest substring without repeating characters. Examples: Given &quot;abcabcbb&quot;, the answer is &quot;abc&quot;, which the length is 3.Given &quot;bbbbb&quot;, the answer is &quot;b&quot;, with the length of 1.Given &quot;pwwkew&quot;, the answer is &quot;wke&quot;, with the length of 3. Note that the answer must be a substring, &quot;pwke&quot; is a subsequence and not a substring. 思路一：使用hash表 变量start记录了子串的起点。 used用来记录字符串的字符，key是字符c，value是索引i。 如果字符之前出现过，start右移，否则，更新最大长度。 实现：12345678910def lengthOfLongestSubstring(self, s): used = &#123;&#125; max_len = start = 0 for i, c in enumerate(s): if c in used and start &lt;= used[c]: start = used[c] + 1 else: max_len = max(max_len, i-start+1) used[c] = i return max_len 备注：注意当前子串的长度为i-start+1。","tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://likernel.github.io/tags/leetcode/"},{"name":"算法","slug":"算法","permalink":"http://likernel.github.io/tags/算法/"}]},{"title":"django工作原理","date":"2017-08-01T04:20:41.000Z","path":"2017/08/01/django工作原理/","text":"主要介绍django的工作原理，其中涉及到Middleware(中间件，包括request, view, exception, response)，URLConf(url映射关系)，Template(模板系统)。 工作流程 下面是一些流程说明： 1.用户通过浏览器请求页面。2.请求到达Request Middlewares中间件，中间件对request做一些预处理或者直接response请求。3.URLConf通过urls.py文件和请求的URL找到相应的View。4.View Middlewares被访问，它同样可以对request做一些处理或者直接返回response。5.调用View中的函数。6.View中的方法可以选择性的通过Models访问底层的数据。7.所有的Model-to-DB的交互都是通过manager完成的。8.如果需要，Views可以使用一个特殊的Context。9.Context被传给Template用来生成页面。10.Template使用Filters和Tags去渲染输出。11.输出被返回到View。12.HTTPResponse被发送到Response Middlewares。13.任何Response Middlewares都可以丰富response或者返回一个完全不同的response。14.Response返回到浏览器，呈现给用户。","tags":[{"name":"django","slug":"django","permalink":"http://likernel.github.io/tags/django/"},{"name":"web开发","slug":"web开发","permalink":"http://likernel.github.io/tags/web开发/"}]},{"title":"二叉搜索树（BST）","date":"2017-07-31T23:39:50.000Z","path":"2017/08/01/二叉搜索树（BST）/","text":"什么是二叉搜索树二叉搜索树，顾名思义，其主要目的用于搜索，它是二叉树结构中最基本的一种数据结构。如下图所示： 二叉搜索树中的关键字总是按照下面的方式存储： 设x为二叉搜索树中的一个节点，如果y是x左子树的一个节点，则y.key &lt;= x.key；如果y是x右子树的一个节点，则y.key &gt;= x.key。 二叉搜索树的遍历中序遍历：左-根-右 上中图，两棵树的中序遍历均为2,5,5,6,7,812345def inorder_tree_walk(x): if x is not null: inorder_tree_walk(x.left) print x.key inorder_tree_walk(x.right) 先序遍历：根-左-右 后序遍历：左-右-根 定理：如果x是一棵有n个子节点的根，那么调用inorder_tree_walk(x)需要O(n)时间。 查询二叉搜索树查找：（小于节点在左树找，大于节点在右树找。）1234567def tree_search(x,k): if x == null or k == x.key: return x elif k &lt; x.key: return tree_search(x.left,k) else: return tree_search(x.right,k) 最大最小：（最大的即找最右边的，最小即找最左边的，以最大为例）1234def tree_max(x): while x.right is not null: x = x.right return x 有时候需要按照中序遍历的次序查找某个节点的后继。分两种情况： 有右子树，那么查找x节点右子树上的最小值即可。 无右子树，并有一个后继y，那么y就是x的最底层祖先，并且y的左孩子也是x的一个祖先。例如，上图左边的树中5的后继节点为6。为了找到y，x开始沿树向上直到遇到这样一个节点：这个节点是它双亲的左孩子。 后继：123456789def tree_successor(x): if x.right is not null: return tree_min(x.right) y = x.parent while y is not null and x == y.right: x = y y = y.parent return y 备注：这里用到了一个性质，如果T中一个节点x的右子树为空，且x有一个后继y，那么y一定是x的最底层祖先，并且其左孩子也是x的祖先。前驱类似，这里不再赘述。 以上操作时间复杂度均为O(h)，其中，h为树的高度。 插入将一个新值v插入到二叉搜索树T中，以节点z作为输入，其中z.key=value,z.left=null,z.right=null。这个过程需要修改T和z的某些属性，把z插入到相应的位置上。123456789101112131415161718def tree_insert(T,z): x , y= T.root , null # x用来记录路径 while x is not null: y = x if z.key &lt; x.key: x = x.left else: x = x.right # 用来记录要插入位置的父节点 z.parent = y # 判断插入在何处 if y is null: T.root = z elif z.key &lt; y.key: y.left = z else: y.right = z 删除从一棵二叉搜索树T中删除一个节点z，分为三种情况： z没有孩子，直接删除z，并修改父节点。 z只有一个孩子，这个孩子代替z，并修改父节点。 z有两个孩子，这种情况最复杂。 下面是四种情况：（一图胜千言） 实际上所有的这些情况都是在执行移植的一个过程。现在我们来定义一下这个子过程transplant，它是用另一棵子树替换一棵子树并成为其双亲的孩子节点。 12345678910def transplant(T,u,v): if u.parent == null: T.root = v elif u == u.parent.left u.parent.left = v else: u.parent.right = v if v is not null: v.parent = u.parent 下面是二叉搜索树中删除节点z的过程：1234567891011121314151617181920def tree_del(T,z): # 没有左孩子 if z.left is null: transplant(T,z,z.right) # 没有右孩子 elif z.right is null: transplant(T,z,z.left) # 下面是有两个孩子的情况 else: # 查找节点y y = tree_min(z.right) if y.parent != z: # 上图情况(d) transplant(T,y,y.right) y.right = z.right y.right.parent = y # y替换z,上图情况(c) transplant(T,z,y) y.left = z.left y.left.parent = y 参考书目：[^1]: 《算法导论》【美】Tomas H.Cormen .etc 编著","tags":[{"name":"算法","slug":"算法","permalink":"http://likernel.github.io/tags/算法/"},{"name":"BST","slug":"BST","permalink":"http://likernel.github.io/tags/BST/"}]},{"title":"贪婪算法","date":"2017-07-30T20:12:44.000Z","path":"2017/07/31/贪婪算法/","text":"A greedy algorithm is an algorithmic paradigm that follows the problem solving heuristic of making the locally optimal choice at each stage with the hope of finding a global optimum. In many problems, a greedy strategy does not in general produce an optimal solution, but nonetheless a greedy heuristic may yield locally optimal solutions that approximate a global optimal solution in a reasonable time. 贪婪算法在对问题求解时，总是做出在当前看来是最好的选择。也就是说，不从整体最优上加以考虑，他所做出的仅是在某种意义上的局部最优解。所以对所采用的贪心策略一定要仔细分析其是否满足无后效性。 例如：之前讲过的狄克斯特拉和广度优先搜索都属于贪婪算法。 步骤 建立数学模型来描述问题。 把求解的问题分成若干个子问题。 对每一子问题求解，得到子问题的局部最优解。 把子问题的解局部最优解合成原来解问题的一个解。 NP完全问题以难解著称的问题，判断NP完全问题很难。但还是有一些蛛丝马迹可寻： 元素较少时运行速度很快，随着元素数量增加，速度会变得非常慢。2，涉及“所有组合”的问题，经常是NP完全问题。 不能将问题分成小问题，必须考虑各种情况。 如果涉及序列或集合且难以解决。 问题可转换为集合覆盖问题或旅行商问题。 近似算法有些问题（NP完全问题），没有任何算法可以足够快的解决这个问题。需要用到近似算法，可以得到非常接近的解。贪婪算法就是一种简单易实现的近似算法。 一般判断一个近似算法优劣的标准如下： 速度有多快。 得到的近似解和最优解的接近程度。 备注：这里没有讲解具体的实例，介绍的非常基础，之后再算法进阶学习中进一步说明。","tags":[{"name":"算法","slug":"算法","permalink":"http://likernel.github.io/tags/算法/"}]},{"title":"leetcode--Search a 2D Matrix","date":"2017-07-30T02:00:09.000Z","path":"2017/07/30/leetcode-Search-a-2D-Matrix/","text":"Write an efficient algorithm that searches for a value in an m x n matrix. This matrix has the following properties: Integers in each row are sorted from left to right. The first integer of each row is greater than the last integer of the previous row. For example, Consider the following matrix:12345[ [1, 3, 5, 7], [10, 11, 16, 20], [23, 30, 34, 50]] Given target = 3, return true. 思路： 思路比较简单，和剑指offer中的FindInPartiallySortedMatrix是一样的： 从右上角或者左下角的元素开始遍历均可。（这里以右上角为例） 如果和target相等说明找到；如果右上角比target大，向下遍历；如果比target小，向左遍历。 实现：1234567891011121314def searchMatrix(matrix, target): if not matrix or target is None: return False i = 0 j = len(matrix[0])-1 while i &lt; len(matrix) and j &gt;= 0: if matrix[i][j] == target: return True elif matrix[i][j] &lt; target: i += 1 else: j -= 1 return False 备注：一定要加上matrix是否为空的判断，系统中给的测试用例中包含一个[ ]。","tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://likernel.github.io/tags/leetcode/"},{"name":"算法","slug":"算法","permalink":"http://likernel.github.io/tags/算法/"}]},{"title":"狄克斯特拉算法","date":"2017-07-29T06:26:48.000Z","path":"2017/07/29/狄克斯特拉算法/","text":"Dijkstra’s algorithm is an algorithm for finding the shortest paths between nodes in a graph, which may represent, for example, road networks. It was conceived by computer scientist Edsger W. Dijkstra in 1956 and published three years later. The algorithm exists in many variants; Dijkstra’s original variant found the shortest path between two nodes, but a more common variant fixes a single node as the “source” node and finds shortest paths from the source to all other nodes in the graph, producing a shortest-path tree. Dijkstra’s algorithm之前，在BFS中我们解决了寻找最短路径的问题，但是在BFS中的边是不带权重的，我们找的最短路径即段数最少的。如果带上了权重，我们需要使用Dijkstra算法。主要包括四个步骤： 找出“最便宜”的节点，即可在最短时间内到达的节点。 更新该节点的邻居的开销。 重复这个过程直到对每个节点都这样做了。 计算最终路径。 术语Dijkstra算法使用之前先澄清一些术语： Dijkstra算法用于每条边都有关联数字的图，这些数字被称为权重。 带权重的图称为加权图，不带权重的图称为非加权图。 计算非加权图的最短路径使用BFS，计算加权图中的最短路径使用Dijkstra。 图可能还有环，即可以在某个节点走一圈后回到这个节点。 之前介绍的无向图意味着彼此指向对方，实际上就是环，无向图中每条边都是一个环。 Dijkstra只适用于有向无环图（directed acyclic graph，DAG） 实现123456789101112131415161718192021222324252627def find_lowest_cost_node(costs): lowest_cost = float(&quot;inf&quot;) lowest_cost_node = None # 遍历所有节点 for node in costs: cost = costs[node] # 如果打枊前节点开销更低且未处理过 if cost &lt; lowest_cost and node not in processed: # 将其视为开销最低的节点 lowest_cost = cost lowest_cost_node = node return lowest_cost_node# 在未处理的节点中找出开销最小的节点node = find_lowest_cost_node(costs)while node is not None: cost = costs[node] neighbors = graph[node] # 遍历当前节点的所有邻居 for n in neighbors.keys(): new_cost = cost + neighbors[n] if costs[n] &gt; new_cost: costs[n] = new_cost parents[n] = node processed.append(node) # 找出接下来要处理的节点，并循环 node = find_lowest_cost_node(costs) 备注：如果图中包含负权边，可以使用贝尔曼-福德算法。 参考书目：[^1]: 《算法图解》【美】Aditya Bhargava. 编著","tags":[{"name":"算法","slug":"算法","permalink":"http://likernel.github.io/tags/算法/"}]},{"title":"Introduce django","date":"2017-07-27T08:01:36.000Z","path":"2017/07/27/Introduce-django/","text":"之前做过一些django项目，但是在那之前没有系统的学过，路子比较野。最近闲下来，觉得很有必要重新系统的学习一下django，这是开篇。 名字的由来最初是比利时的爵士音乐家Django Reinhardt命名，作者希望Django能够优雅的演奏（开发）功能丰富的乐曲（web应用）。 MVC把数据存储逻辑、业务逻辑和表现逻辑组合在一起的概念被称为软件架构的 Model-View-Controller (MVC)模式。 接下来我们来分析一下Django的MVC模式： M层：模型层，对应的应该是models.py文件，主要用一个Python类来描述数据表。运用这个类，你可以通过简单的 Python的代码来实现数据库的操作。 V层：view层，即显示内容以及怎么显示。视图层对应的是模板系统以及视图，对应的文件是views.py和html模板文件。 C层：根据用户输入委派视图的部分，由 Django 框架根据URLconf 设置，对给定 URL 调用适当的 Python 函数但是由于C层是由框架自行处理。 而在Django中主要的关注还是模型（Model），模板（Template）和视图（Views），所以人们也常称这种开发模式为MTV开发模式。 特点 完善的文档。 集成数据访问组件。 强大的URL映射技术。 后台管理系统自动生成。 错误信息完整。 Django核心框架包括： 面向对象的映射器，用作数据模型（以Python类的形式定义）和关联性数据库间的媒介。 基于正则表达式的URL分发器。 视图系统，用于处理请求。 模板系统。 一个轻量级的、独立的Web服务器，用于开发和测试。 一个表单序列化及验证系统，用于HTML表单和适于数据库存储的数据之间的转换。 一个缓存框架，并有几种缓存方式可供选择。 中间件支持，允许对请求处理的各个阶段进行干涉。 内置的分发系统允许应用程序中的组件采用预定义的信号进行相互间的通信。 一个序列化系统，能够生成或读取采用XML或JSON表示的Django模型实例。 一个用于扩展模板引擎的能力的系统。","tags":[{"name":"django","slug":"django","permalink":"http://likernel.github.io/tags/django/"},{"name":"web开发","slug":"web开发","permalink":"http://likernel.github.io/tags/web开发/"}]},{"title":"django实现MySQL数据库连接池","date":"2017-07-26T01:33:53.000Z","path":"2017/07/26/django实现MySQL数据库连接池/","text":"Python可以使用MySQLdb进行数据库操作，但是每次连接MySQL数据库请求时，都是独立的去请求访问，相当浪费资源，而且访问数量达到一定数量时，对mysql的性能会产生较大的影响。实际使用中，通常会使用数据库的连接池来访问数据库达到资源复用的目的。这里介绍一下在django中如何实现数据库连接池。 DBUtilsDBUtils是一套python数据库连接池包，并允许对非线程安全的数据库接口进行线程安全包装。DBUtils来自Webware for Python。 下载地址：DBUtils DBUtils提供两种外部接口： PersistentDB ：提供线程专用的数据库连接，并自动管理连接。 PooledDB ：提供线程间可共享的数据库连接，并自动管理连接。 将下载下来的源码解压，放在应用程序根目录”database”中，修改SteadyDB.py文件，在类 SteadyDBConnection 中添加3个成员方法:123456789def autocommit(self, *args, **kwargs): self._con.autocommit(*args, **kwargs)def get_server_info(self): return self._con.get_server_info()@propertydef encoders(self): return self._con.encoders 修改 PooledDB.py 和 PersistentDB.py 两个文件，将1from DBUtils.SteadyDB import connect 改为：1from .SteadyDB import connect 将Django中的mysql模块加入应用程序目录中,将backends目录下的 __init__.py文件和mysql目录复制到database目录下的db目录中，目录结构如下:123456789应用程序根目录|| -- database | | -- DBUtils | -- db | | -- __init__.py | -- mysql 在mysql目录下添加pool.py文件，如下:12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152# coding:utf-8'''A connection pool of MySQL in Django 1.5 based on DBUtils.'''import MySQLdbfrom database.DBUtils.PooledDB import PooledDBclass ConnectionWrapper(object): def __init__(self, connection): self._conn = connection def __getattr__(self, method): ''' 代理数据库连接的属性方法 ''' return getattr(self._conn, method) def close(self): ''' 代理Django的关闭数据库连接 ''' self._conn.close()class DBWrapper(object): def __init__(self, module): self._connection = None self._db = module self._pool = &#123;&#125; def __getattr__(self, item): return getattr(self._db, item) def _clear_connections(self, **kwargs): ''' 关闭已有连接 ''' conn = MySQLdb.connect(**kwargs) cursor = conn.cursor() sql = '' cursor.execute('show full processlist;') processlist = cursor.fetchall() for th in processlist: if th[3] == kwargs.get('db') and th[0] != conn.thread_id(): sql += 'kill %s;' % th[0] if len(sql.split(';')) &gt; 1: cursor.execute(sql) cursor.close() conn.close() def connect(self, *args, **kwargs): ''' 创建连接 ''' db = kwargs.get('db') if db not in self._pool: size = kwargs.get('size') if 'size' in kwargs: kwargs.pop('size') self._clear_connections(**kwargs) self._pool[db] = PooledDB(self._db, mincached=size, maxcached=size, *args, **kwargs) self._connection = self._pool[db].connection() return ConnectionWrapper(self._connection) 修改mysql目录下的 base.py 文件，在1import MySQLdb as Database 下添加两行12from .pool import DBWrapperDatabase = DBWrapper(Database) 修改类 DatabaseWrapper 中的方法 get_connection_params，在12if settings_dict['PORT']: kwargs['port'] = int(settings_dict['PORT']) 下添加如下代码，使连接池支持”SIZE”参数12if settings_dict.get('SIZE'): kwargs['size'] = int(settings_dict['SIZE']) 在settings.py配置文件的数据库项中，可以通过配置”SIZE”参数来指定连接池中某数据库的连接数量，如：12345678910111213141516DATABASES = &#123; 'default': &#123; # 'ENGINE': 'django.db.backends.mysql', 'ENGINE': 'database.db.mysql', 'NAME': 'cartoon', 'USER': 'root', 'PASSWORD': 'root', 'HOST': '', 'PORT': '', # 指定10个连接到cartoon库 'SIZE': '10', # Default '0' means unlimit connection pool size 'OPTIONS': &#123; 'init_command': 'SET default_storage_engine=INNODB', &#125;, &#125;&#125; 至此，连接池改造完成。 运行程序，进入mysql命令行，执行1show full processlist; 可以看到连接池里面所有的连接。[^1]: 参考链接： Django实现MySQL连接池.","tags":[{"name":"django","slug":"django","permalink":"http://likernel.github.io/tags/django/"},{"name":"web开发","slug":"web开发","permalink":"http://likernel.github.io/tags/web开发/"},{"name":"数据库","slug":"数据库","permalink":"http://likernel.github.io/tags/数据库/"}]},{"title":"广度优先搜索（BFS）","date":"2017-07-25T17:19:20.000Z","path":"2017/07/26/广度优先搜索（BFS）/","text":"Breadth-first search (BFS) is an algorithm for traversing or searching tree or graph data structures. It starts at the tree root (or some arbitrary node of a graph, sometimes referred to as a ‘search key’[1]) and explores the neighbor nodes first, before moving to the next level neighbors.–wiki 图图由节点和边组成。一个节点可能与众多节点直接相连，这些节点被称为邻居。一般我们把顶点用V缩写，把边用E缩写。 广度优先搜索广度优先搜索是一种用于图的查找算法，可帮助解决两类问题。 从节点A出发，有前往B的路径吗？ 从节点A出发，前往节点B的哪条路径最短？ 找出最短路径在搜索过程中是由近及远的。在寻找最近路径时，需要按添加顺序进行检查，因此需要使用队列。 队列和现实生活中的队列类似，是一种FIFO的数据结构。 实现图图可用散列表实现。将键映射到值，可以描述我们需要描述的关系。 实现算法建立关系图：12345graph = &#123;&#125;graph[&quot;you&quot;] = [&quot;alice&quot;, &quot;bob&quot;, &quot;charlie&quot;]graph[&quot;bob&quot;] = [&quot;peggy&quot;]graph[&quot;peggy&quot;] = []... BFS搜索：123456789101112131415161718def search(name): search_queue = deque() search_queue += graph[name] searched = [] while search_queue: person = search_queue.popleft() if person not in searched: if person_is_find(person): print person + &quot;is find!&quot; return true else: search_queue += graph[person] searched.append(person) return false# 查找peggydef person_is_find(name): return name == peggy 备注：以上使用BFS查找你的关系网中叫peggy的人。 运行时间O(V+E) 参考书目：[^1]: 《算法图解》【美】Aditya Bhargava. 编著","tags":[{"name":"算法","slug":"算法","permalink":"http://likernel.github.io/tags/算法/"}]},{"title":"leetcode--4 Sum","date":"2017-07-23T08:18:35.000Z","path":"2017/07/23/leetcode-4-Sum/","text":"4 SumGiven an array S of n integers, are there elements a, b, c, and d in S such that a + b + c + d = target? Find all unique quadruplets in the array which gives the sum of target. The solution set must not contain duplicate quadruplets. Example:1234567given array S = [1, 0, -1, 0, -2, 2], and target = 0.A solution set is:[ [-1, 0, 0, 1], [-2, -1, 1, 2], [-2, 0, 0, 2]] 思路：n重循环这里就不做赘述了，而且可能会引起超时，肯定不是出题者的本意，这里使用hash表来实现。 将问题转化为3sum，即我们可以将两个元素求和之后当做一个元素处理。首先建立一个字典dict，字典的key值为数组中每两个元素的和，每个key对应的value为这两个元素的下标组成的元组。 接下来就转化为3sum的问题，有一些细节仍需要处理，我们需要找到满足的value。 根据value找到对应的下标，判断下标是否和当前遍历元素的下标重复。不重复则将结果添加至结果集中。 实现： 12345678910111213141516171819def fourSum(self, nums, target): nums_len, res, dict = len(nums), set(), &#123;&#125; if nums_len &lt; 4: return [] nums.sort() # 将值添加至至dict for i in range(nums_len): for j in range(i+1, nums_len): if nums[i]+nums[j] not in dict: dict[nums[i]+nums[j]] = [(i,j)] else: dict[nums[i]+nums[j]].append((i,j)) # 查找Value for i in range(nums_len): for j in range(i+1, nums_len-2): V = target-nums[i]-nums[j] if V in dict: for k in dict[V]: if k[0] &gt; j: res.add((nums[i],nums[j],nums[k[0]],nums[k[1]])) return [list(i) for i in res]","tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://likernel.github.io/tags/leetcode/"},{"name":"算法","slug":"算法","permalink":"http://likernel.github.io/tags/算法/"}]},{"title":"leetcode--3 Sum Closest","date":"2017-07-23T08:16:29.000Z","path":"2017/07/23/leetcode-3-Sum-Closest/","text":"3 Sum ClosestGiven an array S of n integers, find three integers in S such that the sum is closest to a given number, target. Return the sum of the three integers. You may assume that each input would have exactly one solution. Example:12For example, given array S = &#123;-1 2 1 -4&#125;, and target = 1.The sum that is closest to the target is 2. (-1 + 2 + 1 = 2). 思路：思路和3sum类似，还是找一个基准值和两个指针lp和rp不过有些地方简化了，只需要获得一个值。因此，对应的组合不用存取，只需要不断的更新最接近的值即可。 实现：123456789101112131415161718192021def threeSumClosest(nums, target): if not len(nums): return 0 nums.sort() res = nums[0] + nums[1] + nums[2] for i in range(len(nums) - 2): lp = i + 1 rp = len(nums) - 1 while lp &lt; rp: closest = nums[i] + nums[lp] + nums[rp] if abs(closest - target) &lt; abs(res - target): res = closest if closest &lt; target: lp += 1 elif closest &gt; target: rp -= 1 else: lp += 1 rp -= 1 return res","tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://likernel.github.io/tags/leetcode/"},{"name":"算法","slug":"算法","permalink":"http://likernel.github.io/tags/算法/"}]},{"title":"leetcode--3 Sum","date":"2017-07-23T08:12:02.000Z","path":"2017/07/23/leetcode-3-Sum/","text":"3 SumGiven an array S of n integers, are there elements a, b, c in S such that a + b + c = 0? Find all unique triplets in the array which gives the sum of zero. The solution set must not contain duplicate triplets. Example：123456given array S = [-1, 0, 1, 2, -1, -4],A solution set is:[ [-1, 0, 1], [-1, -1, 2]] 思路：1.首先，还是进行排序处理，然后对三个数我们分别做如下处理：2.第一个数当做基准数，从数组第一个数开始一直向右遍历到倒数第三个数。3.另外两个数我们每次都只从基准数右边选取，可以将右边部分当做一个新的数组。4.借助两个变量（类似于指针），分别指向这个新数组最左和最右元素即为剩下要处理的两个数。5.有了这三个数我们做如下讨论：6.如果这三个数之和小于0，则左指针加1；大于0则右指针减1；否则，满足条件，把当前三个数加入结果集，两个指针同时向中间移动。7.两指针相遇，则基准数下所有结果已经遍历完成，基准数加1，继续寻找结果。8.这里我们所有结果找到了，但是没有处理重复，思路如下：9.在基准数操作的时候，有这种情况，如果这个基准数和上一个基准数一样，那么，后面的操作就重复了，得到的结果也会重复，所以，在操作之前，需要判断基准数是否和上一个重复，这样可以避免重复。10.同样在指针操作的时候，如果和指向的上一个数字一样，也会造成重复，所以，也需要进行判断处理。 解法：123456789101112131415161718192021def threeSum(self, nums): nums.sort() res,i = [],0 for i in range(len(nums)-2): if i == 0 or nums[i] != nums[i-1]: lp ,rp= i+1 ,len(nums)-1 while lp &lt; rp: if nums[i]+nums[lp]+nums[rp] &lt; 0: lp += 1 elif nums[i]+nums[lp]+nums[rp] &gt; 0: rp -= 1 else: res.append([nums[i],nums[lp],nums[rp]]) lp += 1 rp -= 1 while lp &lt; rp and nums[lp] == nums[lp-1]: lp += 1 while lp &lt; rp and nums[rp] == nums[rp+1]: rp -= 1 i += 1 return res 备注：在判断指针指向重复的时候一定要使用while，不能用if，因为你不清楚是否是连续重复，如果用if，判断了一次就跳出循环了。","tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://likernel.github.io/tags/leetcode/"},{"name":"算法","slug":"算法","permalink":"http://likernel.github.io/tags/算法/"},{"name":"数组","slug":"数组","permalink":"http://likernel.github.io/tags/数组/"}]},{"title":"leetcode--Container With Most Water","date":"2017-07-23T08:06:25.000Z","path":"2017/07/23/leetcode-Container-With-Most-Water/","text":"Container With Most WaterGiven n non-negative integers a1, a2, …, an, where each represents a point at coordinate (i, ai). n vertical lines are drawn such that the two endpoints of line i is at (i, ai) and (i, 0). Find two lines, which together with x-axis forms a container, such that the container contains the most water. Note: You may not slant the container and n is at least 2. 思路：这个题还是比较容易实现的，主要就是题目理解起来比较绕（英语水平有限）。大概就是在二维坐标系中，(i, ai) 表示 从 (i, 0) 到 (i, ai) 的一条线段，给定了一个数组[a1…..an]，这就有了n条线段。任意两条这样的线段和 x 轴组成一个木桶，找出能够盛水最多的木桶，返回其容积。 高选较短的，而最长的一种情况显然就是n-1，但是这不能保证面积是最大的。 这个时候谁短谁向中间移，这个时候更新一下面积即可，移动的时候可以借助两个变量当做指针。短的向中间移，即我们说的贪婪算法，选取局部最优。 当指针相等的时候结束遍历。算法时间复杂度为O(n)。 实现：123456789def maxArea(height): left, right, max_area = 0, len(height)-1, 0 while left &lt; right: max_area = max(max_area,min(height[right],height[left])*(right-left)) if height[left] &lt;= height[right]: left += 1 elif height[left] &gt; height[right]: right -= 1 return max_area","tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://likernel.github.io/tags/leetcode/"},{"name":"算法","slug":"算法","permalink":"http://likernel.github.io/tags/算法/"}]},{"title":"选择排序","date":"2017-07-23T00:13:36.000Z","path":"2017/07/23/选择排序/","text":"The algorithm divides the input list into two parts: the sublist of items already sorted, which is built up from left to right at the front (left) of the list, and the sublist of items remaining to be sorted that occupy the rest of the list. 选择排序选择排序（Selection sort）是一种简单直观的排序算法。它的工作原理是每一次从待排序的数据元素中选出最小（或最大）的一个元素，存放在序列的起始位置，直到全部待排序的数据元素排完。时间复杂度为O(n^2)。 python实现：123456789101112131415def findSmallest(arr): smallest = arr[0] #最小的数 smallest_index = 0 #最小的数的索引 for i in range(1,len(arr)): if arr[i] &lt; smallest: smallest = arr[i] smallest_index = i return smallest_indexdef selection_sort(arr): #对数组进行排序 new_arr = [] for i in range(len(arr)): smallest = findSmallest(arr) new_arr.append(arr.pop(smallest)) return new_arr 参考书目：[^1]: 《算法图解》【美】Aditya Bhargava. 编著","tags":[{"name":"算法","slug":"算法","permalink":"http://likernel.github.io/tags/算法/"},{"name":"排序","slug":"排序","permalink":"http://likernel.github.io/tags/排序/"}]},{"title":"leetcode--Median of Two Sorted Arrays","date":"2017-07-22T00:14:52.000Z","path":"2017/07/22/leetcode-Median-of-Two-Sorted-Arrays/","text":"There are two sorted arrays nums1 and nums2 of size m and n respectively. Find the median of the two sorted arrays. The overall run time complexity should be O(log (m+n)). Example 1:1234nums1 = [1, 3]nums2 = [2]The median is 2.0 Example 2:1234nums1 = [1, 2]nums2 = [3, 4]The median is (2 + 3)/2 = 2.5 概念： median：首先需要了解何为median，即我们常说的中位数（针对排序数组来说的），如果为奇数就是正中间的那个数，如果为偶数就是中间的两个数的平均数，like Example 1和Example 2. 思路： 这个题乍看比较容易，但是在LeetCode中给出的Difficulty是hard，关键就在于它对时间复杂度有要求，为O(log (m+n))。对数时间我首先想到的是二分查找，说明该算法的效率一定要与之类似，但又有所限制，确实很难。处理时不能将两个数组合并，不然时间复杂度就提升为线性时间O(m+n)。但我们每次处理需要类似二分查找那样每次平均要处理一半的数。1.这里我们借用findKthNumber的思想。先实现findKthNumber，如果是偶数个，则把中间2个加起来平均，奇数就用中间的。2.为了达到对数级的复杂度，我们可以这样：每次在A，B取前k/2个元素。有以下几种情况：1） A的元素不够k/2，我们可以丢弃B前k/2个元素。反之亦然。反证法：假设第K大在B的前k/2中，例如位置在索引m(m&lt;=k/2-1)那么A必然拥有前k中的k -(m+1)个元素，而m&lt;=k/2-1,则m+1&lt;=k/2,k-(m+1)&gt;k/2与条件：A的元素不够k/2矛盾，所以假设不成立，得证。2）A[mid] &lt; B[mid] (mid是k/2 -1索引处的元素）。这种情况下，我们可以丢弃A前k/2。12345反证法：假设第K大在A的前k/2中记为maxK，例如位置在索引m(m&lt;= k/2-1)。那么B必然拥有前k中的k-(m+1)个元素，而m&lt;=k/2-1,则m+1 &lt;=k/2,k-(m+1)&gt;k/2，推出B[mid]&lt;=maxK。而A[mid] &gt;= maxK。 推出 A[mid]&gt;=B[mid], 与题设矛盾。 3.知道上面两个结论对我们很重要。接下来，使用D&amp;C来解决一下这个问题。1234561.基线条件（有两种情况）：1）有一个数组为空2）数组都不为空，k=1（这时候取两个数组最小的元素即可）2.递归条件：A[mid] &lt; B[mid]，丢弃A前k/2。（包含两层意思：A或B舍弃k/2;k做相应变化，k-mid） 源码：123456789101112131415161718192021222324252627def findMedianSortedArrays(num1, num2): len_sum = len(num1)+len(num2) if(len_sum % 2 == 1): return findKth(num1, num2, len_sum/2+1) else: return (findKth(num1, num2, len_sum/2)+findKth(num1, num2, len_sum/2+1))/2.0def findKth(A, B, k): len1,len2 = len(A),len(B) if len(A)==0: return B[k-1] if len(B)==0: return A[k-1] if k == 1: return min(A[0],B[0]) mid1 = min(k/2,len1) mid2 = min(k/2,len2) if A[mid1-1] &lt; B[mid2-1]: C = A[mid1:len1] return findKth(C,B,k-mid1) else: C = B[mid2:len2] return findKth(A,C,k-mid2)print findMedianSortedArrays([1,2],[3,4]) 备注：不使用D&amp;C，使用循环一样可以实现。这里给出一种使用循环的解法。123456789101112131415161718192021def findMedianSortedArrays(nums1, nums2): len_sum = len(nums1)+len(nums2) if(len_sum % 2 == 1): return findKth(nums1, nums2, len_sum/2+1) return (findKth(nums1, nums2, len_sum/2)+findKth(nums1, nums2, len_sum/2+1))/2.0 def findKth(self, A, B, k): m,n = len(A), len(B) if m &gt; n: return findKth(B, A, k) left, right = 0, m while left &lt; right: mid = left + (right-left)/2 if 0 &lt;= k-1-mid &lt; n and A[mid] &gt;= B[k-1-mid]: right = mid else: left = mid+1 Ai_minus1 = A[left - 1] if left - 1 &gt;= 0 else float(&quot;-inf&quot;) Bj = B[k - 1 - left] if k - 1 - left &gt;= 0 else float(&quot;-inf&quot;) return max(Ai_minus1,Bj) 注：float(“-inf”)表示负无穷。","tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://likernel.github.io/tags/leetcode/"},{"name":"算法","slug":"算法","permalink":"http://likernel.github.io/tags/算法/"}]},{"title":"leetcode--Two Sum","date":"2017-07-21T04:12:52.000Z","path":"2017/07/21/leetcode-Two-Sum/","text":"Two SumGiven an array of integers, return indices of the two numbers such that they add up to a specific target. You may assume that each input would have exactly one solution, and you may not use the same element twice. Example:123Given nums = [2, 7, 11, 15], target = 9,Because nums[0] + nums[1] = 2 + 7 = 9,return [0, 1]. 思路：12341.题目未说明是有序数组，因此，为了方便我们进行处理，首先需要进行排序。2.第二步进行查找，找出排序之后小于target的元素。3.在剩下的数组中进行遍历，找出两个数。4.找出这两个数对应原数组的下标。 实现：123456789101112131415def twoSum(nums, target): item_index = nums arr = [i for i in nums if i &lt; target] arr.sort() for i in range(len(arr)): for j in range(i+1,len(arr)): if arr[i] + arr[j] == target: return([findIndex(arr[i],item_index), findIndex(arr[j],item_index)])def findIndex(item,item_index): for index in range(len(item_index)): if item == item_index[index]: return index 其他解法：123456def twoSum(nums, target): process=&#123;&#125; for index in range(len(nums)): if target-nums[index] in process: return [process[target-nums[index]],index] process[nums[index]]=index 注：这个解法是在网上看到的，确实简单许多，采用hashtable，数值记为key,value记为index，target-num[index]作为搜索条件。","tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://likernel.github.io/tags/leetcode/"},{"name":"算法","slug":"算法","permalink":"http://likernel.github.io/tags/算法/"}]},{"title":"散列表","date":"2017-07-21T03:51:56.000Z","path":"2017/07/21/散列表/","text":"A hash table (hash map) is a data structure which implements an associative array abstract data type, a structure that can map keys to values. A hash table uses a hash function to compute an index into an array of buckets or slots, from which the desired value can be found. 散列函数散列函数是这样的函数，无论你给它什么数据，它都会给你一个数字。用专业的话说，“散列函数将输入映射到数字。” 散列函数总是将同样的输入映射到相同的索引。 散列函数总是将不同的输入映射到不同的索引。（有问题，暂且先这样理解） 散列表知道数组有多大，只返回有效的索引。 任何一门优秀的语言都提供了散列表的实现，python提供的散列表的实现为字典。可以通过dict来创建散列表。像之前leetcode中的Two Sum，最快捷的方法就是使用dict。1234#第一种创建方法hash_table = dict()#第二种创建方法hash_table = &#123;&#125; 应用散列表的用途十分广泛，下面介绍一下它的用途。 将散列表用于查找散列表常被用于大海捞针式的查找。例如，我们常见的DNS解析（将网址映射到IP地址），散列表就是实现这种功能的方式之一。 散列表用于查找,大致分为两个步骤：121. 创建映射2. 查找 防止重复121. 创建映射2. 检查是否重复 将散列表用作缓存缓存是一种常用的加速方式，所有的大型网站都使用缓存，而缓存的数据就是存储在散列表中的。 当URL不在缓存中时，才让服务器做处理，并将生成的数据存储到缓存中，再返回它。123456789cache = &#123;&#125;def get_page(url): if cache.get(url): return cache[url] else: data = get_data_from_server(url) cache[url] = data return data 冲突这里我们没有讨论散列表内部的原理，但是我们依旧需要考虑散列表的性能，我们需要搞清楚什么是冲突。 之前谈到散列函数总是将不同的输入映射到不同的索引，这句话实际上是有问题的。因为这只是最理想的情况，实际上散列函数可能将不同的输入映射到同一个索引。这种情况就是冲突。处理冲突的方法有很多，最简单的办法就是：如果两个键映射到了同一个位置，就在这个位置存储一个链表，但是链表很长依然会影响散列表的性能。因此，需要记住： 散列函数很重要； 如果散列函数很好，这些链表就不会很长。性能在平均情况下，散列表执行各种操作的时间都为O(1)，O(1)被称为常量时间。在最糟情况下，散列表所有操作的运行时间都为O(n)，—线性时间，这就比较慢了。 所以，避开最糟情况很重要，为此我们需要： 较低的填装因子 良好的散列函数 填装因子填装因子=散列表包含的元素数/位置总数 填装因子是用来度量散列表中有多少位置是空的。大于1意味着元素数量超过位置数，需要在散列表中添加位置，这被称为调整长度（resizing）。 填装因子越低，发生冲突的可能性越小，散列表的性能越高，一个不错的经验规则是：一旦填装因子大于0.7，就调整散列表的长度。 调整散列表的长度开销很大，所以最好不要频繁这样操作。但平均而言，即便考虑调整长度所需的时间，散列表操作所需的时间仍为O(1)。 良好的散列函数良好的散列函数，让数组中的值呈均匀分布。糟糕的散列函数让值扎堆，导致大量冲突。 SHA就是一种良好的散列函数，之后将会做详细的介绍。 参考书目：[^1]: 《算法图解》【美】Aditya Bhargava. 编著","tags":[{"name":"算法","slug":"算法","permalink":"http://likernel.github.io/tags/算法/"}]},{"title":"快速排序","date":"2017-07-21T00:42:56.000Z","path":"2017/07/21/快速排序/","text":"Divide and conquer (D&amp;C) is an algorithm design paradigm based on multi-branched recursion. A divide and conquer algorithm works by recursively breaking down a problem into two or more sub-problems of the same or related type, until these become simple enough to be solved directly. The solutions to the sub-problems are then combined to give a solution to the original problem. D&amp;C分而治之，提供的是解决问题的一种思路。使用D&amp;C解决问题的过程包括两个步骤：121.找出基线条件，这种条件必须尽可能简单。2.不断将问题分解（或者缩小规模），直到符合基线条件 快速排序下面以快排为例进行讲解，对排序算法来说，最简单的数组就是“不用排序”的数组。 1.空数组2.数组中只有一个数字 因此基线条件为数组为空或者只包含一个元素。这时候只需原样返回数组即可。 要使用D&amp;C，需要将数组分解，直到满足基线条件。首先，从数组中选择一个元素作为基准值（pivot）。找出比基准值大的元素和比基准值小的元素。这个过程被称为分区（patitioning）。现在你将数组分成了三个部分： 1.小于基准值的数组成的子数组2.基准值3.大于基准值的数组成的子数组 快排代码：12345678def quicksort(arr): if len(arr)&lt;2: return arr else: pivot = arr[0] less = [i for i in arrray[1:] if i &lt;= pivot] greater = [i for i in arrray[1:] if i &gt; pivot] return quicksort(less) + [pivot] + quicksort(greater) 参考书目：[^1]: 《算法图解》【美】Aditya Bhargava. 编著","tags":[{"name":"算法","slug":"算法","permalink":"http://likernel.github.io/tags/算法/"},{"name":"排序","slug":"排序","permalink":"http://likernel.github.io/tags/排序/"}]},{"title":"递归","date":"2017-07-21T00:40:52.000Z","path":"2017/07/21/递归/","text":"Recursion in computer science is a method where the solution to a problem depends on solutions to smaller instances of the same problem (as opposed to iteration).[1] The approach can be applied to many types of problems, and recursion is one of the central ideas of computer science. Most computer programming languages support recursion by allowing a function to call itself within the program text. Some functional programming languages do not define any looping constructs but rely solely on recursion to repeatedly call code. 递归递归就是函数自己调用自己。在一些函数式编程中没有循环，只能用递归的方式来编写函数。递归可以让程序更加的清晰，并没有性能上的优势。至于选择，引用Stack Overflow上的一句话“如果使用循环，程序性能可能更高；如果使用递归程序可能更容易理解。如何选择，要看什么对你来说更重要。” 基线条件与递归条件编写递归函数时，一定要告诉它何时停止。每个递归函数都有两个部分，基线条件（base case）和递归条件（recursive case）。基线条件就是何时不调用自己，递归条件是何时调用自己。 栈栈（stack）又名堆栈，它是一种运算受限的线性表。其限制是仅允许在表的一端进行插入和删除运算。这一端被称为栈顶，相对地，把另一端称为栈底。 调用栈这个概念对理解递归很重要，这里便于理解不做专业的解释。调用栈是计算机内部使用的。调用一个函数的时候，该函数就进入调用栈，在栈顶添加了函数的内存块。调用另一个函数的时候，当前函数暂停并处于未完成状态。 递归调用栈下面以阶乘factorial为例来展示一下递归调用栈。 代码：12345def fact(x): if x == 1: return 1 else: return x*fact(x-1) 图解： 尾递归栈在递归中扮演了重要的角色，使用栈虽然方便，但要付出代价，每个函数调用都要占用一定内存，如果栈很高，会出现内存溢出。这时候有两种选择，使用循环或者尾递归。 尾递归就是用来减少这种堆栈的耗用，在这种递归代码在执行过程中是可以不需要回溯。一般是把当前的运算结果放在参数里传给下层函数。还是以阶乘为例：123456789def fact(x,a): if x &lt; 0: return 0 elif x == 0: return 1 elif x == 1: return a else: return fact(x-1,x*a) 备注：上述尾递归就是用了一个参数a来维护递归的层次。同上过程中，最后不需要再依次回调这些函数，每次的结果a都存储了下来。 参考书目：[^1]: 《算法图解》【美】Aditya Bhargava. 编著","tags":[{"name":"算法","slug":"算法","permalink":"http://likernel.github.io/tags/算法/"}]},{"title":"数组与链表","date":"2017-07-21T00:37:54.000Z","path":"2017/07/21/数组与链表/","text":"Array is a data structure consisting of a collection of elements (values or variables), each identified by at least one array index or key. An array is stored so that the position of each element can be computed from its index tuple by a mathematical formula. The simplest type of data structure is a linear array, also called one-dimensional array. A linked list whose nodes contain two fields: an integer value and a link to the next node. The last node is linked to a terminator used to signify the end of the list. 数组与链表在请求计算机提供存储空间的时候，计算机会提供一个存储地址，在存储多项数据的时候，有两种基本的方式数组和链表。 数组数组意味着所有项在内存中是相连的，会预留空间。 链表链表中的元素可以存储在内存中的任何地方。链表的每一个元素都存储了下一个元素的地址，从而使一串随机的内存地址串在一起。 比较链表的优势在于插入和删除元素，数组的优势在于读取元素。 在中间插入元素时，链表的表现显然更好，它只需要修改前面一个元素指向的地址就好了。而使用数组时，必须将后面所有的元素都向后移，同时还要考虑空间的问题； 在删除元素时，同样是只需要求该前一个元素的指向地址即可，而数组需要集体前移； 数组和链表哪个用的多一些呢，显然是数组，因为它支持随机访问，链表只能顺序访问（需要读最后一个元素时，必须要先读取前面所有的元素），很多情况都要求能随机访问，因此数组用的更多。 参考书目：[^1]: 《算法图解》【美】Aditya Bhargava. 编著","tags":[{"name":"算法","slug":"算法","permalink":"http://likernel.github.io/tags/算法/"}]}]